{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13823004,"sourceType":"datasetVersion","datasetId":8802882},{"sourceId":13823508,"sourceType":"datasetVersion","datasetId":8802605}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:14:00.923338Z","iopub.execute_input":"2025-11-24T17:14:00.923492Z","iopub.status.idle":"2025-11-24T17:14:00.927803Z","shell.execute_reply.started":"2025-11-24T17:14:00.923477Z","shell.execute_reply":"2025-11-24T17:14:00.926944Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nprint(\"CUDA available:\", torch.cuda.is_available())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:14:00.929473Z","iopub.execute_input":"2025-11-24T17:14:00.929715Z","iopub.status.idle":"2025-11-24T17:14:05.119863Z","shell.execute_reply.started":"2025-11-24T17:14:00.929694Z","shell.execute_reply":"2025-11-24T17:14:05.119099Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"This file illustrates how you might experiment with the HMM interface.\nYou can paste these commands in at the Python prompt, or execute `test_en.py` directly.\nA notebook interface is nicer than the plain Python prompt, so we provide\na notebook version of this file as `test_en.ipynb`, which you can open with\n`jupyter` or with Visual Studio `code` (run it with the `nlp-class` kernel).","metadata":{}},{"cell_type":"code","source":"import logging\nimport math\nimport os\nfrom pathlib import Path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:14:05.120786Z","iopub.execute_input":"2025-11-24T17:14:05.121743Z","iopub.status.idle":"2025-11-24T17:14:05.125646Z","shell.execute_reply.started":"2025-11-24T17:14:05.121707Z","shell.execute_reply":"2025-11-24T17:14:05.124877Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"%cd /kaggle/input/testing-run","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:14:10.244399Z","iopub.execute_input":"2025-11-24T17:14:10.245097Z","iopub.status.idle":"2025-11-24T17:14:10.249188Z","shell.execute_reply.started":"2025-11-24T17:14:10.245072Z","shell.execute_reply":"2025-11-24T17:14:10.248463Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/testing-run\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"pip install typeguard","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:14:10.474435Z","iopub.execute_input":"2025-11-24T17:14:10.474814Z","iopub.status.idle":"2025-11-24T17:14:14.556513Z","shell.execute_reply.started":"2025-11-24T17:14:10.474794Z","shell.execute_reply":"2025-11-24T17:14:14.555719Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: typeguard in /usr/local/lib/python3.11/dist-packages (4.4.4)\nRequirement already satisfied: typing_extensions>=4.14.0 in /usr/local/lib/python3.11/dist-packages (from typeguard) (4.15.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"pip install more_itertools","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:14:14.558037Z","iopub.execute_input":"2025-11-24T17:14:14.558287Z","iopub.status.idle":"2025-11-24T17:14:17.614105Z","shell.execute_reply.started":"2025-11-24T17:14:14.558263Z","shell.execute_reply":"2025-11-24T17:14:17.612946Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (10.7.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"pip install jaxtyping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:14:17.615378Z","iopub.execute_input":"2025-11-24T17:14:17.615709Z","iopub.status.idle":"2025-11-24T17:14:21.133938Z","shell.execute_reply.started":"2025-11-24T17:14:17.615655Z","shell.execute_reply":"2025-11-24T17:14:21.133229Z"}},"outputs":[{"name":"stdout","text":"Collecting jaxtyping\n  Downloading jaxtyping-0.3.3-py3-none-any.whl.metadata (7.8 kB)\nCollecting wadler-lindig>=0.1.3 (from jaxtyping)\n  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\nDownloading jaxtyping-0.3.3-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\nInstalling collected packages: wadler-lindig, jaxtyping\nSuccessfully installed jaxtyping-0.3.3 wadler-lindig-0.1.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from corpus import TaggedCorpus\nfrom eval import eval_tagging, model_cross_entropy, viterbi_error_rate\nfrom hmm import HiddenMarkovModel\nfrom crf import ConditionalRandomField","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:14:21.135855Z","iopub.execute_input":"2025-11-24T17:14:21.136179Z","iopub.status.idle":"2025-11-24T17:14:21.385328Z","shell.execute_reply.started":"2025-11-24T17:14:21.136153Z","shell.execute_reply":"2025-11-24T17:14:21.384562Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Set up logging.","metadata":{}},{"cell_type":"code","source":"logging.root.setLevel(level=logging.INFO)\nlog = logging.getLogger(\"test_en\")       # For usage, see findsim.py in earlier assignment.\nlogging.basicConfig(format=\"%(levelname)s : %(message)s\", level=logging.INFO)  # could change INFO to DEBUG","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:14:21.386085Z","iopub.execute_input":"2025-11-24T17:14:21.386284Z","iopub.status.idle":"2025-11-24T17:14:21.390528Z","shell.execute_reply.started":"2025-11-24T17:14:21.386268Z","shell.execute_reply":"2025-11-24T17:14:21.389807Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"Switch working directory to the directory where the data live.  You may need to edit this line.","metadata":{}},{"cell_type":"code","source":"entrain = TaggedCorpus(Path(\"ensup\"), Path(\"enraw\"))                               # all training\nensup =   TaggedCorpus(Path(\"ensup\"), tagset=entrain.tagset, vocab=entrain.vocab)  # supervised training\nendev =   TaggedCorpus(Path(\"endev\"), tagset=entrain.tagset, vocab=entrain.vocab)  # evaluation\nprint(f\"{len(entrain)=}  {len(ensup)=}  {len(endev)=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:14:21.391361Z","iopub.execute_input":"2025-11-24T17:14:21.392136Z","iopub.status.idle":"2025-11-24T17:14:21.886566Z","shell.execute_reply.started":"2025-11-24T17:14:21.392118Z","shell.execute_reply":"2025-11-24T17:14:21.885797Z"}},"outputs":[{"name":"stderr","text":"INFO : Read 191873 tokens from ensup, enraw\nINFO : Created 26 tag types\nINFO : Created 18461 word types\n","output_type":"stream"},{"name":"stdout","text":"len(entrain)=8064  len(ensup)=4051  len(endev)=996\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"known_vocab = TaggedCorpus(Path(\"ensup\")).vocab    # words seen with supervised tags; used in evaluation\nlog.info(f\"Tagset: f{list(entrain.tagset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:14:21.887379Z","iopub.execute_input":"2025-11-24T17:14:21.887644Z","iopub.status.idle":"2025-11-24T17:14:21.982697Z","shell.execute_reply.started":"2025-11-24T17:14:21.887622Z","shell.execute_reply":"2025-11-24T17:14:21.982047Z"}},"outputs":[{"name":"stderr","text":"INFO : Read 95936 tokens from ensup\nINFO : Created 26 tag types\nINFO : Created 12466 word types\nINFO : Tagset: f['W', 'J', 'N', 'C', 'V', 'I', 'D', ',', 'M', 'P', '.', 'E', 'R', '`', \"'\", 'T', '$', ':', '-', '#', 'S', 'F', 'U', 'L', '_EOS_TAG_', '_BOS_TAG_']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Make an HMM.  Let's do some pre-training to approximately maximize the\nregularized log-likelihood on supervised training data.  In other words, the\nprobabilities at the M step will just be supervised count ratios.\n\nOn each epoch, you will see two progress bars: first it collects counts from\nall the sentences (E step), and then after the M step, it evaluates the loss\nfunction, which is the (unregularized) cross-entropy on the training set.\n\nThe parameters don't actually matter during the E step because there are no\nhidden tags to impute.  The first M step will jump right to the optimal\nsolution.  The code will try a second epoch with the revised parameters, but\nthe result will be identical, so it will detect convergence and stop.\n\nWe arbitrarily choose λ=1 for our add-λ smoothing at the M step, but it would\nbe better to search for the best value of this hyperparameter.","metadata":{}},{"cell_type":"code","source":"log.info(\"*** Hidden Markov Model (HMM)\")\nhmm = HiddenMarkovModel(entrain.tagset, entrain.vocab)  # randomly initialized parameters  \nloss_sup = lambda model: model_cross_entropy(model, eval_corpus=ensup)\nhmm.train(corpus=ensup, loss=loss_sup, λ=1.0,\n          save_path=\"/kaggle/working/ensup_hmm.pkl\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:14:30.165683Z","iopub.execute_input":"2025-11-24T17:14:30.166269Z","iopub.status.idle":"2025-11-24T17:18:51.212667Z","shell.execute_reply.started":"2025-11-24T17:14:30.166247Z","shell.execute_reply":"2025-11-24T17:18:51.212101Z"}},"outputs":[{"name":"stderr","text":"INFO : *** Hidden Markov Model (HMM)\n100%|██████████| 4051/4051 [00:34<00:00, 118.42it/s]\nINFO : Cross-entropy: 12.6440 nats (= perplexity 309911.781)\n100%|██████████| 4051/4051 [01:19<00:00, 50.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"M-step updated A values:\n0: tensor([9.3953e-20, 3.7944e-02, 1.1729e-01, 1.1570e-02, 4.7851e-01, 1.4794e-02,\n        7.0937e-02, 6.3251e-03, 7.8292e-02, 1.2216e-01, 1.0616e-03, 3.1725e-03,\n        4.5349e-02, 9.3953e-20, 9.3953e-20, 1.0480e-02, 1.0546e-03, 9.3953e-20,\n        1.0523e-03, 9.3953e-20, 9.3953e-20, 9.3953e-20, 9.3953e-20, 9.3953e-20,\n        9.3953e-20, 0.0000e+00], device='cuda:0')\n1: tensor([7.4254e-04, 7.7334e-02, 7.0333e-01, 3.4510e-02, 8.6227e-03, 7.4773e-02,\n        2.6821e-03, 3.3887e-02, 2.9589e-04, 2.6703e-03, 2.3387e-02, 1.3252e-20,\n        4.7409e-03, 1.3418e-03, 4.1924e-03, 1.9703e-02, 2.4028e-03, 3.7428e-03,\n        1.6399e-03, 1.3252e-20, 1.3252e-20, 1.3252e-20, 1.3252e-20, 1.3252e-20,\n        1.3252e-20, 0.0000e+00], device='cuda:0')\n2: tensor([9.3278e-04, 9.4217e-04, 2.0974e-02, 4.1360e-03, 1.0905e-02, 1.4146e-02,\n        6.1158e-04, 1.0185e-02, 1.1621e-03, 2.9302e-03, 7.7825e-03, 5.5597e-06,\n        1.6216e-03, 1.2802e-04, 3.3420e-04, 2.1991e-03, 1.9465e-05, 8.4646e-04,\n        4.5811e-04, 2.4690e-22, 2.4690e-22, 1.3859e-05, 2.4690e-22, 2.4690e-22,\n        9.1967e-01, 0.0000e+00], device='cuda:0')\n3: tensor([3.0714e-04, 4.3693e-03, 2.2365e-02, 9.0255e-03, 3.8367e-03, 5.0621e-03,\n        3.7691e-03, 4.0434e-03, 2.6340e-04, 1.7074e-03, 3.0533e-03, 8.1524e-05,\n        1.5086e-03, 1.9446e-04, 9.0727e-22, 1.2406e-03, 6.6537e-04, 3.0550e-04,\n        5.0788e-04, 9.0727e-22, 9.0727e-22, 1.0211e-05, 9.0727e-22, 9.0727e-22,\n        9.3768e-01, 0.0000e+00], device='cuda:0')\n4: tensor([1.5120e-03, 2.0330e-02, 3.3942e-02, 8.6856e-03, 3.3974e-02, 3.8797e-02,\n        3.8820e-02, 5.9780e-03, 1.2063e-04, 1.5959e-02, 8.5279e-03, 1.8100e-04,\n        2.5012e-02, 1.7186e-03, 3.0134e-04, 1.6640e-02, 2.0049e-03, 7.6998e-04,\n        3.4356e-04, 6.0555e-05, 2.0171e-05, 2.0131e-05, 2.0036e-05, 1.7931e-21,\n        7.4626e-01, 0.0000e+00], device='cuda:0')\n5: tensor([7.9204e-03, 1.0060e-01, 3.1804e-01, 6.2349e-02, 3.4374e-02, 2.0269e-02,\n        3.1703e-01, 3.1869e-03, 9.9687e-05, 6.9865e-02, 3.1830e-03, 1.5887e-03,\n        1.8178e-02, 5.9296e-03, 1.0013e-04, 3.1789e-03, 3.2508e-02, 3.0078e-04,\n        2.9799e-04, 7.9874e-04, 8.8669e-21, 2.0017e-04, 8.8669e-21, 8.8669e-21,\n        8.8669e-21, 0.0000e+00], device='cuda:0')\n6: tensor([2.2669e-04, 7.1600e-02, 1.9961e-01, 6.3769e-03, 6.9994e-03, 3.6572e-03,\n        1.5044e-04, 5.6787e-04, 5.2855e-04, 2.2567e-04, 4.1716e-04, 3.3637e-21,\n        4.4616e-03, 1.7457e-03, 3.3637e-21, 1.8832e-04, 2.9104e-03, 2.2548e-04,\n        1.5109e-04, 1.1408e-04, 3.3637e-21, 1.5164e-04, 3.3637e-21, 3.3637e-21,\n        6.9969e-01, 0.0000e+00], device='cuda:0')\n7: tensor([7.4129e-03, 5.1301e-03, 2.4576e-02, 1.3999e-02, 1.8958e-02, 1.0030e-02,\n        1.5840e-02, 2.3842e-05, 1.1448e-03, 6.1159e-03, 2.1216e-21, 2.8788e-04,\n        6.4253e-03, 1.3188e-03, 7.1739e-03, 1.4268e-03, 1.9071e-04, 2.1216e-21,\n        2.1216e-21, 2.1216e-21, 2.1216e-21, 2.1216e-21, 2.3977e-05, 2.1216e-21,\n        8.7992e-01, 0.0000e+00], device='cuda:0')\n8: tensor([1.0196e-19, 1.0196e-19, 2.2973e-03, 1.0196e-19, 7.7653e-01, 1.0196e-19,\n        1.1435e-03, 3.4316e-03, 1.0196e-19, 7.9963e-03, 2.3033e-03, 1.0196e-19,\n        2.0056e-01, 2.3116e-03, 1.0196e-19, 2.2838e-03, 1.0196e-19, 1.0196e-19,\n        1.1404e-03, 1.0196e-19, 1.0196e-19, 1.0196e-19, 1.0196e-19, 1.0196e-19,\n        1.0196e-19, 0.0000e+00], device='cuda:0')\n9: tensor([1.7859e-04, 2.0795e-02, 5.5816e-02, 2.5565e-03, 6.0174e-02, 2.5576e-03,\n        2.8202e-03, 2.0983e-03, 1.0077e-02, 4.9129e-04, 3.3735e-03, 3.9863e-21,\n        5.7897e-03, 1.2108e-03, 4.5037e-05, 1.1204e-03, 5.8333e-04, 2.6828e-04,\n        4.5070e-05, 4.4784e-05, 3.9863e-21, 8.9356e-05, 3.9863e-21, 3.9863e-21,\n        8.2987e-01, 0.0000e+00], device='cuda:0')\n10: tensor([1.2789e-24, 1.4370e-08, 2.0195e-07, 1.2789e-24, 1.2789e-24, 1.2789e-24,\n        1.2789e-24, 1.2789e-24, 1.2789e-24, 1.4385e-08, 2.8924e-08, 1.2789e-24,\n        1.2789e-24, 1.2789e-24, 3.2931e-06, 1.2789e-24, 1.2789e-24, 2.8632e-08,\n        4.4544e-07, 1.2789e-24, 1.2789e-24, 1.2789e-24, 1.2789e-24, 1.2789e-24,\n        1.0000e+00, 0.0000e+00], device='cuda:0')\n11: tensor([9.7063e-19, 9.7063e-19, 9.7063e-19, 9.7063e-19, 8.9081e-01, 9.7063e-19,\n        9.7063e-19, 2.1926e-02, 5.4532e-02, 2.1883e-02, 9.7063e-19, 9.7063e-19,\n        1.0848e-02, 9.7063e-19, 9.7063e-19, 9.7063e-19, 9.7063e-19, 9.7063e-19,\n        9.7063e-19, 9.7063e-19, 9.7063e-19, 9.7063e-19, 9.7063e-19, 9.7063e-19,\n        9.7063e-19, 0.0000e+00], device='cuda:0')\n12: tensor([3.0778e-04, 7.3320e-03, 1.5682e-03, 2.8313e-03, 1.8259e-02, 8.6560e-03,\n        3.0658e-03, 5.3647e-03, 5.6327e-04, 7.8029e-04, 3.1803e-03, 3.4160e-05,\n        4.5305e-03, 1.2039e-04, 6.8077e-05, 1.6786e-03, 9.0256e-04, 2.3791e-04,\n        8.5076e-05, 3.4191e-05, 1.5151e-21, 1.5151e-21, 1.5151e-21, 1.5151e-21,\n        9.4040e-01, 0.0000e+00], device='cuda:0')\n13: tensor([2.1018e-02, 1.2684e-01, 2.3768e-01, 1.9442e-02, 8.0735e-02, 5.5432e-02,\n        1.5696e-01, 1.3326e-19, 8.9912e-03, 2.0876e-01, 1.3326e-19, 1.8103e-02,\n        4.5128e-02, 1.3326e-19, 1.3326e-19, 2.9713e-03, 1.3326e-19, 1.4964e-03,\n        1.4946e-03, 1.3326e-19, 1.3326e-19, 5.9727e-03, 8.9663e-03, 1.3326e-19,\n        1.3326e-19, 0.0000e+00], device='cuda:0')\n14: tensor([2.2172e-06, 2.4777e-06, 1.7206e-05, 7.6624e-06, 4.0615e-05, 1.2594e-05,\n        7.1114e-06, 2.1924e-23, 7.3503e-07, 1.8489e-05, 7.3979e-07, 2.1924e-23,\n        9.8683e-07, 2.4748e-07, 1.7264e-06, 2.6934e-06, 2.1924e-23, 1.4716e-06,\n        3.4398e-06, 2.1924e-23, 2.1924e-23, 2.1924e-23, 2.1924e-23, 2.1924e-23,\n        9.9988e-01, 0.0000e+00], device='cuda:0')\n15: tensor([2.3451e-03, 3.5015e-02, 1.0142e-01, 8.7093e-02, 5.6709e-01, 2.3523e-03,\n        1.0350e-01, 4.7040e-04, 4.1674e-20, 1.9690e-02, 1.8682e-03, 4.1674e-20,\n        7.9979e-03, 5.1610e-03, 4.1674e-20, 4.1674e-20, 6.3176e-02, 4.6917e-04,\n        4.6954e-04, 9.4046e-04, 4.1674e-20, 4.6729e-04, 4.6989e-04, 4.1674e-20,\n        4.1674e-20, 0.0000e+00], device='cuda:0')\n16: tensor([1.0581e-19, 8.3236e-03, 5.9486e-03, 9.8573e-01, 1.0581e-19, 1.0581e-19,\n        1.0581e-19, 1.0581e-19, 1.0581e-19, 1.0581e-19, 1.0581e-19, 1.0581e-19,\n        1.0581e-19, 1.0581e-19, 1.0581e-19, 1.0581e-19, 1.0581e-19, 1.0581e-19,\n        1.0581e-19, 1.0581e-19, 1.0581e-19, 1.0581e-19, 1.0581e-19, 1.0581e-19,\n        1.0581e-19, 0.0000e+00], device='cuda:0')\n17: tensor([9.7275e-05, 2.9154e-04, 1.0150e-03, 9.1416e-04, 4.5338e-04, 2.9056e-04,\n        5.9350e-04, 9.6055e-22, 7.5724e-05, 3.1443e-04, 9.6055e-22, 1.0840e-05,\n        2.4704e-04, 3.6898e-04, 9.6055e-22, 5.3667e-05, 1.1877e-04, 3.2426e-05,\n        1.0775e-05, 9.6055e-22, 9.6055e-22, 9.6055e-22, 1.0747e-05, 9.6055e-22,\n        9.9510e-01, 0.0000e+00], device='cuda:0')\n18: tensor([9.4481e-06, 1.6488e-05, 1.7914e-04, 4.4871e-05, 4.9378e-05, 6.1736e-05,\n        2.8244e-05, 7.5694e-05, 2.3542e-06, 7.0648e-06, 8.0719e-05, 2.1021e-22,\n        1.8983e-05, 2.1415e-05, 2.1021e-22, 4.7278e-06, 7.7968e-05, 1.8885e-05,\n        2.3640e-06, 2.1021e-22, 2.1021e-22, 7.1207e-06, 2.1021e-22, 2.1021e-22,\n        9.9929e-01, 0.0000e+00], device='cuda:0')\n19: tensor([4.0291e-18, 4.0291e-18, 4.0291e-18, 8.6426e-01, 4.0291e-18, 4.0291e-18,\n        4.0291e-18, 4.0291e-18, 4.0291e-18, 4.0291e-18, 4.0291e-18, 4.0291e-18,\n        4.0291e-18, 4.0291e-18, 4.0291e-18, 4.0291e-18, 4.0291e-18, 4.0291e-18,\n        4.0291e-18, 1.3574e-01, 4.0291e-18, 4.0291e-18, 4.0291e-18, 4.0291e-18,\n        4.0291e-18, 0.0000e+00], device='cuda:0')\n20: tensor([8.9109e-17, 8.9109e-17, 8.9109e-17, 8.9109e-17, 8.9109e-17, 8.9109e-17,\n        8.9109e-17, 8.9109e-17, 8.9109e-17, 8.9109e-17, 8.9109e-17, 8.9109e-17,\n        8.9109e-17, 8.9109e-17, 8.9109e-17, 8.9109e-17, 8.9109e-17, 1.0000e+00,\n        8.9109e-17, 8.9109e-17, 8.9109e-17, 8.9109e-17, 8.9109e-17, 8.9109e-17,\n        8.9109e-17, 0.0000e+00], device='cuda:0')\n21: tensor([2.1162e-18, 2.1162e-18, 3.5719e-01, 2.1162e-18, 2.1162e-18, 2.3718e-02,\n        2.1162e-18, 7.1182e-02, 2.1162e-18, 2.1162e-18, 2.1162e-18, 2.1162e-18,\n        2.1162e-18, 2.1162e-18, 9.5288e-02, 2.1162e-18, 2.1162e-18, 2.1162e-18,\n        2.3951e-02, 2.1162e-18, 2.1162e-18, 4.2867e-01, 2.1162e-18, 2.1162e-18,\n        2.1162e-18, 0.0000e+00], device='cuda:0')\n22: tensor([7.4065e-18, 7.4065e-18, 8.3456e-02, 7.4065e-18, 7.4065e-18, 7.4065e-18,\n        7.4065e-18, 4.9830e-01, 7.4065e-18, 8.3809e-02, 2.5127e-01, 7.4065e-18,\n        7.4065e-18, 7.4065e-18, 7.4065e-18, 8.3170e-02, 7.4065e-18, 7.4065e-18,\n        7.4065e-18, 7.4065e-18, 7.4065e-18, 7.4065e-18, 7.4065e-18, 7.4065e-18,\n        7.4065e-18, 0.0000e+00], device='cuda:0')\n23: tensor([4.4350e-17, 4.4350e-17, 2.3425e-04, 4.4350e-17, 4.9882e-01, 4.4350e-17,\n        4.4350e-17, 5.0095e-01, 4.4350e-17, 4.4350e-17, 4.4350e-17, 4.4350e-17,\n        4.4350e-17, 4.4350e-17, 4.4350e-17, 4.4350e-17, 4.4350e-17, 4.4350e-17,\n        4.4350e-17, 4.4350e-17, 4.4350e-17, 4.4350e-17, 4.4350e-17, 4.4350e-17,\n        4.4350e-17, 0.0000e+00], device='cuda:0')\n24: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], device='cuda:0')\n25: tensor([1.0821e-02, 4.2967e-02, 2.8832e-01, 6.7361e-02, 1.9709e-02, 1.4451e-01,\n        2.0448e-01, 2.2025e-20, 4.9258e-04, 8.1669e-02, 2.2025e-20, 6.6901e-03,\n        5.9399e-02, 6.4184e-02, 2.2025e-20, 2.2313e-03, 2.2025e-20, 2.7196e-03,\n        3.1968e-03, 2.2025e-20, 2.2025e-20, 2.4783e-04, 4.9617e-04, 4.9437e-04,\n        2.2025e-20, 0.0000e+00], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4051/4051 [00:33<00:00, 119.43it/s]\nINFO : Cross-entropy: 7.9735 nats (= perplexity 2903.063)\n100%|██████████| 4051/4051 [01:18<00:00, 51.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"M-step updated A values:\n0: tensor([2.9345e-23, 1.1219e-03, 2.6877e-03, 6.7343e-04, 4.0064e-01, 1.9617e-03,\n        2.8489e-01, 5.7740e-03, 1.5882e-01, 1.2369e-01, 1.6008e-04, 8.4995e-04,\n        2.6478e-03, 2.9345e-23, 2.9345e-23, 1.5855e-02, 1.5741e-04, 2.9345e-23,\n        6.9611e-05, 2.9345e-23, 2.9345e-23, 2.9345e-23, 2.9345e-23, 2.9345e-23,\n        2.9345e-23, 0.0000e+00], device='cuda:0')\n1: tensor([1.7625e-05, 5.6893e-03, 1.5978e-01, 4.2607e-02, 2.4524e-04, 1.3938e-01,\n        4.8374e-04, 3.6069e-01, 9.7988e-07, 1.4906e-04, 1.5997e-01, 9.0042e-24,\n        7.4469e-05, 5.4440e-04, 5.0978e-03, 1.2165e-01, 1.6512e-03, 1.6228e-03,\n        3.4855e-04, 9.0042e-24, 9.0042e-24, 9.0042e-24, 9.0042e-24, 9.0042e-24,\n        9.0042e-24, 0.0000e+00], device='cuda:0')\n2: tensor([6.0873e-04, 2.3061e-05, 1.5660e-03, 1.2658e-02, 8.1598e-03, 1.0193e-01,\n        3.9546e-04, 4.1846e-01, 1.0041e-03, 6.7955e-03, 2.3962e-01, 7.3366e-08,\n        1.3747e-04, 5.9901e-05, 4.2036e-04, 1.9493e-02, 1.0774e-06, 1.0689e-03,\n        3.3867e-04, 2.1681e-24, 2.1681e-24, 7.7896e-08, 2.1681e-24, 2.1681e-24,\n        1.8726e-01, 0.0000e+00], device='cuda:0')\n3: tensor([1.2897e-04, 1.2656e-03, 2.6254e-02, 6.0268e-02, 1.3579e-03, 2.8832e-02,\n        4.7530e-02, 1.8086e-01, 1.5649e-04, 2.1015e-03, 1.0034e-01, 4.3024e-05,\n        2.6448e-04, 4.0098e-04, 2.1677e-23, 1.6839e-02, 4.7685e-03, 3.6489e-04,\n        1.2942e-03, 2.1677e-23, 2.1677e-23, 1.6394e-07, 2.1677e-23, 2.1677e-23,\n        5.2693e-01, 0.0000e+00], device='cuda:0')\n4: tensor([1.5852e-04, 1.4692e-03, 1.2535e-03, 3.6480e-03, 3.4024e-03, 8.3513e-02,\n        4.7026e-01, 3.4465e-02, 3.6909e-06, 1.7206e-02, 6.6195e-02, 1.8623e-05,\n        1.7790e-02, 2.5916e-03, 7.9374e-05, 2.6493e-01, 3.7175e-03, 1.9193e-04,\n        3.7449e-05, 3.5384e-06, 3.9289e-07, 5.6015e-08, 3.2520e-08, 3.7567e-24,\n        2.9071e-02, 0.0000e+00], device='cuda:0')\n5: tensor([2.6855e-04, 1.0415e-03, 2.5213e-03, 7.2832e-04, 3.9438e-05, 1.1130e-03,\n        9.5956e-01, 2.5223e-04, 2.8210e-10, 7.8483e-03, 2.4195e-04, 3.6903e-05,\n        1.0691e-04, 8.0822e-04, 2.3857e-07, 2.5019e-04, 2.5170e-02, 7.7635e-07,\n        6.7980e-07, 1.5804e-05, 4.7704e-25, 9.4304e-08, 4.7704e-25, 4.7704e-25,\n        4.7704e-25, 0.0000e+00], device='cuda:0')\n6: tensor([8.3499e-05, 1.4989e-01, 4.8489e-01, 4.9913e-03, 4.7105e-03, 2.1781e-02,\n        6.1456e-05, 2.7981e-03, 2.9282e-04, 2.3262e-05, 1.3594e-03, 6.3358e-23,\n        1.5086e-03, 2.4938e-02, 6.3358e-23, 3.0757e-04, 7.2219e-02, 1.3297e-04,\n        4.9478e-05, 1.1242e-04, 6.3358e-23, 1.1861e-05, 6.3358e-23, 6.3358e-23,\n        2.2985e-01, 0.0000e+00], device='cuda:0')\n7: tensor([4.9711e-02, 4.5594e-04, 4.5177e-03, 1.0269e-01, 2.0267e-02, 2.2208e-02,\n        3.7188e-01, 2.5045e-06, 1.2320e-03, 1.1196e-02, 2.0261e-23, 2.1300e-04,\n        2.0302e-03, 6.7126e-03, 2.1293e-01, 8.9421e-03, 1.5722e-04, 2.0261e-23,\n        2.0261e-23, 2.0261e-23, 2.0261e-23, 2.0261e-23, 2.0989e-07, 2.0261e-23,\n        1.8486e-01, 0.0000e+00], device='cuda:0')\n8: tensor([2.4766e-23, 2.4766e-23, 2.5487e-07, 2.4766e-23, 7.6488e-01, 2.4766e-23,\n        3.5874e-05, 1.3219e-03, 2.4766e-23, 1.7071e-04, 5.4063e-04, 2.4766e-23,\n        2.3183e-01, 5.7323e-04, 2.4766e-23, 5.8320e-04, 2.4766e-23, 2.4766e-23,\n        6.3667e-05, 2.4766e-23, 2.4766e-23, 2.4766e-23, 2.4766e-23, 2.4766e-23,\n        2.4766e-23, 0.0000e+00], device='cuda:0')\n9: tensor([1.7852e-05, 1.2086e-02, 1.6632e-02, 3.9733e-03, 3.9773e-01, 3.1686e-03,\n        1.6500e-02, 3.4107e-02, 1.1801e-01, 1.3844e-04, 8.3383e-02, 6.6703e-23,\n        4.2555e-03, 1.0527e-02, 1.5004e-05, 9.6327e-03, 2.5728e-03, 2.3165e-04,\n        8.2289e-07, 1.5488e-05, 6.6703e-23, 8.8293e-06, 6.6703e-23, 6.6703e-23,\n        2.8700e-01, 0.0000e+00], device='cuda:0')\n10: tensor([5.2079e-26, 5.7603e-16, 1.5453e-13, 5.2079e-26, 5.2079e-26, 5.2079e-26,\n        5.2079e-26, 5.2079e-26, 5.2079e-26, 2.0431e-14, 1.5480e-11, 5.2079e-26,\n        5.2079e-26, 5.2079e-26, 1.8692e-07, 5.2079e-26, 5.2079e-26, 7.8489e-12,\n        1.6812e-09, 5.2079e-26, 5.2079e-26, 5.2079e-26, 5.2079e-26, 5.2079e-26,\n        1.0000e+00, 0.0000e+00], device='cuda:0')\n11: tensor([7.5975e-23, 7.5975e-23, 7.5975e-23, 7.5975e-23, 9.5725e-01, 7.5975e-23,\n        7.5975e-23, 1.7274e-02, 2.1505e-02, 3.9494e-03, 7.5975e-23, 7.5975e-23,\n        2.0697e-05, 7.5975e-23, 7.5975e-23, 7.5975e-23, 7.5975e-23, 7.5975e-23,\n        7.5975e-23, 7.5975e-23, 7.5975e-23, 7.5975e-23, 7.5975e-23, 7.5975e-23,\n        7.5975e-23, 0.0000e+00], device='cuda:0')\n12: tensor([6.3169e-05, 1.3614e-03, 2.2035e-05, 2.9222e-03, 1.7876e-02, 4.7094e-02,\n        2.3827e-02, 2.8893e-01, 5.9532e-04, 3.2373e-04, 9.6455e-02, 3.4282e-06,\n        1.8199e-03, 1.1996e-04, 4.4851e-05, 2.8254e-02, 7.7251e-03, 1.7919e-04,\n        2.1141e-05, 1.1692e-05, 3.2977e-23, 3.2977e-23, 3.2977e-23, 3.2977e-23,\n        4.8235e-01, 0.0000e+00], device='cuda:0')\n13: tensor([1.7576e-03, 6.2696e-03, 3.0647e-03, 6.0473e-03, 1.1480e-02, 1.2534e-02,\n        6.3614e-01, 6.5063e-23, 3.5189e-03, 2.7840e-01, 6.5063e-23, 3.1330e-02,\n        3.9164e-03, 6.5063e-23, 6.5063e-23, 1.9934e-03, 6.5063e-23, 1.0998e-06,\n        2.3016e-04, 6.5063e-23, 6.5063e-23, 2.8782e-04, 3.0246e-03, 6.5063e-23,\n        6.5063e-23, 0.0000e+00], device='cuda:0')\n14: tensor([1.7289e-08, 4.6852e-10, 3.2354e-08, 2.2325e-07, 7.1065e-07, 2.5716e-07,\n        3.3909e-07, 8.7743e-25, 1.2664e-09, 3.7997e-07, 6.7009e-09, 8.7743e-25,\n        1.3557e-10, 1.0871e-09, 5.2960e-08, 1.3403e-07, 8.7743e-25, 2.0391e-08,\n        8.5726e-08, 8.7743e-25, 8.7743e-25, 8.7743e-25, 8.7743e-25, 8.7743e-25,\n        1.0000e+00, 0.0000e+00], device='cuda:0')\n15: tensor([7.9600e-05, 5.7852e-04, 1.6093e-03, 3.1821e-03, 1.3997e-01, 9.1593e-06,\n        4.3549e-01, 2.3614e-05, 9.6822e-24, 2.4209e-03, 3.7179e-04, 9.6822e-24,\n        6.3941e-05, 2.2694e-03, 9.6822e-24, 9.6822e-24, 4.1383e-01, 5.1312e-08,\n        1.2444e-06, 9.4421e-05, 9.6822e-24, 5.5851e-07, 1.9657e-06, 9.6822e-24,\n        9.6822e-24, 0.0000e+00], device='cuda:0')\n16: tensor([1.8527e-22, 8.3085e-06, 1.3823e-06, 9.9999e-01, 1.8527e-22, 1.8527e-22,\n        1.8527e-22, 1.8527e-22, 1.8527e-22, 1.8527e-22, 1.8527e-22, 1.8527e-22,\n        1.8527e-22, 1.8527e-22, 1.8527e-22, 1.8527e-22, 1.8527e-22, 1.8527e-22,\n        1.8527e-22, 1.8527e-22, 1.8527e-22, 1.8527e-22, 1.8527e-22, 1.8527e-22,\n        1.8527e-22, 0.0000e+00], device='cuda:0')\n17: tensor([3.3550e-05, 5.5013e-06, 1.0881e-05, 1.2012e-03, 5.8852e-05, 4.3944e-05,\n        1.5497e-03, 3.8547e-23, 8.0517e-06, 1.0067e-04, 3.8547e-23, 1.2715e-06,\n        1.5641e-05, 2.2837e-03, 3.8547e-23, 5.3327e-05, 2.5614e-04, 6.5934e-06,\n        9.3624e-07, 3.8547e-23, 3.8547e-23, 3.8547e-23, 1.7898e-07, 3.8547e-23,\n        9.9437e-01, 0.0000e+00], device='cuda:0')\n18: tensor([3.8247e-07, 1.8475e-08, 6.6604e-07, 8.5759e-06, 8.4246e-07, 4.8651e-06,\n        2.4163e-06, 1.1014e-04, 3.3314e-08, 1.9518e-08, 1.2368e-04, 8.7700e-24,\n        4.9920e-08, 7.5556e-06, 8.7700e-24, 4.2753e-07, 1.0785e-04, 2.8698e-06,\n        4.6735e-08, 8.7700e-24, 8.7700e-24, 6.9380e-08, 8.7700e-24, 8.7700e-24,\n        9.9963e-01, 0.0000e+00], device='cuda:0')\n19: tensor([3.2175e-22, 3.2175e-22, 3.2175e-22, 3.2070e-01, 3.2175e-22, 3.2175e-22,\n        3.2175e-22, 3.2175e-22, 3.2175e-22, 3.2175e-22, 3.2175e-22, 3.2175e-22,\n        3.2175e-22, 3.2175e-22, 3.2175e-22, 3.2175e-22, 3.2175e-22, 3.2175e-22,\n        3.2175e-22, 6.7930e-01, 3.2175e-22, 3.2175e-22, 3.2175e-22, 3.2175e-22,\n        3.2175e-22, 0.0000e+00], device='cuda:0')\n20: tensor([3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22,\n        3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22,\n        3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 1.0000e+00,\n        3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22,\n        3.7996e-22, 0.0000e+00], device='cuda:0')\n21: tensor([2.0726e-22, 2.0726e-22, 4.4307e-03, 2.0726e-22, 2.0726e-22, 1.1649e-03,\n        2.0726e-22, 2.2948e-01, 2.0726e-22, 2.0726e-22, 2.0726e-22, 2.0726e-22,\n        2.0726e-22, 2.0726e-22, 2.0479e-01, 2.0726e-22, 2.0726e-22, 2.0726e-22,\n        1.1750e-02, 2.0726e-22, 2.0726e-22, 5.4839e-01, 2.0726e-22, 2.0726e-22,\n        2.0726e-22, 0.0000e+00], device='cuda:0')\n22: tensor([5.0496e-23, 5.0496e-23, 2.2653e-06, 5.0496e-23, 5.0496e-23, 5.0496e-23,\n        5.0496e-23, 7.8274e-01, 5.0496e-23, 1.1542e-05, 1.9559e-01, 5.0496e-23,\n        5.0496e-23, 5.0496e-23, 5.0496e-23, 2.1652e-02, 5.0496e-23, 5.0496e-23,\n        5.0496e-23, 5.0496e-23, 5.0496e-23, 5.0496e-23, 5.0496e-23, 5.0496e-23,\n        5.0496e-23, 0.0000e+00], device='cuda:0')\n23: tensor([3.8405e-22, 3.8405e-22, 4.2918e-13, 3.8405e-22, 2.5203e-03, 3.8405e-22,\n        3.8405e-22, 9.9748e-01, 3.8405e-22, 3.8405e-22, 3.8405e-22, 3.8405e-22,\n        3.8405e-22, 3.8405e-22, 3.8405e-22, 3.8405e-22, 3.8405e-22, 3.8405e-22,\n        3.8405e-22, 3.8405e-22, 3.8405e-22, 3.8405e-22, 3.8405e-22, 3.8405e-22,\n        3.8405e-22, 0.0000e+00], device='cuda:0')\n24: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], device='cuda:0')\n25: tensor([3.2129e-04, 2.1015e-04, 2.4495e-02, 1.2860e-02, 2.9401e-05, 2.7576e-02,\n        3.4039e-01, 6.9109e-24, 2.0237e-08, 2.0617e-02, 6.9109e-24, 2.6733e-03,\n        9.4473e-04, 5.6886e-01, 6.9109e-24, 3.7037e-06, 6.9109e-24, 3.4630e-04,\n        6.4742e-04, 6.9109e-24, 6.9109e-24, 2.1143e-07, 5.9260e-06, 1.7709e-05,\n        6.9109e-24, 0.0000e+00], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4051/4051 [00:33<00:00, 120.02it/s]\nINFO : Cross-entropy: 8.1743 nats (= perplexity 3548.742)\nINFO : Saved model to /kaggle/working/ensup_hmm.pkl\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Now let's throw in the unsupervised training data as well, and continue\ntraining as before, in order to increase the regularized log-likelihood on\nthis larger, semi-supervised training set.  It's now the *incomplete-data*\nlog-likelihood.\n\nThis time, we'll use a different evaluation loss function: we'll stop when the\n*tagging error rate* on a held-out dev set stops getting better.  Also, the\nimplementation of this loss function (`viterbi_error_rate`) includes a helpful\nside effect: it logs the *cross-entropy* on the held-out dataset as well, just\nfor your information.\n\nWe hope that held-out tagging accuracy will go up for a little bit before it\ngoes down again (see Merialdo 1994). (Log-likelihood on training data will\ncontinue to improve, and that improvement may generalize to held-out\ncross-entropy.  But getting accuracy to increase is harder.)","metadata":{}},{"cell_type":"code","source":"hmm = HiddenMarkovModel.load(\"/kaggle/working/ensup_hmm.pkl\")  # reset to supervised model (in case you're re-executing this bit)\nloss_dev = lambda model: viterbi_error_rate(model, eval_corpus=endev, \n                                            known_vocab=known_vocab)\nhmm.train(corpus=entrain, loss=loss_dev, λ=1.0,\n          save_path=\"/kaggle/working/entrain_hmm.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:18:51.213742Z","iopub.execute_input":"2025-11-24T17:18:51.213966Z","iopub.status.idle":"2025-11-24T17:18:51.319146Z","shell.execute_reply.started":"2025-11-24T17:18:51.213949Z","shell.execute_reply":"2025-11-24T17:18:51.318101Z"}},"outputs":[{"name":"stderr","text":"INFO : Loaded model from /kaggle/working/ensup_hmm.pkl\n  0%|          | 0/996 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/782274903.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m loss_dev = lambda model: viterbi_error_rate(model, eval_corpus=endev, \n\u001b[1;32m      3\u001b[0m                                             known_vocab=known_vocab)\n\u001b[0;32m----> 4\u001b[0;31m hmm.train(corpus=entrain, loss=loss_dev, λ=1.0,\n\u001b[0m\u001b[1;32m      5\u001b[0m           save_path=\"/kaggle/working/entrain_hmm.pkl\")\n","\u001b[0;32m/kaggle/input/testing-run/hmm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus, loss, λ, tolerance, max_steps, save_path)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# mark start of training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mdev_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;31m# evaluate the model at the start of training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mold_dev_loss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_loss\u001b[0m     \u001b[0;31m# loss from the last epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m   \u001b[0;31m# total number of sentences the model has been trained on so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_48/782274903.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHiddenMarkovModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/ensup_hmm.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# reset to supervised model (in case you're re-executing this bit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m loss_dev = lambda model: viterbi_error_rate(model, eval_corpus=endev, \n\u001b[0m\u001b[1;32m      3\u001b[0m                                             known_vocab=known_vocab)\n\u001b[1;32m      4\u001b[0m hmm.train(corpus=entrain, loss=loss_dev, λ=1.0,\n\u001b[1;32m      5\u001b[0m           save_path=\"/kaggle/working/entrain_hmm.pkl\")\n","\u001b[0;32m/kaggle/input/testing-run/eval.py\u001b[0m in \u001b[0;36mviterbi_error_rate\u001b[0;34m(model, eval_corpus, known_vocab, show_cross_entropy)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshow_cross_entropy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mmodel_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_corpus\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# call this for its side effect (logging)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     return tagger_error_rate(viterbi_tagger(model, eval_corpus),\n\u001b[1;32m     51\u001b[0m                              \u001b[0meval_corpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/testing-run/eval.py\u001b[0m in \u001b[0;36mmodel_cross_entropy\u001b[0;34m(model, eval_corpus)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtoken_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mlogprob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtoken_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m    \u001b[0;31m# count EOS but not BOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mcross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogprob\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtoken_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/testing-run/hmm.py\u001b[0m in \u001b[0;36mlogprob\u001b[0;34m(self, sentence, corpus)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# Integerize the words and tags of the given sentence, which came from the given corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0misent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_integerize_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mE_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIntegerizedSentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/testing-run/hmm.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(self, isent)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0malpha_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0me_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"],"ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_mm)","output_type":"error"}],"execution_count":14},{"cell_type":"markdown","source":"You can also retry the above workflow where you start with a worse supervised\nmodel (like Merialdo).  Does EM help more in that case?  It's easiest to rerun\nexactly the code above, but first make the `ensup` file smaller by copying\n`ensup-tiny` over it.  `ensup-tiny` is only 25 sentences (that happen to cover\nall tags in `endev`).  Back up your old `ensup` and your old `*.pkl` models\nbefore you do this.","metadata":{}},{"cell_type":"markdown","source":"More detailed look at the first 10 sentences in the held-out corpus,\nincluding Viterbi tagging.","metadata":{}},{"cell_type":"code","source":"def look_at_your_data(model, dev, N):\n    for m, sentence in enumerate(dev):\n        if m >= N: break\n        viterbi = model.viterbi_tagging(sentence.desupervise(), endev)\n        counts = eval_tagging(predicted=viterbi, gold=sentence, \n                              known_vocab=known_vocab)\n        num = counts['NUM', 'ALL']\n        denom = counts['DENOM', 'ALL']\n        \n        log.info(f\"Gold:    {sentence}\")\n        log.info(f\"Viterbi: {viterbi}\")\n        log.info(f\"Loss:    {denom - num}/{denom}\")\n        xent = -model.logprob(sentence, endev) / len(sentence)  # measured in nats\n        log.info(f\"Cross-entropy: {xent/math.log(2)} nats (= perplexity {math.exp(xent)})\\n---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:18:51.319459Z","iopub.status.idle":"2025-11-24T17:18:51.319678Z","shell.execute_reply.started":"2025-11-24T17:18:51.319574Z","shell.execute_reply":"2025-11-24T17:18:51.319585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"look_at_your_data(hmm, endev, 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:18:51.320315Z","iopub.status.idle":"2025-11-24T17:18:51.320507Z","shell.execute_reply.started":"2025-11-24T17:18:51.320415Z","shell.execute_reply":"2025-11-24T17:18:51.320424Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now let's try supervised training of a CRF (this doesn't use the unsupervised\npart of the data, so it is comparable to the supervised pre-training we did\nfor the HMM).  We will use SGD to approximately maximize the regularized\nlog-likelihood. \n\nAs with the semi-supervised HMM training, we'll periodically evaluate the\ntagging accuracy (and also print the cross-entropy) on a held-out dev set.\nWe use the default `eval_interval` and `tolerance`.  If you want to stop\nsooner, then you could increase the `tolerance` so the training method decides\nsooner that it has converged.\n\nWe arbitrarily choose reg = 1.0 for L2 regularization, learning rate = 0.05,\nand a minibatch size of 10, but it would be better to search for the best\nvalue of these hyperparameters.\n\nNote that the logger reports the CRF's *conditional* cross-entropy, log p(tags\n| words) / n.  This is much lower than the HMM's *joint* cross-entropy log\np(tags, words) / n, but that doesn't mean the CRF is worse at tagging.  The\nCRF is just predicting less information.","metadata":{}},{"cell_type":"code","source":"log.info(\"*** Conditional Random Field (CRF)\\n\")\ncrf = ConditionalRandomField(entrain.tagset, entrain.vocab)  # randomly initialized parameters  \ncrf.train(corpus=ensup, loss=loss_dev, reg=1.0, lr=0.05, minibatch_size=10,\n          save_path=\"/kaggle/working/ensup_crf.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T15:15:16.130735Z","iopub.execute_input":"2025-11-24T15:15:16.130967Z","iopub.status.idle":"2025-11-24T15:46:42.800849Z","shell.execute_reply.started":"2025-11-24T15:15:16.130949Z","shell.execute_reply":"2025-11-24T15:46:42.799785Z"}},"outputs":[{"name":"stderr","text":"INFO : *** Conditional Random Field (CRF)\n\n100%|██████████| 996/996 [00:04<00:00, 212.53it/s]\nINFO : Cross-entropy: 3.0501 nats (= perplexity 21.118)\n100%|██████████| 996/996 [02:56<00:00,  5.65it/s]\nINFO : Tagging accuracy: all: 5.800%, known: 6.245%, seen: 3.704%, novel: 0.198%\n100%|██████████| 500/500 [00:07<00:00, 70.98it/s]\n100%|██████████| 996/996 [00:04<00:00, 216.99it/s]\nINFO : Cross-entropy: 2.9038 nats (= perplexity 18.244)\n100%|██████████| 996/996 [02:55<00:00,  5.68it/s]\nINFO : Tagging accuracy: all: 33.513%, known: 31.336%, seen: 54.209%, novel: 56.803%\n  1%|          | 6/500 [00:00<00:09, 53.11it/s]INFO : Saved model to /kaggle/working/ensup_crf-510.pkl\n100%|██████████| 500/500 [00:07<00:00, 69.81it/s]\n100%|██████████| 996/996 [00:04<00:00, 211.21it/s]\nINFO : Cross-entropy: 2.8704 nats (= perplexity 17.645)\n100%|██████████| 996/996 [02:56<00:00,  5.63it/s]\nINFO : Tagging accuracy: all: 33.722%, known: 31.564%, seen: 54.209%, novel: 56.803%\n100%|██████████| 500/500 [00:07<00:00, 67.61it/s]\n100%|██████████| 996/996 [00:04<00:00, 212.83it/s]\nINFO : Cross-entropy: 2.8491 nats (= perplexity 17.272)\n100%|██████████| 996/996 [02:57<00:00,  5.62it/s]\nINFO : Tagging accuracy: all: 33.722%, known: 31.564%, seen: 54.209%, novel: 56.803%\n  2%|▏         | 9/500 [00:00<00:05, 88.37it/s]INFO : Saved model to /kaggle/working/ensup_crf-1510.pkl\n100%|██████████| 500/500 [00:06<00:00, 72.75it/s]\n100%|██████████| 996/996 [00:04<00:00, 215.15it/s]\nINFO : Cross-entropy: 2.8265 nats (= perplexity 16.887)\n100%|██████████| 996/996 [02:57<00:00,  5.62it/s]\nINFO : Tagging accuracy: all: 33.738%, known: 31.583%, seen: 54.209%, novel: 56.803%\n100%|██████████| 500/500 [00:08<00:00, 62.20it/s]\n100%|██████████| 996/996 [00:04<00:00, 211.18it/s]\nINFO : Cross-entropy: 2.8153 nats (= perplexity 16.698)\n100%|██████████| 996/996 [02:58<00:00,  5.59it/s]\nINFO : Tagging accuracy: all: 33.738%, known: 31.583%, seen: 54.209%, novel: 56.803%\n  2%|▏         | 9/500 [00:00<00:11, 43.46it/s]INFO : Saved model to /kaggle/working/ensup_crf-2510.pkl\n100%|██████████| 500/500 [00:07<00:00, 64.37it/s]\n100%|██████████| 996/996 [00:04<00:00, 212.56it/s]\nINFO : Cross-entropy: 2.8054 nats (= perplexity 16.534)\n100%|██████████| 996/996 [02:57<00:00,  5.60it/s]\nINFO : Tagging accuracy: all: 33.738%, known: 31.583%, seen: 54.209%, novel: 56.803%\n100%|██████████| 500/500 [00:07<00:00, 66.36it/s]\n100%|██████████| 996/996 [00:04<00:00, 215.23it/s]\nINFO : Cross-entropy: 2.7968 nats (= perplexity 16.391)\n100%|██████████| 996/996 [02:57<00:00,  5.62it/s]\nINFO : Tagging accuracy: all: 33.738%, known: 31.583%, seen: 54.209%, novel: 56.803%\n  1%|          | 6/500 [00:00<00:09, 49.83it/s]INFO : Saved model to /kaggle/working/ensup_crf-3510.pkl\n100%|██████████| 500/500 [00:07<00:00, 67.00it/s]\n100%|██████████| 996/996 [00:04<00:00, 216.28it/s]\nINFO : Cross-entropy: 2.7925 nats (= perplexity 16.321)\n100%|██████████| 996/996 [02:57<00:00,  5.62it/s]\nINFO : Tagging accuracy: all: 33.738%, known: 31.583%, seen: 54.209%, novel: 56.803%\n100%|██████████| 500/500 [00:07<00:00, 65.19it/s]\n100%|██████████| 996/996 [00:04<00:00, 212.87it/s]\nINFO : Cross-entropy: 2.7851 nats (= perplexity 16.202)\n100%|██████████| 996/996 [02:59<00:00,  5.56it/s]\nINFO : Tagging accuracy: all: 33.738%, known: 31.583%, seen: 54.209%, novel: 56.803%\nINFO : Saved model to /kaggle/working/ensup_crf.pkl\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"Let's examine how the CRF does on individual sentences. \n(Do you see any error patterns here that would inspire additional CRF features?)","metadata":{}},{"cell_type":"code","source":"look_at_your_data(crf, endev, 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T15:47:18.751198Z","iopub.execute_input":"2025-11-24T15:47:18.751579Z","iopub.status.idle":"2025-11-24T15:47:20.690625Z","shell.execute_reply.started":"2025-11-24T15:47:18.751558Z","shell.execute_reply":"2025-11-24T15:47:20.689698Z"}},"outputs":[{"name":"stderr","text":"INFO : Gold:    ``/` We/P 're/V strongly/R _OOV_/V that/I anyone/N who/W has/V eaten/V in/I the/D cafeteria/N this/D month/N have/V the/D shot/N ,/, ''/' Mr./N Mattausch/N added/V ,/, ``/` and/C that/D means/V virtually/R everyone/N who/W works/V here/R ./.\nINFO : Viterbi: ``/N We/N 're/N strongly/N _OOV_/N that/N anyone/N who/N has/N eaten/N in/N the/N cafeteria/N this/N month/N have/N the/N shot/N ,/N ''/N Mr./N Mattausch/N added/N ,/N ``/N and/N that/N means/N virtually/N everyone/N who/N works/N here/N ./.\nINFO : Loss:    26/34\nINFO : Cross-entropy: 4.020375211200853 nats (= perplexity 16.227571539277715)\n---\nINFO : Gold:    I/P was/V _OOV_/V to/T read/V the/D _OOV_/N of/I facts/N in/I your/P Oct./N 13/C editorial/N ``/` _OOV_/N 's/P _OOV_/N _OOV_/N ./. ''/'\nINFO : Viterbi: I/N was/N _OOV_/N to/N read/N the/N _OOV_/N of/N facts/N in/N your/N Oct./N 13/N editorial/N ``/N _OOV_/N 's/N _OOV_/N _OOV_/N ./. ''/.\nINFO : Loss:    13/21\nINFO : Cross-entropy: 3.8831678415781927 nats (= perplexity 14.755366410094656)\n---\nINFO : Gold:    It/P is/V the/D _OOV_/J guerrillas/N who/W are/V aligned/V with/I the/D drug/N traffickers/N ,/, not/R the/D left/J _OOV_/N ./.\nINFO : Viterbi: It/N is/N the/N _OOV_/N guerrillas/N who/N are/N aligned/N with/N the/N drug/N traffickers/N ,/N not/N the/N left/N _OOV_/N ./.\nINFO : Loss:    13/18\nINFO : Cross-entropy: 3.693675975502884 nats (= perplexity 12.93919514731451)\n---\nINFO : Gold:    This/D information/N was/V _OOV_/V from/I your/P own/J news/N stories/N on/I the/D region/N ./.\nINFO : Viterbi: This/N information/N was/N _OOV_/N from/N your/N own/N news/N stories/N on/N the/N region/N ./.\nINFO : Loss:    8/13\nINFO : Cross-entropy: 3.509957838949756 nats (= perplexity 11.3920686402271)\n---\nINFO : Gold:    _OOV_/J _OOV_/J government/N _OOV_/N of/I the/D ``/` _OOV_/F ''/' was/V due/J to/T the/D drug/N _OOV_/N '/P history/N of/I _OOV_/V out/R _OOV_/N in/I the/D _OOV_/N ./.\nINFO : Viterbi: _OOV_/N _OOV_/N government/N _OOV_/N of/N the/N ``/N _OOV_/N ''/N was/N due/N to/N the/N drug/N _OOV_/N '/N history/N of/N _OOV_/N out/N _OOV_/N in/N the/N _OOV_/N ./.\nINFO : Loss:    17/25\nINFO : Cross-entropy: 3.909451668303758 nats (= perplexity 15.026651653781819)\n---\nINFO : Gold:    Mary/N _OOV_/N Palo/N Alto/N ,/, Calif/N ./.\nINFO : Viterbi: Mary/N _OOV_/N Palo/N Alto/N ,/N Calif/N ./.\nINFO : Loss:    1/7\nINFO : Cross-entropy: 2.9657307028660127 nats (= perplexity 7.812209848584419)\n---\nINFO : Gold:    I/P suggest/V that/I The/D Wall/N Street/N Journal/N -LRB-/- as/R well/R as/I other/J U.S./N news/N publications/N of/I like/J mind/N -RRB-/- should/M put/V its/P money/N where/W its/P mouth/N is/V :/: _OOV_/V computer/N equipment/N to/T replace/V that/I damaged/V at/I El/N _OOV_/N ,/, buy/V ad/N space/N ,/, publish/V stories/N under/I the/D _OOV_/N of/I El/N _OOV_/N journalists/N ./.\nINFO : Viterbi: I/N suggest/N that/N The/N Wall/N Street/N Journal/N -LRB-/N as/N well/N as/N other/N U.S./N news/N publications/N of/N like/N mind/N -RRB-/N should/N put/N its/N money/N where/N its/N mouth/N is/N :/N _OOV_/N computer/N equipment/N to/N replace/N that/N damaged/N at/N El/N _OOV_/N ,/N buy/N ad/N space/N ,/N publish/N stories/N under/N the/N _OOV_/N of/N El/N _OOV_/N journalists/N ./.\nINFO : Loss:    32/53\nINFO : Cross-entropy: 4.06929710511254 nats (= perplexity 16.787286018154514)\n---\nINFO : Gold:    Perhaps/R an/D arrangement/N could/M be/V worked/V out/R to/T ``/` sponsor/V ''/' El/N _OOV_/N journalists/N and/C staff/N by/I paying/V for/I added/V security/N in/I exchange/N for/I exclusive/J stories/N ./.\nINFO : Viterbi: Perhaps/N an/N arrangement/N could/N be/N worked/N out/N to/N ``/N sponsor/N ''/N El/N _OOV_/N journalists/N and/N staff/N by/N paying/N for/N added/N security/N in/N exchange/N for/N exclusive/N stories/N ./.\nINFO : Loss:    18/27\nINFO : Cross-entropy: 3.9748081521040692 nats (= perplexity 15.723038606450697)\n---\nINFO : Gold:    _OOV_/V El/N _OOV_/N 's/P courage/N with/I real/J support/N ./.\nINFO : Viterbi: _OOV_/N El/N _OOV_/N 's/N courage/N with/N real/N support/N ./.\nINFO : Loss:    4/9\nINFO : Cross-entropy: 3.3166828614307002 nats (= perplexity 9.963708824411796)\n---\nINFO : Gold:    Douglas/N B./N Evans/N\nINFO : Viterbi: Douglas/N B./N Evans/.\nINFO : Loss:    1/3\nINFO : Cross-entropy: 2.4651118023696905 nats (= perplexity 5.521697303685183)\n---\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### CRF with PyTorch backprop\nTrain the autograd-enabled CRF to verify `ConditionalRandomFieldBackprop` behaves like the manual-gradient version.","metadata":{}},{"cell_type":"code","source":"loss_dev = lambda model: viterbi_error_rate(model, eval_corpus=endev, \n                                            known_vocab=known_vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T15:47:42.726054Z","iopub.execute_input":"2025-11-24T15:47:42.726477Z","iopub.status.idle":"2025-11-24T15:47:42.730271Z","shell.execute_reply.started":"2025-11-24T15:47:42.726445Z","shell.execute_reply":"2025-11-24T15:47:42.729348Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from crf_backprop import ConditionalRandomFieldBackprop\n\nloss_dev = lambda model: viterbi_error_rate(model, eval_corpus=endev, \n                                            known_vocab=known_vocab)\n\nlog.info(\"*** Conditional Random Field (autograd/backprop)\")\ncrf_backprop = ConditionalRandomFieldBackprop(entrain.tagset, entrain.vocab)\ncrf_backprop.train(\n    corpus=ensup,\n    loss=loss_dev,\n    reg=1.0,\n    lr=0.05,\n    minibatch_size=10,\n    eval_interval=200,\n    max_steps=5000,\n    save_path=\"/kaggle/working/ensup_crf_backprop.pkl\",\n)\nlook_at_your_data(crf_backprop, endev, 5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T15:47:48.656690Z","iopub.execute_input":"2025-11-24T15:47:48.657002Z","iopub.status.idle":"2025-11-24T17:03:54.985351Z","execution_failed":"2025-11-24T17:03:56.654Z"}},"outputs":[{"name":"stderr","text":"INFO : *** Conditional Random Field (autograd/backprop)\nINFO : Parameters: 480610 = 26*18459 + 26*26\n100%|██████████| 996/996 [00:04<00:00, 212.18it/s]\nINFO : Cross-entropy: 3.0511 nats (= perplexity 21.139)\n100%|██████████| 996/996 [02:58<00:00,  5.57it/s]\nINFO : Tagging accuracy: all: 5.558%, known: 5.993%, seen: 3.535%, novel: 0.066%\n100%|██████████| 200/200 [00:35<00:00,  5.71it/s]\nINFO : Average learning speed: 0.12 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 208.53it/s]\nINFO : Cross-entropy: 2.3221 nats (= perplexity 10.197)\n100%|██████████| 996/996 [02:56<00:00,  5.63it/s]\nINFO : Tagging accuracy: all: 33.513%, known: 31.336%, seen: 54.209%, novel: 56.803%\n  4%|▍         | 9/200 [00:01<00:22,  8.46it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-210.pkl\n100%|██████████| 200/200 [00:34<00:00,  5.73it/s]\nINFO : Average learning speed: 0.078 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 211.11it/s]\nINFO : Cross-entropy: 1.8973 nats (= perplexity 6.668)\n100%|██████████| 996/996 [02:55<00:00,  5.67it/s]\nINFO : Tagging accuracy: all: 40.753%, known: 39.275%, seen: 54.209%, novel: 56.803%\n100%|██████████| 200/200 [00:32<00:00,  6.10it/s]\nINFO : Average learning speed: 0.05 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 211.37it/s]\nINFO : Cross-entropy: 1.6814 nats (= perplexity 5.373)\n100%|██████████| 996/996 [02:58<00:00,  5.58it/s]\nINFO : Tagging accuracy: all: 51.146%, known: 50.923%, seen: 51.515%, novel: 54.227%\n  4%|▍         | 9/200 [00:00<00:22,  8.41it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-610.pkl\n100%|██████████| 200/200 [00:36<00:00,  5.42it/s]\nINFO : Average learning speed: 0.04 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 210.26it/s]\nINFO : Cross-entropy: 1.5472 nats (= perplexity 4.698)\n100%|██████████| 996/996 [02:58<00:00,  5.57it/s]\nINFO : Tagging accuracy: all: 51.522%, known: 51.339%, seen: 51.515%, novel: 54.161%\n100%|██████████| 200/200 [00:34<00:00,  5.78it/s]\nINFO : Average learning speed: 0.032 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 210.89it/s]\nINFO : Cross-entropy: 1.4492 nats (= perplexity 4.260)\n100%|██████████| 996/996 [02:59<00:00,  5.54it/s]\nINFO : Tagging accuracy: all: 54.825%, known: 55.359%, seen: 48.316%, novel: 49.670%\n  4%|▍         | 9/200 [00:00<00:19,  9.81it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-1010.pkl\n100%|██████████| 200/200 [00:32<00:00,  6.12it/s]\nINFO : Average learning speed: 0.027 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 209.23it/s]\nINFO : Cross-entropy: 1.3789 nats (= perplexity 3.971)\n100%|██████████| 996/996 [02:58<00:00,  5.58it/s]\nINFO : Tagging accuracy: all: 57.685%, known: 57.781%, seen: 55.556%, novel: 57.133%\n100%|██████████| 200/200 [00:34<00:00,  5.76it/s]\nINFO : Average learning speed: 0.025 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 210.24it/s]\nINFO : Cross-entropy: 1.3179 nats (= perplexity 3.736)\n100%|██████████| 996/996 [02:58<00:00,  5.57it/s]\nINFO : Tagging accuracy: all: 60.353%, known: 60.798%, seen: 55.219%, novel: 55.945%\n  4%|▍         | 8/200 [00:00<00:20,  9.18it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-1410.pkl\n100%|██████████| 200/200 [00:34<00:00,  5.75it/s]\nINFO : Average learning speed: 0.025 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 211.55it/s]\nINFO : Cross-entropy: 1.2651 nats (= perplexity 3.543)\n100%|██████████| 996/996 [02:59<00:00,  5.56it/s]\nINFO : Tagging accuracy: all: 61.355%, known: 61.920%, seen: 55.051%, novel: 55.680%\n100%|██████████| 200/200 [00:35<00:00,  5.59it/s]\nINFO : Average learning speed: 0.024 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 210.78it/s]\nINFO : Cross-entropy: 1.2210 nats (= perplexity 3.391)\n100%|██████████| 996/996 [02:58<00:00,  5.59it/s]\nINFO : Tagging accuracy: all: 62.303%, known: 62.841%, seen: 56.734%, novel: 56.737%\n  4%|▍         | 8/200 [00:00<00:15, 12.47it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-1810.pkl\n100%|██████████| 200/200 [00:34<00:00,  5.76it/s]\nINFO : Average learning speed: 0.023 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 211.29it/s]\nINFO : Cross-entropy: 1.1862 nats (= perplexity 3.274)\n100%|██████████| 996/996 [02:57<00:00,  5.62it/s]\nINFO : Tagging accuracy: all: 64.938%, known: 65.826%, seen: 55.051%, novel: 56.011%\n100%|██████████| 200/200 [00:34<00:00,  5.86it/s]\nINFO : Average learning speed: 0.02 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 212.65it/s]\nINFO : Cross-entropy: 1.1578 nats (= perplexity 3.183)\n100%|██████████| 996/996 [02:57<00:00,  5.60it/s]\nINFO : Tagging accuracy: all: 64.115%, known: 64.699%, seen: 56.902%, novel: 58.520%\n  4%|▍         | 8/200 [00:00<00:20,  9.53it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-2210.pkl\n100%|██████████| 200/200 [00:34<00:00,  5.78it/s]\nINFO : Average learning speed: 0.021 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 212.71it/s]\nINFO : Cross-entropy: 1.1305 nats (= perplexity 3.097)\n100%|██████████| 996/996 [02:57<00:00,  5.61it/s]\nINFO : Tagging accuracy: all: 64.842%, known: 65.533%, seen: 56.566%, novel: 58.124%\n100%|██████████| 200/200 [00:35<00:00,  5.58it/s]\nINFO : Average learning speed: 0.02 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 210.81it/s]\nINFO : Cross-entropy: 1.1051 nats (= perplexity 3.019)\n100%|██████████| 996/996 [02:57<00:00,  5.60it/s]\nINFO : Tagging accuracy: all: 64.333%, known: 64.837%, seen: 57.239%, novel: 59.841%\n  4%|▍         | 9/200 [00:01<00:20,  9.18it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-2610.pkl\n100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\nINFO : Average learning speed: 0.022 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 209.63it/s]\nINFO : Cross-entropy: 1.0804 nats (= perplexity 2.946)\n100%|██████████| 996/996 [02:57<00:00,  5.62it/s]\nINFO : Tagging accuracy: all: 67.176%, known: 67.849%, seen: 57.071%, novel: 61.427%\n100%|██████████| 200/200 [00:36<00:00,  5.43it/s]\nINFO : Average learning speed: 0.02 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 212.50it/s]\nINFO : Cross-entropy: 1.0598 nats (= perplexity 2.886)\n100%|██████████| 996/996 [02:57<00:00,  5.60it/s]\nINFO : Tagging accuracy: all: 66.287%, known: 66.906%, seen: 57.576%, novel: 60.766%\n  4%|▍         | 8/200 [00:00<00:18, 10.20it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-3010.pkl\n100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\nINFO : Average learning speed: 0.018 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 211.07it/s]\nINFO : Cross-entropy: 1.0416 nats (= perplexity 2.834)\n100%|██████████| 996/996 [02:57<00:00,  5.61it/s]\nINFO : Tagging accuracy: all: 66.274%, known: 66.851%, seen: 58.249%, novel: 61.096%\n100%|██████████| 200/200 [00:36<00:00,  5.53it/s]\nINFO : Average learning speed: 0.018 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 207.01it/s]\nINFO : Cross-entropy: 1.0243 nats (= perplexity 2.785)\n100%|██████████| 996/996 [03:02<00:00,  5.46it/s]\nINFO : Tagging accuracy: all: 68.195%, known: 68.889%, seen: 58.586%, novel: 61.955%\n  4%|▍         | 8/200 [00:00<00:16, 11.56it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-3410.pkl\n100%|██████████| 200/200 [00:39<00:00,  5.11it/s]\nINFO : Average learning speed: 0.019 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 206.76it/s]\nINFO : Cross-entropy: 1.0062 nats (= perplexity 2.735)\n100%|██████████| 996/996 [03:02<00:00,  5.47it/s]\nINFO : Tagging accuracy: all: 69.264%, known: 70.075%, seen: 58.586%, novel: 61.757%\n100%|██████████| 200/200 [00:34<00:00,  5.87it/s]\nINFO : Average learning speed: 0.016 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 207.55it/s]\nINFO : Cross-entropy: 0.9929 nats (= perplexity 2.699)\n100%|██████████| 996/996 [02:59<00:00,  5.54it/s]\nINFO : Tagging accuracy: all: 69.819%, known: 70.711%, seen: 58.081%, novel: 61.559%\n  4%|▍         | 9/200 [00:01<00:22,  8.53it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-3810.pkl\n100%|██████████| 200/200 [00:35<00:00,  5.57it/s]\nINFO : Average learning speed: 0.018 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 209.64it/s]\nINFO : Cross-entropy: 0.9797 nats (= perplexity 2.664)\n100%|██████████| 996/996 [03:00<00:00,  5.53it/s]\nINFO : Tagging accuracy: all: 69.857%, known: 70.674%, seen: 58.754%, novel: 62.417%\n 18%|█▊        | 35/200 [00:06<00:28,  5.77it/s]\n","output_type":"stream"},{"traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m log.info(\u001b[33m\"\u001b[39m\u001b[33m*** Conditional Random Field (autograd/backprop)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m crf_backprop = ConditionalRandomFieldBackprop(entrain.tagset, entrain.vocab)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mcrf_backprop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_dev\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mminibatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/kaggle/working/ensup_crf_backprop.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m look_at_your_data(crf_backprop, endev, \u001b[32m5\u001b[39m)\n","\u001b[36mFile \u001b[39m\u001b[32m/kaggle/input/testing-run/crf_backprop.py:135\u001b[39m, in \u001b[36mConditionalRandomFieldBackprop.train\u001b[39m\u001b[34m(self, corpus, minibatch_size, lr, reg, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28mself\u001b[39m._save_time = time.time()   \u001b[38;5;66;03m# this line is here just in case you're using an old version of parent class that doesn't do it\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28mself\u001b[39m._minibatch_size_value = minibatch_size\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminibatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mminibatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32m/kaggle/input/testing-run/crf.py:190\u001b[39m, in \u001b[36mConditionalRandomField.train\u001b[39m\u001b[34m(self, corpus, loss, tolerance, minibatch_size, eval_interval, lr, reg, max_steps, save_path)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m evalbatch \u001b[38;5;129;01min\u001b[39;00m more_itertools.batched(\n\u001b[32m    184\u001b[39m                    itertools.islice(corpus.draw_sentences_forever(), \n\u001b[32m    185\u001b[39m                                     max_steps),  \u001b[38;5;66;03m# limit infinite iterator\u001b[39;00m\n\u001b[32m    186\u001b[39m                    eval_interval): \u001b[38;5;66;03m# group into \"evaluation batches\"\u001b[39;00m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m tqdm(evalbatch, total=eval_interval):\n\u001b[32m    188\u001b[39m         \u001b[38;5;66;03m# Accumulate the gradient of log p(tags | words) on this sentence \u001b[39;00m\n\u001b[32m    189\u001b[39m         \u001b[38;5;66;03m# into A_counts and B_counts.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccumulate_logprob_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m         steps += \u001b[32m1\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m steps % minibatch_size == \u001b[32m0\u001b[39m:              \n\u001b[32m    197\u001b[39m             \u001b[38;5;66;03m# Time to update params based on the accumulated \u001b[39;00m\n\u001b[32m    198\u001b[39m             \u001b[38;5;66;03m# minibatch gradient and regularizer.\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32m/kaggle/input/testing-run/crf_backprop.py:162\u001b[39m, in \u001b[36mConditionalRandomFieldBackprop.accumulate_logprob_gradient\u001b[39m\u001b[34m(self, sentence, corpus)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maccumulate_logprob_gradient\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence: Sentence, corpus: TaggedCorpus) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;66;03m# [docstring will be inherited from parent method]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# Hint: You want to maximize the (regularized) log-probability. However,\u001b[39;00m\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# PyTorch optimizers *minimize* functions by default.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     loss = -\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogprob\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     norm_loss = loss / \u001b[38;5;28mmax\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m._minibatch_size_value)\n\u001b[32m    164\u001b[39m     \u001b[38;5;28mself\u001b[39m._pending_losses.append(norm_loss)\n","\u001b[36mFile \u001b[39m\u001b[32m/kaggle/input/testing-run/crf.py:244\u001b[39m, in \u001b[36mConditionalRandomField.logprob\u001b[39m\u001b[34m(self, sentence, corpus)\u001b[39m\n\u001b[32m    239\u001b[39m desup_isent = \u001b[38;5;28mself\u001b[39m._integerize_sentence(sentence.desupervise(), corpus)\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# Compute log p(tags | words) = log p(tags, words) - log p(words)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m log_p_tags_and_words = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43misent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m log_p_words = \u001b[38;5;28mself\u001b[39m.forward_pass(desup_isent)\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m log_p_tags_and_words - log_p_words\n","\u001b[36mFile \u001b[39m\u001b[32m/kaggle/input/testing-run/hmm.py:386\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(self, isent)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:      \n\u001b[32m    383\u001b[39m     e_j = B[:, w_j]\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m alpha_j = (\u001b[43malpha\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m) * e_j\n\u001b[32m    389\u001b[39m \u001b[38;5;66;03m# print(f\"Type of alpha_j before scaling: {type(alpha_j)}, type of e_j: {type(e_j)}, type of alpha[j-1]: {type(alpha[j-1])}, type of A: {type(A)}\")\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[38;5;66;03m# scale = alpha_j.sum()\u001b[39;00m\n\u001b[32m    391\u001b[39m \u001b[38;5;66;03m# scale_factors.append(scale)\u001b[39;00m\n\u001b[32m    392\u001b[39m \u001b[38;5;66;03m# alpha_j = alpha_j / scale\u001b[39;00m\n\u001b[32m    393\u001b[39m scale = alpha_j.sum().clamp_min(torch.tensor(\u001b[32m1e-12\u001b[39m, dtype=\u001b[38;5;28mself\u001b[39m.dtype, device=\u001b[38;5;28mself\u001b[39m.device))\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/fx/traceback.py:189\u001b[39m, in \u001b[36mformat_stack\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta.get(\u001b[33m\"\u001b[39m\u001b[33mstack_trace\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback.format_list(\u001b[43mtraceback\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:-\u001b[32m1\u001b[39m])\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/traceback.py:232\u001b[39m, in \u001b[36mextract_stack\u001b[39m\u001b[34m(f, limit)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    231\u001b[39m     f = sys._getframe().f_back\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m stack = \u001b[43mStackSummary\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m stack.reverse()\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/traceback.py:395\u001b[39m, in \u001b[36mStackSummary.extract\u001b[39m\u001b[34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[39m\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f, lineno \u001b[38;5;129;01min\u001b[39;00m frame_gen:\n\u001b[32m    393\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f, (lineno, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_extract_from_extended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/traceback.py:423\u001b[39m, in \u001b[36mStackSummary._extract_from_extended_frame_gen\u001b[39m\u001b[34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[39m\n\u001b[32m    420\u001b[39m filename = co.co_filename\n\u001b[32m    421\u001b[39m name = co.co_name\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[43mfnames\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    424\u001b[39m linecache.lazycache(filename, f.f_globals)\n\u001b[32m    425\u001b[39m \u001b[38;5;66;03m# Must defer line lookups until we have called checkcache.\u001b[39;00m\n","\u001b[31mKeyboardInterrupt\u001b[39m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":null},{"cell_type":"markdown","source":"### Neural biRNN-CRF\nRun the neural CRF with a simple one-hot lexicon to sanity-check `ConditionalRandomFieldNeural`.","metadata":{}},{"cell_type":"code","source":"from crf_neural import ConditionalRandomFieldNeural\nfrom lexicon import build_lexicon\nimport torch\n\nlog.info(\"*** Neural biRNN-CRF (autograd/backprop)\")\nlexicon = build_lexicon(entrain, embeddings_file = Path(\"words-10.txt\"),\n                       newvocab=known_vocab)\nlexicon = lexicon.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), dtype=torch.float64)\ncrf_neural = ConditionalRandomFieldNeural(\n    entrain.tagset,\n    entrain.vocab,\n    lexicon=lexicon,\n    rnn_dim=2,\n)\ncrf_neural.train(\n    corpus=ensup,\n    loss=loss_dev,\n    reg=0.5,\n    lr=0.01,\n    minibatch_size=5,\n    eval_interval=100,\n    max_steps=2000,\n    save_path=\"/kaggle/working/ensup_crf_neural.pkl\",\n)\nlook_at_your_data(crf_neural, endev, 3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T16:40:59.971422Z","iopub.execute_input":"2025-11-22T16:40:59.971710Z","iopub.status.idle":"2025-11-22T16:46:11.762707Z","shell.execute_reply.started":"2025-11-22T16:40:59.971691Z","shell.execute_reply":"2025-11-22T16:46:11.761628Z"}},"outputs":[{"name":"stderr","text":"INFO : *** Neural biRNN-CRF (autograd/backprop)\nINFO : From words-10.txt, got embeddings for 10420 of 18461 previously known types + 0 new seen types\nINFO : Parameters: 352 = 2*13 + 2*13 + 3*57 + 3*41 + 3 + 3\n100%|██████████| 996/996 [00:52<00:00, 18.89it/s]\nINFO : Cross-entropy: 3.0508 nats (= perplexity 21.132)\n100%|██████████| 996/996 [04:15<00:00,  3.90it/s]\nINFO : Tagging accuracy: all: 0.000%, known: 0.000%, seen: 0.000%, novel: 0.000%\n  4%|▍         | 4/100 [00:02<01:11,  1.35it/s]\n","output_type":"stream"},{"traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      8\u001b[39m lexicon = lexicon.to(torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m), dtype=torch.float64)\n\u001b[32m      9\u001b[39m crf_neural = ConditionalRandomFieldNeural(\n\u001b[32m     10\u001b[39m     entrain.tagset,\n\u001b[32m     11\u001b[39m     entrain.vocab,\n\u001b[32m     12\u001b[39m     lexicon=lexicon,\n\u001b[32m     13\u001b[39m     rnn_dim=\u001b[32m2\u001b[39m,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mcrf_neural\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_dev\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mminibatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mensup_crf_neural.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m look_at_your_data(crf_neural, endev, \u001b[32m3\u001b[39m)\n","\u001b[36mFile \u001b[39m\u001b[32m/kaggle/input/testing-run/crf_backprop.py:135\u001b[39m, in \u001b[36mConditionalRandomFieldBackprop.train\u001b[39m\u001b[34m(self, corpus, minibatch_size, lr, reg, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28mself\u001b[39m._save_time = time.time()   \u001b[38;5;66;03m# this line is here just in case you're using an old version of parent class that doesn't do it\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28mself\u001b[39m._minibatch_size_value = minibatch_size\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminibatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mminibatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32m/kaggle/input/testing-run/crf.py:204\u001b[39m, in \u001b[36mConditionalRandomField.train\u001b[39m\u001b[34m(self, corpus, loss, tolerance, minibatch_size, eval_interval, lr, reg, max_steps, save_path)\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[38;5;28mself\u001b[39m.updateAB()      \u001b[38;5;66;03m# update A and B potential matrices from new params\u001b[39;00m\n\u001b[32m    203\u001b[39m         \u001b[38;5;28mself\u001b[39m._zero_grad()    \u001b[38;5;66;03m# get ready to accumulate a new gradient for next minibatch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m save_path: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# save incompletely trained model in case we crash\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# End of the evalbatch: evaluate our progress.\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isnan(\u001b[38;5;28msum\u001b[39m(learning_speeds)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(learning_speeds) > \u001b[32m0\u001b[39m:\n","\u001b[36mFile \u001b[39m\u001b[32m/kaggle/input/testing-run/hmm.py:683\u001b[39m, in \u001b[36mHiddenMarkovModel.save\u001b[39m\u001b[34m(self, path, checkpoint, checkpoint_interval)\u001b[39m\n\u001b[32m    681\u001b[39m     \u001b[38;5;28mself\u001b[39m._checkpoint_path    = old_checkpoint_path\n\u001b[32m    682\u001b[39m     \u001b[38;5;28mself\u001b[39m.total_training_time = old_total_training_time\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    685\u001b[39m \u001b[38;5;66;03m# Since save was successful, remember it and remove old temp version (if any)\u001b[39;00m\n\u001b[32m    686\u001b[39m \u001b[38;5;28mself\u001b[39m._save_time = now\n","\u001b[36mFile \u001b[39m\u001b[32m/kaggle/input/testing-run/hmm.py:675\u001b[39m, in \u001b[36mHiddenMarkovModel.save\u001b[39m\u001b[34m(self, path, checkpoint, checkpoint_interval)\u001b[39m\n\u001b[32m    672\u001b[39m \u001b[38;5;66;03m# Save the model with the fields set as above, so that we'll \u001b[39;00m\n\u001b[32m    673\u001b[39m \u001b[38;5;66;03m# continue from it correctly when we reload it.\u001b[39;00m\n\u001b[32m    674\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHIGHEST_PROTOCOL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    676\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved model to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:   \n\u001b[32m    678\u001b[39m     \u001b[38;5;66;03m# something went wrong with the save; so restore our old fields,\u001b[39;00m\n\u001b[32m    679\u001b[39m     \u001b[38;5;66;03m# so that caller can potentially catch this exception and try again\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/serialization.py:966\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    963\u001b[39m     f = os.fspath(f)\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m    967\u001b[39m         _save(\n\u001b[32m    968\u001b[39m             obj,\n\u001b[32m    969\u001b[39m             opened_zipfile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    972\u001b[39m             _disable_byteorder_record,\n\u001b[32m    973\u001b[39m         )\n\u001b[32m    974\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/serialization.py:828\u001b[39m, in \u001b[36m_open_zipfile_writer\u001b[39m\u001b[34m(name_or_buffer)\u001b[39m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    827\u001b[39m     container = _open_zipfile_writer_buffer\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/serialization.py:792\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__init__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    785\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    786\u001b[39m         torch._C.PyTorchFileWriter(\n\u001b[32m    787\u001b[39m             \u001b[38;5;28mself\u001b[39m.file_stream, get_crc32_options(), _get_storage_alignment()\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     )\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    791\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_crc32_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_storage_alignment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    795\u001b[39m     )\n","\u001b[31mRuntimeError\u001b[39m: File ensup_crf_neural-5.pkl cannot be opened."],"ename":"RuntimeError","evalue":"File ensup_crf_neural-5.pkl cannot be opened.","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"from crf_neural import ConditionalRandomFieldNeural\nfrom lexicon import build_lexicon\nMAX_STEPS=1500\nEVAL_INTERVAL=200\nBATCH=8\nREG=0.5\ndims = [0,1,3,5]\nlrs = [0.01, 0.001]\nlog.info(\"*** Neural biRNN-CRF (autograd/backprop)\")\nlexicon = build_lexicon(entrain, embeddings_file = Path(\"words-100.txt\"),\n                       newvocab=known_vocab)\nlexicon = lexicon.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), dtype=torch.float64)\nfor d in dims:\n    for lr in lrs:\n        crf_neural = ConditionalRandomFieldNeural(\n            entrain.tagset,\n            entrain.vocab,\n            lexicon=lexicon,\n            rnn_dim=d,\n        )\n        crf_neural.train(\n            corpus=ensup,\n            loss=loss_dev,\n            reg=REG,\n            lr=lr,\n            minibatch_size=BATCH,\n            eval_interval=EVAL_INTERVAL,\n            max_steps=MAX_STEPS,\n            save_path=f\"/kaggle/working/ensup_crf_{d}_{lr}_neural.pkl\",\n        )\n        # ---- CAPTURE OUTPUT OF THE EVALUATION ----\n        buffer = io.StringIO()\n        with redirect_stdout(buffer):\n            look_at_your_data(crf_neural, endev, 5)\n\n        # ---- SAVE TO FILE ----\n        out_file = f\"/kaggle/working/output_d={d}_lr={lr}.eval\"\n        with open(out_file, \"w\") as f:\n            f.write(buffer.getvalue())\n\n        print(f\"Saved evaluation output to {out_file}\")\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T17:31:00.668536Z","iopub.execute_input":"2025-11-24T17:31:00.669201Z"}},"outputs":[{"name":"stderr","text":"INFO : *** Neural biRNN-CRF (autograd/backprop)\nINFO : From words-100.txt, got embeddings for 10420 of 18461 previously known types + 0 new seen types\nINFO : Parameters: 182 = 0*0 + 0*0 + 1*53 + 1*127 + 1 + 1\n100%|██████████| 996/996 [00:35<00:00, 28.18it/s]\nINFO : Cross-entropy: 3.0512 nats (= perplexity 21.140)\n 61%|██████    | 605/996 [08:58<04:19,  1.51it/s]","output_type":"stream"}],"execution_count":null}]}