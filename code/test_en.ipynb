{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13823004,"sourceType":"datasetVersion","datasetId":8802882},{"sourceId":13901614,"sourceType":"datasetVersion","datasetId":8802605}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T00:11:50.949597Z","iopub.execute_input":"2025-11-28T00:11:50.949861Z","iopub.status.idle":"2025-11-28T00:11:50.954078Z","shell.execute_reply.started":"2025-11-28T00:11:50.949836Z","shell.execute_reply":"2025-11-28T00:11:50.953391Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nprint(\"CUDA available:\", torch.cuda.is_available())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T00:11:50.955946Z","iopub.execute_input":"2025-11-28T00:11:50.956596Z","iopub.status.idle":"2025-11-28T00:11:54.786203Z","shell.execute_reply.started":"2025-11-28T00:11:50.956570Z","shell.execute_reply":"2025-11-28T00:11:54.785416Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"This file illustrates how you might experiment with the HMM interface.\nYou can paste these commands in at the Python prompt, or execute `test_en.py` directly.\nA notebook interface is nicer than the plain Python prompt, so we provide\na notebook version of this file as `test_en.ipynb`, which you can open with\n`jupyter` or with Visual Studio `code` (run it with the `nlp-class` kernel).","metadata":{}},{"cell_type":"code","source":"import logging\nimport math\nimport os\nfrom pathlib import Path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T00:11:54.787278Z","iopub.execute_input":"2025-11-28T00:11:54.787685Z","iopub.status.idle":"2025-11-28T00:11:54.791657Z","shell.execute_reply.started":"2025-11-28T00:11:54.787654Z","shell.execute_reply":"2025-11-28T00:11:54.790874Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"%cd /kaggle/input/testing-run","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T00:11:54.792405Z","iopub.execute_input":"2025-11-28T00:11:54.792664Z","iopub.status.idle":"2025-11-28T00:11:54.816297Z","shell.execute_reply.started":"2025-11-28T00:11:54.792641Z","shell.execute_reply":"2025-11-28T00:11:54.815477Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/testing-run\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"pip install typeguard","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T00:11:54.817193Z","iopub.execute_input":"2025-11-28T00:11:54.817513Z","iopub.status.idle":"2025-11-28T00:11:59.146300Z","shell.execute_reply.started":"2025-11-28T00:11:54.817489Z","shell.execute_reply":"2025-11-28T00:11:59.145526Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: typeguard in /usr/local/lib/python3.11/dist-packages (4.4.4)\nRequirement already satisfied: typing_extensions>=4.14.0 in /usr/local/lib/python3.11/dist-packages (from typeguard) (4.15.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"pip install more_itertools","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T00:11:59.147358Z","iopub.execute_input":"2025-11-28T00:11:59.147646Z","iopub.status.idle":"2025-11-28T00:12:02.347491Z","shell.execute_reply.started":"2025-11-28T00:11:59.147621Z","shell.execute_reply":"2025-11-28T00:12:02.346637Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (10.7.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"pip install jaxtyping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T00:12:02.349959Z","iopub.execute_input":"2025-11-28T00:12:02.350230Z","iopub.status.idle":"2025-11-28T00:15:23.397757Z","shell.execute_reply.started":"2025-11-28T00:12:02.350199Z","shell.execute_reply":"2025-11-28T00:15:23.396889Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e551f9bf590>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/jaxtyping/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e551f790d90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/jaxtyping/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e551f767910>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/jaxtyping/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e551f7761d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/jaxtyping/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e551f868790>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/jaxtyping/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement jaxtyping (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for jaxtyping\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"pip install logging","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T00:15:23.398810Z","iopub.execute_input":"2025-11-28T00:15:23.399092Z","iopub.status.idle":"2025-11-28T00:18:44.452372Z","shell.execute_reply.started":"2025-11-28T00:15:23.399041Z","shell.execute_reply":"2025-11-28T00:18:44.451421Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bdaf679cc90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/logging/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bdaf55bdd10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/logging/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bdaf57b1590>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/logging/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bdaf55a9250>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/logging/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bdaf55b1f10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/logging/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement logging (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for logging\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from corpus import TaggedCorpus\nfrom eval import eval_tagging, model_cross_entropy, viterbi_error_rate\nfrom hmm import HiddenMarkovModel\nfrom crf import ConditionalRandomField","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T00:18:44.453523Z","iopub.execute_input":"2025-11-28T00:18:44.453853Z","iopub.status.idle":"2025-11-28T00:18:44.576282Z","shell.execute_reply.started":"2025-11-28T00:18:44.453818Z","shell.execute_reply":"2025-11-28T00:18:44.575261Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2577880001.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTaggedCorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meval_tagging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cross_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mviterbi_error_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhmm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHiddenMarkovModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcrf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConditionalRandomField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/testing-run/eval.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEOS_WORD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBOS_WORD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOOV_WORD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaggedCorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhmm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHiddenMarkovModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mintegerize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIntegerizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/testing-run/hmm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjaxtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jaxtyping'"],"ename":"ModuleNotFoundError","evalue":"No module named 'jaxtyping'","output_type":"error"}],"execution_count":9},{"cell_type":"markdown","source":"Set up logging.","metadata":{}},{"cell_type":"code","source":"logging.root.setLevel(level=logging.INFO)\nlog = logging.getLogger(\"test_en\")       # For usage, see findsim.py in earlier assignment.\nlogging.basicConfig(format=\"%(levelname)s : %(message)s\", level=logging.INFO)  # could change INFO to DEBUG","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T23:47:02.807879Z","iopub.status.idle":"2025-11-27T23:47:02.808145Z","shell.execute_reply.started":"2025-11-27T23:47:02.808012Z","shell.execute_reply":"2025-11-27T23:47:02.808039Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Switch working directory to the directory where the data live.  You may need to edit this line.","metadata":{}},{"cell_type":"code","source":"entrain = TaggedCorpus(Path(\"ensup\"), Path(\"enraw\"))                               # all training\nensup =   TaggedCorpus(Path(\"ensup\"), tagset=entrain.tagset, vocab=entrain.vocab)  # supervised training\nendev =   TaggedCorpus(Path(\"endev\"), tagset=entrain.tagset, vocab=entrain.vocab)  # evaluation\nprint(f\"{len(entrain)=}  {len(ensup)=}  {len(endev)=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T23:47:02.809265Z","iopub.status.idle":"2025-11-27T23:47:02.809584Z","shell.execute_reply.started":"2025-11-27T23:47:02.809389Z","shell.execute_reply":"2025-11-27T23:47:02.809403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"known_vocab = TaggedCorpus(Path(\"ensup\")).vocab    # words seen with supervised tags; used in evaluation\nlog.info(f\"Tagset: f{list(entrain.tagset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T23:47:02.811028Z","iopub.status.idle":"2025-11-27T23:47:02.811363Z","shell.execute_reply.started":"2025-11-27T23:47:02.811216Z","shell.execute_reply":"2025-11-27T23:47:02.811234Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Make an HMM.  Let's do some pre-training to approximately maximize the\nregularized log-likelihood on supervised training data.  In other words, the\nprobabilities at the M step will just be supervised count ratios.\n\nOn each epoch, you will see two progress bars: first it collects counts from\nall the sentences (E step), and then after the M step, it evaluates the loss\nfunction, which is the (unregularized) cross-entropy on the training set.\n\nThe parameters don't actually matter during the E step because there are no\nhidden tags to impute.  The first M step will jump right to the optimal\nsolution.  The code will try a second epoch with the revised parameters, but\nthe result will be identical, so it will detect convergence and stop.\n\nWe arbitrarily choose λ=1 for our add-λ smoothing at the M step, but it would\nbe better to search for the best value of this hyperparameter.","metadata":{}},{"cell_type":"code","source":"log.info(\"*** Hidden Markov Model (HMM)\")\nhmm = HiddenMarkovModel(entrain.tagset, entrain.vocab)  # randomly initialized parameters  \nloss_sup = lambda model: model_cross_entropy(model, eval_corpus=ensup)\nhmm.train(corpus=ensup, loss=loss_sup, λ=1.0,\n          save_path=\"/kaggle/working/ensup_hmm.pkl\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T03:50:37.056556Z","iopub.execute_input":"2025-11-26T03:50:37.056884Z","iopub.status.idle":"2025-11-26T03:50:48.236290Z","shell.execute_reply.started":"2025-11-26T03:50:37.056861Z","shell.execute_reply":"2025-11-26T03:50:48.234916Z"}},"outputs":[{"name":"stderr","text":"INFO : *** Hidden Markov Model (HMM)\n 32%|███▏      | 1311/4051 [00:10<00:22, 120.84it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/1934541254.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHiddenMarkovModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# randomly initialized parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss_sup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_corpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m hmm.train(corpus=ensup, loss=loss_sup, λ=1.0,\n\u001b[0m\u001b[1;32m      5\u001b[0m           save_path=\"/kaggle/working/ensup_hmm.pkl\") \n","\u001b[0;32m/kaggle/input/testing-run/hmm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus, loss, λ, tolerance, max_steps, save_path)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# mark start of training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mdev_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;31m# evaluate the model at the start of training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mold_dev_loss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_loss\u001b[0m     \u001b[0;31m# loss from the last epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m   \u001b[0;31m# total number of sentences the model has been trained on so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/1934541254.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*** Hidden Markov Model (HMM)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHiddenMarkovModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# randomly initialized parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss_sup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_corpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m hmm.train(corpus=ensup, loss=loss_sup, λ=1.0,\n\u001b[1;32m      5\u001b[0m           save_path=\"/kaggle/working/ensup_hmm.pkl\") \n","\u001b[0;32m/kaggle/input/testing-run/eval.py\u001b[0m in \u001b[0;36mmodel_cross_entropy\u001b[0;34m(model, eval_corpus)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtoken_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mlogprob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtoken_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m    \u001b[0;31m# count EOS but not BOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mcross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogprob\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtoken_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/testing-run/hmm.py\u001b[0m in \u001b[0;36mlogprob\u001b[0;34m(self, sentence, corpus)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# Integerize the words and tags of the given sentence, which came from the given corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0misent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_integerize_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mE_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIntegerizedSentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/testing-run/hmm.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(self, isent)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;31m# scale_factors.append(scale)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;31m# alpha_j = alpha_j / scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0mscale_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":13},{"cell_type":"markdown","source":"Now let's throw in the unsupervised training data as well, and continue\ntraining as before, in order to increase the regularized log-likelihood on\nthis larger, semi-supervised training set.  It's now the *incomplete-data*\nlog-likelihood.\n\nThis time, we'll use a different evaluation loss function: we'll stop when the\n*tagging error rate* on a held-out dev set stops getting better.  Also, the\nimplementation of this loss function (`viterbi_error_rate`) includes a helpful\nside effect: it logs the *cross-entropy* on the held-out dataset as well, just\nfor your information.\n\nWe hope that held-out tagging accuracy will go up for a little bit before it\ngoes down again (see Merialdo 1994). (Log-likelihood on training data will\ncontinue to improve, and that improvement may generalize to held-out\ncross-entropy.  But getting accuracy to increase is harder.)","metadata":{}},{"cell_type":"code","source":"hmm = HiddenMarkovModel.load(\"/kaggle/working/ensup_hmm.pkl\")  # reset to supervised model (in case you're re-executing this bit)\nloss_dev = lambda model: viterbi_error_rate(model, eval_corpus=endev, \n                                            known_vocab=known_vocab)\nhmm.train(corpus=entrain, loss=loss_dev, λ=1.0,\n          save_path=\"/kaggle/working/entrain_hmm.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T03:50:48.236815Z","iopub.status.idle":"2025-11-26T03:50:48.237112Z","shell.execute_reply.started":"2025-11-26T03:50:48.236939Z","shell.execute_reply":"2025-11-26T03:50:48.236955Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You can also retry the above workflow where you start with a worse supervised\nmodel (like Merialdo).  Does EM help more in that case?  It's easiest to rerun\nexactly the code above, but first make the `ensup` file smaller by copying\n`ensup-tiny` over it.  `ensup-tiny` is only 25 sentences (that happen to cover\nall tags in `endev`).  Back up your old `ensup` and your old `*.pkl` models\nbefore you do this.","metadata":{}},{"cell_type":"markdown","source":"More detailed look at the first 10 sentences in the held-out corpus,\nincluding Viterbi tagging.","metadata":{}},{"cell_type":"code","source":"def look_at_your_data(model, dev, N):\n    for m, sentence in enumerate(dev):\n        if m >= N: break\n        viterbi = model.viterbi_tagging(sentence.desupervise(), endev)\n        counts = eval_tagging(predicted=viterbi, gold=sentence, \n                              known_vocab=known_vocab)\n        num = counts['NUM', 'ALL']\n        denom = counts['DENOM', 'ALL']\n        \n        log.info(f\"Gold:    {sentence}\")\n        log.info(f\"Viterbi: {viterbi}\")\n        log.info(f\"Loss:    {denom - num}/{denom}\")\n        xent = -model.logprob(sentence, endev) / len(sentence)  # measured in nats\n        log.info(f\"Cross-entropy: {xent/math.log(2)} nats (= perplexity {math.exp(xent)})\\n---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T23:47:02.812242Z","iopub.status.idle":"2025-11-27T23:47:02.812495Z","shell.execute_reply.started":"2025-11-27T23:47:02.812388Z","shell.execute_reply":"2025-11-27T23:47:02.812398Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"look_at_your_data(hmm, endev, 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T03:50:48.240505Z","iopub.status.idle":"2025-11-26T03:50:48.240852Z","shell.execute_reply.started":"2025-11-26T03:50:48.240662Z","shell.execute_reply":"2025-11-26T03:50:48.240675Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now let's try supervised training of a CRF (this doesn't use the unsupervised\npart of the data, so it is comparable to the supervised pre-training we did\nfor the HMM).  We will use SGD to approximately maximize the regularized\nlog-likelihood. \n\nAs with the semi-supervised HMM training, we'll periodically evaluate the\ntagging accuracy (and also print the cross-entropy) on a held-out dev set.\nWe use the default `eval_interval` and `tolerance`.  If you want to stop\nsooner, then you could increase the `tolerance` so the training method decides\nsooner that it has converged.\n\nWe arbitrarily choose reg = 1.0 for L2 regularization, learning rate = 0.05,\nand a minibatch size of 10, but it would be better to search for the best\nvalue of these hyperparameters.\n\nNote that the logger reports the CRF's *conditional* cross-entropy, log p(tags\n| words) / n.  This is much lower than the HMM's *joint* cross-entropy log\np(tags, words) / n, but that doesn't mean the CRF is worse at tagging.  The\nCRF is just predicting less information.","metadata":{}},{"cell_type":"code","source":"log.info(\"*** Conditional Random Field (CRF)\\n\")\ncrf = ConditionalRandomField(entrain.tagset, entrain.vocab)  # randomly initialized parameters  \ncrf.train(corpus=ensup, loss=loss_dev, reg=1.0, lr=0.05, minibatch_size=10,\n          save_path=\"/kaggle/working/ensup_crf.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T03:50:48.242591Z","iopub.status.idle":"2025-11-26T03:50:48.242917Z","shell.execute_reply.started":"2025-11-26T03:50:48.242759Z","shell.execute_reply":"2025-11-26T03:50:48.242775Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's examine how the CRF does on individual sentences. \n(Do you see any error patterns here that would inspire additional CRF features?)","metadata":{}},{"cell_type":"code","source":"look_at_your_data(crf, endev, 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T03:50:48.243378Z","iopub.status.idle":"2025-11-26T03:50:48.243608Z","shell.execute_reply.started":"2025-11-26T03:50:48.243501Z","shell.execute_reply":"2025-11-26T03:50:48.243510Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### CRF with PyTorch backprop\nTrain the autograd-enabled CRF to verify `ConditionalRandomFieldBackprop` behaves like the manual-gradient version.","metadata":{}},{"cell_type":"code","source":"loss_dev = lambda model: viterbi_error_rate(model, eval_corpus=endev, \n                                            known_vocab=known_vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T23:47:02.813453Z","iopub.status.idle":"2025-11-27T23:47:02.813747Z","shell.execute_reply.started":"2025-11-27T23:47:02.813596Z","shell.execute_reply":"2025-11-27T23:47:02.813608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from crf_backprop import ConditionalRandomFieldBackprop\n\nloss_dev = lambda model: viterbi_error_rate(model, eval_corpus=endev, \n                                            known_vocab=known_vocab)\n\nlog.info(\"*** Conditional Random Field (autograd/backprop)\")\ncrf_backprop = ConditionalRandomFieldBackprop(entrain.tagset, entrain.vocab)\ncrf_backprop.train(\n    corpus=ensup,\n    loss=loss_dev,\n    reg=1.0,\n    lr=0.05,\n    minibatch_size=10,\n    eval_interval=200,\n    max_steps=5000,\n    save_path=\"/kaggle/working/ensup_crf_backprop.pkl\",\n)\nlook_at_your_data(crf_backprop, endev, 5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T03:50:48.246346Z","iopub.status.idle":"2025-11-26T03:50:48.246576Z","shell.execute_reply.started":"2025-11-26T03:50:48.246468Z","shell.execute_reply":"2025-11-26T03:50:48.246480Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Neural biRNN-CRF\nRun the neural CRF with a simple one-hot lexicon to sanity-check `ConditionalRandomFieldNeural`.","metadata":{}},{"cell_type":"code","source":"from crf_neural import ConditionalRandomFieldNeural\nfrom lexicon import build_lexicon\nimport torch\n\nlog.info(\"*** Neural biRNN-CRF (autograd/backprop)\")\nlexicon = build_lexicon(entrain, embeddings_file = Path(\"words-10.txt\"),\n                       newvocab=known_vocab)\nlexicon = lexicon.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), dtype=torch.float64)\ncrf_neural = ConditionalRandomFieldNeural(\n    entrain.tagset,\n    entrain.vocab,\n    lexicon=lexicon,\n    rnn_dim=2,\n)\ncrf_neural.train(\n    corpus=ensup,\n    loss=loss_dev,\n    reg=0.5,\n    lr=0.01,\n    minibatch_size=5,\n    eval_interval=100,\n    max_steps=2000,\n    save_path=\"/kaggle/working/ensup_crf_neural.pkl\",\n)\nlook_at_your_data(crf_neural, endev, 3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T03:50:48.247878Z","iopub.status.idle":"2025-11-26T03:50:48.248294Z","shell.execute_reply.started":"2025-11-26T03:50:48.248134Z","shell.execute_reply":"2025-11-26T03:50:48.248150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss_dev = lambda model: viterbi_error_rate(model, eval_corpus=endev, \n                                            known_vocab=known_vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T22:58:57.065072Z","iopub.execute_input":"2025-11-27T22:58:57.065553Z","iopub.status.idle":"2025-11-27T22:58:57.068998Z","shell.execute_reply.started":"2025-11-27T22:58:57.065529Z","shell.execute_reply":"2025-11-27T22:58:57.068301Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import torch\nimport io\nfrom contextlib import redirect_stdout\nfrom crf_neural import ConditionalRandomFieldNeural\nfrom crf_backprop import ConditionalRandomFieldBackprop\nfrom lexicon import build_lexicon\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nMAX_STEPS = 5000\nEVAL_INTERVAL = 200\nBATCH = 64\nREG = 0.1\ndims = [2, 3, 5]\nlrs = [0.1, 0.05]\n\nlog.info(\"*** Neural biRNN-CRF (autograd/backprop)\")\n\nlexicon = build_lexicon(\n    entrain,\n    embeddings_file=Path(\"words-200.txt\"),\n    newvocab=known_vocab\n).to(device, dtype=torch.float32)\n\nfor d in dims:\n    for lr in lrs:\n\n       \n        crf_neural = ConditionalRandomFieldNeural(\n            entrain.tagset,\n            entrain.vocab,\n            lexicon=lexicon,\n            rnn_dim=d,\n        ).to(device) \n\n        # TRAIN\n        crf_neural.train(\n            corpus=ensup,\n            loss=loss_dev,\n            reg=REG,\n            lr=lr,\n            minibatch_size=BATCH,\n            eval_interval=EVAL_INTERVAL,\n            max_steps=MAX_STEPS,\n            save_path=f\"/kaggle/working/ensup_crf_{d}_{lr}_neural.pkl\",\n        )\n\n        buffer = io.StringIO()\n        with redirect_stdout(buffer):\n            look_at_your_data(crf_neural, endev, 5)\n\n        out_file = f\"/kaggle/working/output_d={d}_lr={lr}.eval\"\n        with open(out_file, \"w\") as f:\n            f.write(buffer.getvalue())\n\n        print(f\"Saved evaluation output to {out_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T23:47:02.814488Z","iopub.status.idle":"2025-11-27T23:47:02.814686Z","shell.execute_reply.started":"2025-11-27T23:47:02.814586Z","shell.execute_reply":"2025-11-27T23:47:02.814594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport io\nfrom contextlib import redirect_stdout\nfrom crf_neural import ConditionalRandomFieldNeural\nfrom crf_backprop import ConditionalRandomFieldBackprop\nfrom lexicon import build_lexicon\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nMAX_STEPS = 5000\nEVAL_INTERVAL = 200\nBATCH = 64\nREG = 0.1\ndims = [2, 3, 5]\nlrs = [0.1, 0.05]\n\nlog.info(\"*** Neural biRNN-CRF (autograd/backprop)\")\n\nproblex_aff = [[True, True], [True, False], [False, True]]\n\nfor p in problex_aff:\n    problex = p[0]\n    aff = p[1]\n    lexicon = build_lexicon(\n        entrain,\n        embeddings_file=Path(\"words-200.txt\"),\n        problex=problex,\n        affixes=affixes,\n        newvocab=known_vocab\n    ).to(device, dtype=torch.float32)\n\n       \n    crf_neural = ConditionalRandomFieldNeural(\n        entrain.tagset,\n        entrain.vocab,\n        lexicon=lexicon,\n        rnn_dim=2,\n    ).to(device) \n\n    # TRAIN\n    crf_neural.train(\n        corpus=ensup,\n        loss=loss_dev,\n        reg=REG,\n        lr=0.1,\n        minibatch_size=BATCH,\n        eval_interval=EVAL_INTERVAL,\n        max_steps=MAX_STEPS,\n        save_path=f\"/kaggle/working/ensup_crf_{d}_{lr}_neural.pkl\",\n    )\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        look_at_your_data(crf_neural, endev, 5)\n\n    out_file = f\"/kaggle/working/output_d_p_{problex}_aff={aff}.eval\"\n    with open(out_file, \"w\") as f:\n        f.write(buffer.getvalue())\n\n    print(f\"Saved evaluation output to {out_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T03:50:48.252144Z","iopub.status.idle":"2025-11-26T03:50:48.252395Z","shell.execute_reply.started":"2025-11-26T03:50:48.252286Z","shell.execute_reply":"2025-11-26T03:50:48.252298Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lexicon = build_lexicon(\n    entrain,\n    embeddings_file=Path(\"words-200.txt\"),\n    problex=True,\n    affixes=True,\n    newvocab=known_vocab\n).to(device, dtype=torch.float32)\n\n   \ncrf_neural = ConditionalRandomFieldNeural(\n    entrain.tagset,\n    entrain.vocab,\n    lexicon=lexicon,\n    rnn_dim=0,\n).to(device) \n\n# TRAIN\ncrf_neural.train(\n    corpus=ensup,\n    loss=loss_dev,\n    reg=REG,\n    lr=0.1,\n    minibatch_size=BATCH,\n    eval_interval=EVAL_INTERVAL,\n    max_steps=MAX_STEPS,\n    save_path=f\"/kaggle/working/ensup_crf_0_p_a_neural.pkl\",\n)\n\nbuffer = io.StringIO()\nwith redirect_stdout(buffer):\n    look_at_your_data(crf_neural, endev, 5)\n\nout_file = f\"/kaggle/working/output_d_p_aff.eval\"\nwith open(out_file, \"w\") as f:\n    f.write(buffer.getvalue())\n\nprint(f\"Saved evaluation output to {out_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T23:37:32.329905Z","iopub.execute_input":"2025-11-27T23:37:32.330474Z","iopub.status.idle":"2025-11-27T23:38:01.256337Z","shell.execute_reply.started":"2025-11-27T23:37:32.330449Z","shell.execute_reply":"2025-11-27T23:38:01.255275Z"}},"outputs":[{"name":"stderr","text":"INFO : From words-200.txt, got embeddings for 10420 of 18461 previously known types + 0 new seen types\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/1533637658.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnewvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mknown_vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m ).to(device, dtype=torch.float32)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 620.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 6.19 MiB is free. Process 3438 has 14.73 GiB memory in use. Of the allocated memory 13.38 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 620.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 6.19 MiB is free. Process 3438 has 14.73 GiB memory in use. Of the allocated memory 13.38 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}