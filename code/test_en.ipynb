{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[{"sourceId":13823004,"sourceType":"datasetVersion","datasetId":8802882},{"sourceId":13823508,"sourceType":"datasetVersion","datasetId":8802605}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:48:56.980621Z","iopub.execute_input":"2025-11-22T13:48:56.980772Z","iopub.status.idle":"2025-11-22T13:48:56.992369Z","shell.execute_reply.started":"2025-11-22T13:48:56.980756Z","shell.execute_reply":"2025-11-22T13:48:56.991752Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nprint(\"CUDA available:\", torch.cuda.is_available())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:48:56.992749Z","iopub.execute_input":"2025-11-22T13:48:56.992897Z","iopub.status.idle":"2025-11-22T13:49:04.151252Z","shell.execute_reply.started":"2025-11-22T13:48:56.992881Z","shell.execute_reply":"2025-11-22T13:49:04.150392Z"}},"outputs":[{"name":"stdout","text":"CUDA available: False\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"This file illustrates how you might experiment with the HMM interface.\nYou can paste these commands in at the Python prompt, or execute `test_en.py` directly.\nA notebook interface is nicer than the plain Python prompt, so we provide\na notebook version of this file as `test_en.ipynb`, which you can open with\n`jupyter` or with Visual Studio `code` (run it with the `nlp-class` kernel).","metadata":{}},{"cell_type":"code","source":"import logging\nimport math\nimport os\nfrom pathlib import Path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:49:05.560470Z","iopub.execute_input":"2025-11-22T13:49:05.560749Z","iopub.status.idle":"2025-11-22T13:49:05.563854Z","shell.execute_reply.started":"2025-11-22T13:49:05.560701Z","shell.execute_reply":"2025-11-22T13:49:05.563114Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"%cd /kaggle/input/testing-run","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:49:10.040978Z","iopub.execute_input":"2025-11-22T13:49:10.041360Z","iopub.status.idle":"2025-11-22T13:49:10.048198Z","shell.execute_reply.started":"2025-11-22T13:49:10.041331Z","shell.execute_reply":"2025-11-22T13:49:10.047410Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/testing-run\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"pip install typeguard","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:49:11.335516Z","iopub.execute_input":"2025-11-22T13:49:11.335778Z","iopub.status.idle":"2025-11-22T13:49:14.047699Z","shell.execute_reply.started":"2025-11-22T13:49:11.335761Z","shell.execute_reply":"2025-11-22T13:49:14.046612Z"}},"outputs":[{"name":"stdout","text":"Collecting typeguard\n  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: typing_extensions>=4.14.0 in /usr/local/lib/python3.12/site-packages (from typeguard) (4.15.0)\nDownloading typeguard-4.4.4-py3-none-any.whl (34 kB)\nInstalling collected packages: typeguard\nSuccessfully installed typeguard-4.4.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"pip install more_itertools","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:49:15.880702Z","iopub.execute_input":"2025-11-22T13:49:15.880966Z","iopub.status.idle":"2025-11-22T13:49:17.121545Z","shell.execute_reply.started":"2025-11-22T13:49:15.880949Z","shell.execute_reply":"2025-11-22T13:49:17.120599Z"}},"outputs":[{"name":"stdout","text":"Collecting more_itertools\n  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\nDownloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\nInstalling collected packages: more_itertools\nSuccessfully installed more_itertools-10.8.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"pip install jaxtyping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:49:17.122102Z","iopub.execute_input":"2025-11-22T13:49:17.122270Z","iopub.status.idle":"2025-11-22T13:49:18.110354Z","shell.execute_reply.started":"2025-11-22T13:49:17.122254Z","shell.execute_reply":"2025-11-22T13:49:18.109472Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: jaxtyping in /usr/local/lib/python3.12/site-packages (0.3.3)\nRequirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.12/site-packages (from jaxtyping) (0.1.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from corpus import TaggedCorpus\nfrom eval import eval_tagging, model_cross_entropy, viterbi_error_rate\nfrom hmm import HiddenMarkovModel\nfrom crf import ConditionalRandomField","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:49:18.110930Z","iopub.execute_input":"2025-11-22T13:49:18.111095Z","iopub.status.idle":"2025-11-22T13:49:18.332048Z","shell.execute_reply.started":"2025-11-22T13:49:18.111079Z","shell.execute_reply":"2025-11-22T13:49:18.331300Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Set up logging.","metadata":{}},{"cell_type":"code","source":"logging.root.setLevel(level=logging.INFO)\nlog = logging.getLogger(\"test_en\")       # For usage, see findsim.py in earlier assignment.\nlogging.basicConfig(format=\"%(levelname)s : %(message)s\", level=logging.INFO)  # could change INFO to DEBUG","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:49:21.620799Z","iopub.execute_input":"2025-11-22T13:49:21.621061Z","iopub.status.idle":"2025-11-22T13:49:21.624470Z","shell.execute_reply.started":"2025-11-22T13:49:21.621043Z","shell.execute_reply":"2025-11-22T13:49:21.623742Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Switch working directory to the directory where the data live.  You may need to edit this line.","metadata":{}},{"cell_type":"code","source":"entrain = TaggedCorpus(Path(\"ensup\"), Path(\"enraw\"))                               # all training\nensup =   TaggedCorpus(Path(\"ensup\"), tagset=entrain.tagset, vocab=entrain.vocab)  # supervised training\nendev =   TaggedCorpus(Path(\"endev\"), tagset=entrain.tagset, vocab=entrain.vocab)  # evaluation\nprint(f\"{len(entrain)=}  {len(ensup)=}  {len(endev)=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:49:35.901682Z","iopub.execute_input":"2025-11-22T13:49:35.901980Z","iopub.status.idle":"2025-11-22T13:49:36.351011Z","shell.execute_reply.started":"2025-11-22T13:49:35.901954Z","shell.execute_reply":"2025-11-22T13:49:36.350257Z"}},"outputs":[{"name":"stderr","text":"INFO : Read 191873 tokens from ensup, enraw\nINFO : Created 26 tag types\nINFO : Created 18461 word types\n","output_type":"stream"},{"name":"stdout","text":"len(entrain)=8064  len(ensup)=4051  len(endev)=996\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"known_vocab = TaggedCorpus(Path(\"ensup\")).vocab    # words seen with supervised tags; used in evaluation\nlog.info(f\"Tagset: f{list(entrain.tagset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:49:52.541066Z","iopub.execute_input":"2025-11-22T13:49:52.541317Z","iopub.status.idle":"2025-11-22T13:49:52.637443Z","shell.execute_reply.started":"2025-11-22T13:49:52.541300Z","shell.execute_reply":"2025-11-22T13:49:52.636642Z"}},"outputs":[{"name":"stderr","text":"INFO : Read 95936 tokens from ensup\nINFO : Created 26 tag types\nINFO : Created 12466 word types\nINFO : Tagset: f['W', 'J', 'N', 'C', 'V', 'I', 'D', ',', 'M', 'P', '.', 'E', 'R', '`', \"'\", 'T', '$', ':', '-', '#', 'S', 'F', 'U', 'L', '_EOS_TAG_', '_BOS_TAG_']\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Make an HMM.  Let's do some pre-training to approximately maximize the\nregularized log-likelihood on supervised training data.  In other words, the\nprobabilities at the M step will just be supervised count ratios.\n\nOn each epoch, you will see two progress bars: first it collects counts from\nall the sentences (E step), and then after the M step, it evaluates the loss\nfunction, which is the (unregularized) cross-entropy on the training set.\n\nThe parameters don't actually matter during the E step because there are no\nhidden tags to impute.  The first M step will jump right to the optimal\nsolution.  The code will try a second epoch with the revised parameters, but\nthe result will be identical, so it will detect convergence and stop.\n\nWe arbitrarily choose λ=1 for our add-λ smoothing at the M step, but it would\nbe better to search for the best value of this hyperparameter.","metadata":{}},{"cell_type":"code","source":"log.info(\"*** Hidden Markov Model (HMM)\")\nhmm = HiddenMarkovModel(entrain.tagset, entrain.vocab)  # randomly initialized parameters  \nloss_sup = lambda model: model_cross_entropy(model, eval_corpus=ensup)\nhmm.train(corpus=ensup, loss=loss_sup, λ=1.0,\n          save_path=\"/kaggle/working/ensup_hmm.pkl\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T03:54:17.059580Z","iopub.execute_input":"2025-11-22T03:54:17.059731Z","iopub.status.idle":"2025-11-22T03:55:40.451860Z","shell.execute_reply.started":"2025-11-22T03:54:17.059717Z","shell.execute_reply":"2025-11-22T03:55:40.450670Z"}},"outputs":[{"name":"stderr","text":"INFO : *** Hidden Markov Model (HMM)\n100%|██████████| 4051/4051 [00:10<00:00, 378.24it/s]\nINFO : Cross-entropy: 12.6440 nats (= perplexity 309893.787)\n100%|██████████| 4051/4051 [00:25<00:00, 158.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"M-step updated A values:\n0: tensor([9.4107e-20, 3.8028e-02, 1.1793e-01, 1.1624e-02, 4.7782e-01, 1.4787e-02,\n        7.0548e-02, 6.3396e-03, 7.8161e-02, 1.2242e-01, 1.0630e-03, 3.1572e-03,\n        4.5436e-02, 9.4107e-20, 9.4107e-20, 1.0552e-02, 1.0641e-03, 9.4107e-20,\n        1.0652e-03, 9.4107e-20, 9.4107e-20, 9.4107e-20, 9.4107e-20, 9.4107e-20,\n        9.4107e-20, 0.0000e+00])\n1: tensor([7.4188e-04, 7.6821e-02, 7.0454e-01, 3.4448e-02, 8.6307e-03, 7.4635e-02,\n        2.6699e-03, 3.3698e-02, 2.9666e-04, 2.6706e-03, 2.3364e-02, 1.3196e-20,\n        4.7442e-03, 1.3276e-03, 4.1474e-03, 1.9553e-02, 2.3648e-03, 3.7073e-03,\n        1.6382e-03, 1.3196e-20, 1.3196e-20, 1.3196e-20, 1.3196e-20, 1.3196e-20,\n        1.3196e-20, 0.0000e+00])\n2: tensor([9.1840e-04, 9.4116e-04, 2.0798e-02, 4.0924e-03, 1.0871e-02, 1.4010e-02,\n        6.1269e-04, 1.0102e-02, 1.1552e-03, 2.9211e-03, 7.7810e-03, 5.4938e-06,\n        1.6006e-03, 1.2607e-04, 3.3026e-04, 2.1775e-03, 1.9236e-05, 8.3759e-04,\n        4.6005e-04, 2.4529e-22, 2.4529e-22, 1.3776e-05, 2.4529e-22, 2.4529e-22,\n        9.2023e-01, 0.0000e+00])\n3: tensor([3.0334e-04, 4.3641e-03, 2.2184e-02, 9.0942e-03, 3.8097e-03, 5.0483e-03,\n        3.7795e-03, 4.0375e-03, 2.6270e-04, 1.6971e-03, 3.0298e-03, 8.0956e-05,\n        1.4994e-03, 1.9339e-04, 9.0419e-22, 1.2355e-03, 6.6160e-04, 3.0529e-04,\n        5.0924e-04, 9.0419e-22, 9.0419e-22, 1.0093e-05, 9.0419e-22, 9.0419e-22,\n        9.3789e-01, 0.0000e+00])\n4: tensor([1.5261e-03, 2.0515e-02, 3.4111e-02, 8.7074e-03, 3.4168e-02, 3.9093e-02,\n        3.8925e-02, 5.9734e-03, 1.2116e-04, 1.6070e-02, 8.6190e-03, 1.8160e-04,\n        2.5147e-02, 1.7225e-03, 3.0466e-04, 1.6726e-02, 2.0104e-03, 7.6745e-04,\n        3.4528e-04, 6.0761e-05, 2.0142e-05, 2.0185e-05, 2.0115e-05, 1.8009e-21,\n        7.4485e-01, 0.0000e+00])\n5: tensor([7.8789e-03, 1.0060e-01, 3.1790e-01, 6.2200e-02, 3.4484e-02, 2.0440e-02,\n        3.1735e-01, 3.1913e-03, 9.9899e-05, 6.9759e-02, 3.1936e-03, 1.5990e-03,\n        1.8127e-02, 5.8621e-03, 1.0002e-04, 3.1828e-03, 3.2428e-02, 3.0147e-04,\n        2.9946e-04, 8.0483e-04, 8.8807e-21, 1.9841e-04, 8.8807e-21, 8.8807e-21,\n        8.8807e-21, 0.0000e+00])\n6: tensor([2.2642e-04, 7.1426e-02, 2.0028e-01, 6.3533e-03, 6.9982e-03, 3.6864e-03,\n        1.5239e-04, 5.7083e-04, 5.3198e-04, 2.2709e-04, 4.1869e-04, 3.3790e-21,\n        4.4818e-03, 1.7448e-03, 3.3790e-21, 1.8876e-04, 2.9178e-03, 2.2794e-04,\n        1.5264e-04, 1.1418e-04, 3.3790e-21, 1.5195e-04, 3.3790e-21, 3.3790e-21,\n        6.9915e-01, 0.0000e+00])\n7: tensor([7.3441e-03, 5.1422e-03, 2.4570e-02, 1.3970e-02, 1.8999e-02, 9.9808e-03,\n        1.5693e-02, 2.3742e-05, 1.1402e-03, 6.0989e-03, 2.1141e-21, 2.8524e-04,\n        6.4027e-03, 1.3101e-03, 7.1488e-03, 1.4195e-03, 1.9001e-04, 2.1141e-21,\n        2.1141e-21, 2.1141e-21, 2.1141e-21, 2.1141e-21, 2.3738e-05, 2.1141e-21,\n        8.8026e-01, 0.0000e+00])\n8: tensor([1.0189e-19, 1.0189e-19, 2.2880e-03, 1.0189e-19, 7.7751e-01, 1.0189e-19,\n        1.1525e-03, 3.4195e-03, 1.0189e-19, 8.0140e-03, 2.2908e-03, 1.0189e-19,\n        1.9961e-01, 2.2825e-03, 1.0189e-19, 2.2903e-03, 1.0189e-19, 1.0189e-19,\n        1.1496e-03, 1.0189e-19, 1.0189e-19, 1.0189e-19, 1.0189e-19, 1.0189e-19,\n        1.0189e-19, 0.0000e+00])\n9: tensor([1.7988e-04, 2.0854e-02, 5.5963e-02, 2.5423e-03, 6.0125e-02, 2.5445e-03,\n        2.8141e-03, 2.1008e-03, 1.0076e-02, 4.9200e-04, 3.3546e-03, 3.9860e-21,\n        5.7875e-03, 1.2090e-03, 4.4621e-05, 1.1178e-03, 5.8300e-04, 2.6962e-04,\n        4.4798e-05, 4.4937e-05, 3.9860e-21, 8.9753e-05, 3.9860e-21, 3.9860e-21,\n        8.2976e-01, 0.0000e+00])\n10: tensor([1.2793e-24, 1.4441e-08, 2.0174e-07, 1.2793e-24, 1.2793e-24, 1.2793e-24,\n        1.2793e-24, 1.2793e-24, 1.2793e-24, 1.4303e-08, 2.8846e-08, 1.2793e-24,\n        1.2793e-24, 1.2793e-24, 3.2667e-06, 1.2793e-24, 1.2793e-24, 2.8784e-08,\n        4.4497e-07, 1.2793e-24, 1.2793e-24, 1.2793e-24, 1.2793e-24, 1.2793e-24,\n        1.0000e+00, 0.0000e+00])\n11: tensor([9.6719e-19, 9.6719e-19, 9.6719e-19, 9.6719e-19, 8.9153e-01, 9.6719e-19,\n        9.6719e-19, 2.1688e-02, 5.4098e-02, 2.1758e-02, 9.6719e-19, 9.6719e-19,\n        1.0924e-02, 9.6719e-19, 9.6719e-19, 9.6719e-19, 9.6719e-19, 9.6719e-19,\n        9.6719e-19, 9.6719e-19, 9.6719e-19, 9.6719e-19, 9.6719e-19, 9.6719e-19,\n        9.6719e-19, 0.0000e+00])\n12: tensor([3.0438e-04, 7.2855e-03, 1.5596e-03, 2.8219e-03, 1.8297e-02, 8.6331e-03,\n        3.0533e-03, 5.3266e-03, 5.5885e-04, 7.7975e-04, 3.1717e-03, 3.3841e-05,\n        4.4742e-03, 1.1883e-04, 6.8134e-05, 1.6728e-03, 8.9528e-04, 2.3877e-04,\n        8.4932e-05, 3.4152e-05, 1.5086e-21, 1.5086e-21, 1.5086e-21, 1.5086e-21,\n        9.4059e-01, 0.0000e+00])\n13: tensor([2.0945e-02, 1.2699e-01, 2.3817e-01, 1.9267e-02, 8.0329e-02, 5.5396e-02,\n        1.5735e-01, 1.3283e-19, 8.9383e-03, 2.0911e-01, 1.3283e-19, 1.7838e-02,\n        4.4761e-02, 1.3283e-19, 1.3283e-19, 2.9882e-03, 1.3283e-19, 1.4843e-03,\n        1.4982e-03, 1.3283e-19, 1.3283e-19, 5.9769e-03, 8.9543e-03, 1.3283e-19,\n        1.3283e-19, 0.0000e+00])\n14: tensor([2.2028e-06, 2.4639e-06, 1.7159e-05, 7.5930e-06, 4.0684e-05, 1.2492e-05,\n        7.0995e-06, 2.1862e-23, 7.3436e-07, 1.8464e-05, 7.4075e-07, 2.1862e-23,\n        9.8462e-07, 2.4500e-07, 1.7237e-06, 2.6807e-06, 2.1862e-23, 1.4765e-06,\n        3.4566e-06, 2.1862e-23, 2.1862e-23, 2.1862e-23, 2.1862e-23, 2.1862e-23,\n        9.9988e-01, 0.0000e+00])\n15: tensor([2.3465e-03, 3.5145e-02, 1.0143e-01, 8.6969e-02, 5.6712e-01, 2.3474e-03,\n        1.0384e-01, 4.6645e-04, 4.1655e-20, 1.9624e-02, 1.8794e-03, 4.1655e-20,\n        7.9565e-03, 5.1689e-03, 4.1655e-20, 4.1655e-20, 6.2893e-02, 4.6771e-04,\n        4.6906e-04, 9.3853e-04, 4.1655e-20, 4.6786e-04, 4.6918e-04, 4.1655e-20,\n        4.1655e-20, 0.0000e+00])\n16: tensor([1.0557e-19, 8.3021e-03, 5.9191e-03, 9.8578e-01, 1.0557e-19, 1.0557e-19,\n        1.0557e-19, 1.0557e-19, 1.0557e-19, 1.0557e-19, 1.0557e-19, 1.0557e-19,\n        1.0557e-19, 1.0557e-19, 1.0557e-19, 1.0557e-19, 1.0557e-19, 1.0557e-19,\n        1.0557e-19, 1.0557e-19, 1.0557e-19, 1.0557e-19, 1.0557e-19, 1.0557e-19,\n        1.0557e-19, 0.0000e+00])\n17: tensor([9.7001e-05, 2.9312e-04, 1.0151e-03, 9.1746e-04, 4.5566e-04, 2.9139e-04,\n        5.9731e-04, 9.6293e-22, 7.5725e-05, 3.1502e-04, 9.6293e-22, 1.0772e-05,\n        2.4744e-04, 3.6869e-04, 9.6293e-22, 5.3965e-05, 1.1945e-04, 3.2486e-05,\n        1.0867e-05, 9.6293e-22, 9.6293e-22, 9.6293e-22, 1.0906e-05, 9.6293e-22,\n        9.9509e-01, 0.0000e+00])\n18: tensor([9.3628e-06, 1.6541e-05, 1.7956e-04, 4.4873e-05, 4.9721e-05, 6.1269e-05,\n        2.8402e-05, 7.5340e-05, 2.3583e-06, 7.0990e-06, 8.0716e-05, 2.0988e-22,\n        1.8787e-05, 2.1272e-05, 2.0988e-22, 4.6881e-06, 7.7531e-05, 1.8834e-05,\n        2.3765e-06, 2.0988e-22, 2.0988e-22, 7.0949e-06, 2.0988e-22, 2.0988e-22,\n        9.9929e-01, 0.0000e+00])\n19: tensor([4.0353e-18, 4.0353e-18, 4.0353e-18, 8.6421e-01, 4.0353e-18, 4.0353e-18,\n        4.0353e-18, 4.0353e-18, 4.0353e-18, 4.0353e-18, 4.0353e-18, 4.0353e-18,\n        4.0353e-18, 4.0353e-18, 4.0353e-18, 4.0353e-18, 4.0353e-18, 4.0353e-18,\n        4.0353e-18, 1.3579e-01, 4.0353e-18, 4.0353e-18, 4.0353e-18, 4.0353e-18,\n        4.0353e-18, 0.0000e+00])\n20: tensor([8.9044e-17, 8.9044e-17, 8.9044e-17, 8.9044e-17, 8.9044e-17, 8.9044e-17,\n        8.9044e-17, 8.9044e-17, 8.9044e-17, 8.9044e-17, 8.9044e-17, 8.9044e-17,\n        8.9044e-17, 8.9044e-17, 8.9044e-17, 8.9044e-17, 8.9044e-17, 1.0000e+00,\n        8.9044e-17, 8.9044e-17, 8.9044e-17, 8.9044e-17, 8.9044e-17, 8.9044e-17,\n        8.9044e-17, 0.0000e+00])\n21: tensor([2.1232e-18, 2.1232e-18, 3.5647e-01, 2.1232e-18, 2.1232e-18, 2.3879e-02,\n        2.1232e-18, 7.1310e-02, 2.1232e-18, 2.1232e-18, 2.1232e-18, 2.1232e-18,\n        2.1232e-18, 2.1232e-18, 9.5442e-02, 2.1232e-18, 2.1232e-18, 2.1232e-18,\n        2.4047e-02, 2.1232e-18, 2.1232e-18, 4.2885e-01, 2.1232e-18, 2.1232e-18,\n        2.1232e-18, 0.0000e+00])\n22: tensor([7.3944e-18, 7.3944e-18, 8.3234e-02, 7.3944e-18, 7.3944e-18, 7.3944e-18,\n        7.3944e-18, 4.9958e-01, 7.3944e-18, 8.3608e-02, 2.5101e-01, 7.3944e-18,\n        7.3944e-18, 7.3944e-18, 7.3944e-18, 8.2563e-02, 7.3944e-18, 7.3944e-18,\n        7.3944e-18, 7.3944e-18, 7.3944e-18, 7.3944e-18, 7.3944e-18, 7.3944e-18,\n        7.3944e-18, 0.0000e+00])\n23: tensor([4.4472e-17, 4.4472e-17, 2.3616e-04, 4.4472e-17, 4.9760e-01, 4.4472e-17,\n        4.4472e-17, 5.0217e-01, 4.4472e-17, 4.4472e-17, 4.4472e-17, 4.4472e-17,\n        4.4472e-17, 4.4472e-17, 4.4472e-17, 4.4472e-17, 4.4472e-17, 4.4472e-17,\n        4.4472e-17, 4.4472e-17, 4.4472e-17, 4.4472e-17, 4.4472e-17, 4.4472e-17,\n        4.4472e-17, 0.0000e+00])\n24: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.])\n25: tensor([1.0905e-02, 4.2962e-02, 2.8826e-01, 6.7374e-02, 1.9729e-02, 1.4361e-01,\n        2.0545e-01, 2.2024e-20, 4.9344e-04, 8.1937e-02, 2.2024e-20, 6.6479e-03,\n        5.8919e-02, 6.4290e-02, 2.2024e-20, 2.2176e-03, 2.2024e-20, 2.7228e-03,\n        3.2391e-03, 2.2024e-20, 2.2024e-20, 2.4796e-04, 4.9492e-04, 4.9274e-04,\n        2.2024e-20, 0.0000e+00])\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4051/4051 [00:10<00:00, 380.31it/s]\nINFO : Cross-entropy: 7.9752 nats (= perplexity 2907.821)\n100%|██████████| 4051/4051 [00:25<00:00, 158.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"M-step updated A values:\n0: tensor([2.9404e-23, 1.1266e-03, 2.7079e-03, 6.7795e-04, 4.0086e-01, 1.9647e-03,\n        2.8390e-01, 5.7989e-03, 1.5887e-01, 1.2420e-01, 1.6061e-04, 8.4755e-04,\n        2.6582e-03, 2.9404e-23, 2.9404e-23, 1.5996e-02, 1.5915e-04, 2.9404e-23,\n        7.0605e-05, 2.9404e-23, 2.9404e-23, 2.9404e-23, 2.9404e-23, 2.9404e-23,\n        2.9404e-23, 0.0000e+00])\n1: tensor([1.7667e-05, 5.6702e-03, 1.6058e-01, 4.2670e-02, 2.4628e-04, 1.3958e-01,\n        4.8314e-04, 3.5987e-01, 9.8570e-07, 1.4957e-04, 1.6034e-01, 9.0339e-24,\n        7.4767e-05, 5.4041e-04, 5.0597e-03, 1.2112e-01, 1.6305e-03, 1.6128e-03,\n        3.4933e-04, 9.0339e-24, 9.0339e-24, 9.0339e-24, 9.0339e-24, 9.0339e-24,\n        9.0339e-24, 0.0000e+00])\n2: tensor([6.0219e-04, 2.3146e-05, 1.5602e-03, 1.2584e-02, 8.1722e-03, 1.0143e-01,\n        3.9806e-04, 4.1702e-01, 1.0028e-03, 6.8067e-03, 2.4071e-01, 7.2841e-08,\n        1.3634e-04, 5.9268e-05, 4.1737e-04, 1.9393e-02, 1.0698e-06, 1.0627e-03,\n        3.4171e-04, 2.1784e-24, 2.1784e-24, 7.7798e-08, 2.1784e-24, 2.1784e-24,\n        1.8828e-01, 0.0000e+00])\n3: tensor([1.2747e-04, 1.2651e-03, 2.6061e-02, 6.0771e-02, 1.3493e-03, 2.8775e-02,\n        4.7695e-02, 1.8074e-01, 1.5619e-04, 2.0904e-03, 9.9641e-02, 4.2756e-05,\n        2.6307e-04, 3.9906e-04, 2.1693e-23, 1.6782e-02, 4.7450e-03, 3.6491e-04,\n        1.2987e-03, 2.1693e-23, 2.1693e-23, 1.6217e-07, 2.1693e-23, 2.1693e-23,\n        5.2744e-01, 0.0000e+00])\n4: tensor([1.5934e-04, 1.4764e-03, 1.2545e-03, 3.6419e-03, 3.4076e-03, 8.3799e-02,\n        4.6957e-01, 3.4296e-02, 3.6920e-06, 1.7253e-02, 6.6624e-02, 1.8608e-05,\n        1.7812e-02, 2.5867e-03, 7.9912e-05, 2.6518e-01, 3.7122e-03, 1.9050e-04,\n        3.7479e-05, 3.5357e-06, 3.9069e-07, 5.5932e-08, 3.2513e-08, 3.7411e-24,\n        2.8895e-02, 0.0000e+00])\n5: tensor([2.6691e-04, 1.0406e-03, 2.5179e-03, 7.2593e-04, 3.9529e-05, 1.1214e-03,\n        9.5967e-01, 2.5236e-04, 2.8245e-10, 7.8295e-03, 2.4253e-04, 3.7108e-05,\n        1.0651e-04, 7.9830e-04, 2.3811e-07, 2.5027e-04, 2.5086e-02, 7.7742e-07,\n        6.8256e-07, 1.5911e-05, 4.7662e-25, 9.3390e-08, 4.7662e-25, 4.7662e-25,\n        4.7662e-25, 0.0000e+00])\n6: tensor([8.3281e-05, 1.4931e-01, 4.8581e-01, 4.9656e-03, 4.7030e-03, 2.1923e-02,\n        6.2161e-05, 2.8087e-03, 2.9430e-04, 2.3373e-05, 1.3624e-03, 6.3267e-23,\n        1.5133e-03, 2.4890e-02, 6.3267e-23, 3.0786e-04, 7.2299e-02, 1.3423e-04,\n        4.9914e-05, 1.1236e-04, 6.3267e-23, 1.1868e-05, 6.3267e-23, 6.3267e-23,\n        2.2934e-01, 0.0000e+00])\n7: tensor([4.9497e-02, 4.5931e-04, 4.5394e-03, 1.0299e-01, 2.0413e-02, 2.2210e-02,\n        3.7028e-01, 2.5065e-06, 1.2332e-03, 1.1221e-02, 2.0363e-23, 2.1211e-04,\n        2.0333e-03, 6.7015e-03, 2.1325e-01, 8.9414e-03, 1.5744e-04, 2.0363e-23,\n        2.0363e-23, 2.0363e-23, 2.0363e-23, 2.0363e-23, 2.0884e-07, 2.0363e-23,\n        1.8586e-01, 0.0000e+00])\n8: tensor([2.4770e-23, 2.4770e-23, 2.5387e-07, 2.4770e-23, 7.6594e-01, 2.4770e-23,\n        3.6164e-05, 1.3174e-03, 2.4770e-23, 1.7112e-04, 5.4460e-04, 2.4770e-23,\n        2.3077e-01, 5.6611e-04, 2.4770e-23, 5.8496e-04, 2.4770e-23, 2.4770e-23,\n        6.4189e-05, 2.4770e-23, 2.4770e-23, 2.4770e-23, 2.4770e-23, 2.4770e-23,\n        2.4770e-23, 0.0000e+00])\n9: tensor([1.7995e-05, 1.2130e-02, 1.6690e-02, 3.9544e-03, 3.9774e-01, 3.1550e-03,\n        1.6479e-02, 3.4175e-02, 1.1810e-01, 1.3876e-04, 8.2985e-02, 6.6758e-23,\n        4.2575e-03, 1.0520e-02, 1.4878e-05, 9.6178e-03, 2.5735e-03, 2.3300e-04,\n        8.1862e-07, 1.5554e-05, 6.6758e-23, 8.8759e-06, 6.6758e-23, 6.6758e-23,\n        2.8720e-01, 0.0000e+00])\n10: tensor([5.2079e-26, 5.7887e-16, 1.5437e-13, 5.2079e-26, 5.2079e-26, 5.2079e-26,\n        5.2079e-26, 5.2079e-26, 5.2079e-26, 2.0315e-14, 1.5439e-11, 5.2079e-26,\n        5.2079e-26, 5.2079e-26, 1.8545e-07, 5.2079e-26, 5.2079e-26, 7.8905e-12,\n        1.6794e-09, 5.2079e-26, 5.2079e-26, 5.2079e-26, 5.2079e-26, 5.2079e-26,\n        1.0000e+00, 0.0000e+00])\n11: tensor([7.5945e-23, 7.5945e-23, 7.5945e-23, 7.5945e-23, 9.5765e-01, 7.5945e-23,\n        7.5945e-23, 1.7079e-02, 2.1325e-02, 3.9253e-03, 7.5945e-23, 7.5945e-23,\n        2.0833e-05, 7.5945e-23, 7.5945e-23, 7.5945e-23, 7.5945e-23, 7.5945e-23,\n        7.5945e-23, 7.5945e-23, 7.5945e-23, 7.5945e-23, 7.5945e-23, 7.5945e-23,\n        7.5945e-23, 0.0000e+00])\n12: tensor([6.2636e-05, 1.3563e-03, 2.1972e-05, 2.9201e-03, 1.7960e-02, 4.7092e-02,\n        2.3792e-02, 2.8762e-01, 5.9288e-04, 3.2435e-04, 9.6445e-02, 3.4051e-06,\n        1.8020e-03, 1.1872e-04, 4.5006e-05, 2.8229e-02, 7.6828e-03, 1.8031e-04,\n        2.1161e-05, 1.1709e-05, 3.3063e-23, 3.3063e-23, 3.3063e-23, 3.3063e-23,\n        4.8371e-01, 0.0000e+00])\n13: tensor([1.7490e-03, 6.2682e-03, 3.0667e-03, 5.9845e-03, 1.1407e-02, 1.2509e-02,\n        6.3681e-01, 6.4971e-23, 3.4932e-03, 2.7847e-01, 6.4971e-23, 3.0829e-02,\n        3.8791e-03, 6.4971e-23, 6.4971e-23, 2.0019e-03, 6.4971e-23, 1.0893e-06,\n        2.3040e-04, 6.4971e-23, 6.4971e-23, 2.8762e-04, 3.0163e-03, 6.4971e-23,\n        6.4971e-23, 0.0000e+00])\n14: tensor([1.7176e-08, 4.6588e-10, 3.2263e-08, 2.2120e-07, 7.1177e-07, 2.5505e-07,\n        3.3849e-07, 8.7734e-25, 1.2651e-09, 3.7941e-07, 6.7089e-09, 8.7734e-25,\n        1.3526e-10, 1.0761e-09, 5.2872e-08, 1.3338e-07, 8.7734e-25, 2.0456e-08,\n        8.6135e-08, 8.7734e-25, 8.7734e-25, 8.7734e-25, 8.7734e-25, 8.7734e-25,\n        1.0000e+00, 0.0000e+00])\n15: tensor([7.9680e-05, 5.8092e-04, 1.6101e-03, 3.1790e-03, 1.4004e-01, 9.1443e-06,\n        4.3709e-01, 2.3426e-05, 9.6864e-24, 2.4138e-03, 3.7417e-04, 9.6864e-24,\n        6.3638e-05, 2.2738e-03, 9.6864e-24, 9.6864e-24, 4.1216e-01, 5.1175e-08,\n        1.2437e-06, 9.4269e-05, 9.6864e-24, 5.5945e-07, 1.9636e-06, 9.6864e-24,\n        9.6864e-24, 0.0000e+00])\n16: tensor([1.8526e-22, 8.2866e-06, 1.3754e-06, 9.9999e-01, 1.8526e-22, 1.8526e-22,\n        1.8526e-22, 1.8526e-22, 1.8526e-22, 1.8526e-22, 1.8526e-22, 1.8526e-22,\n        1.8526e-22, 1.8526e-22, 1.8526e-22, 1.8526e-22, 1.8526e-22, 1.8526e-22,\n        1.8526e-22, 1.8526e-22, 1.8526e-22, 1.8526e-22, 1.8526e-22, 1.8526e-22,\n        1.8526e-22, 0.0000e+00])\n17: tensor([3.3455e-05, 5.5311e-06, 1.0882e-05, 1.2056e-03, 5.9148e-05, 4.4068e-05,\n        1.5596e-03, 3.8547e-23, 8.0517e-06, 1.0086e-04, 3.8547e-23, 1.2636e-06,\n        1.5667e-05, 2.2819e-03, 3.8547e-23, 5.3622e-05, 2.5762e-04, 6.6057e-06,\n        9.4425e-07, 3.8547e-23, 3.8547e-23, 3.8547e-23, 1.8163e-07, 3.8547e-23,\n        9.9436e-01, 0.0000e+00])\n18: tensor([3.7902e-07, 1.8535e-08, 6.6759e-07, 8.5764e-06, 8.4831e-07, 4.8284e-06,\n        2.4298e-06, 1.0962e-04, 3.3372e-08, 1.9612e-08, 1.2367e-04, 8.7700e-24,\n        4.9406e-08, 7.5052e-06, 8.7700e-24, 4.2394e-07, 1.0724e-04, 2.8621e-06,\n        4.6982e-08, 8.7700e-24, 8.7700e-24, 6.9129e-08, 8.7700e-24, 8.7700e-24,\n        9.9963e-01, 0.0000e+00])\n19: tensor([3.2167e-22, 3.2167e-22, 3.2167e-22, 3.2060e-01, 3.2167e-22, 3.2167e-22,\n        3.2167e-22, 3.2167e-22, 3.2167e-22, 3.2167e-22, 3.2167e-22, 3.2167e-22,\n        3.2167e-22, 3.2167e-22, 3.2167e-22, 3.2167e-22, 3.2167e-22, 3.2167e-22,\n        3.2167e-22, 6.7940e-01, 3.2167e-22, 3.2167e-22, 3.2167e-22, 3.2167e-22,\n        3.2167e-22, 0.0000e+00])\n20: tensor([3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22,\n        3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22,\n        3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 1.0000e+00,\n        3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22, 3.7996e-22,\n        3.7996e-22, 0.0000e+00])\n21: tensor([2.0705e-22, 2.0705e-22, 4.4172e-03, 2.0705e-22, 2.0705e-22, 1.1716e-03,\n        2.0705e-22, 2.2965e-01, 2.0705e-22, 2.0705e-22, 2.0705e-22, 2.0705e-22,\n        2.0705e-22, 2.0705e-22, 2.0491e-01, 2.0705e-22, 2.0705e-22, 2.0705e-22,\n        1.1785e-02, 2.0705e-22, 2.0705e-22, 5.4806e-01, 2.0705e-22, 2.0705e-22,\n        2.0705e-22, 0.0000e+00])\n22: tensor([5.0412e-23, 5.0412e-23, 2.2556e-06, 5.0412e-23, 5.0412e-23, 5.0412e-23,\n        5.0412e-23, 7.8346e-01, 5.0412e-23, 1.1495e-05, 1.9507e-01, 5.0412e-23,\n        5.0412e-23, 5.0412e-23, 5.0412e-23, 2.1459e-02, 5.0412e-23, 5.0412e-23,\n        5.0412e-23, 5.0412e-23, 5.0412e-23, 5.0412e-23, 5.0412e-23, 5.0412e-23,\n        5.0412e-23, 0.0000e+00])\n23: tensor([3.8312e-22, 3.8312e-22, 4.2538e-13, 3.8312e-22, 2.5081e-03, 3.8312e-22,\n        3.8312e-22, 9.9749e-01, 3.8312e-22, 3.8312e-22, 3.8312e-22, 3.8312e-22,\n        3.8312e-22, 3.8312e-22, 3.8312e-22, 3.8312e-22, 3.8312e-22, 3.8312e-22,\n        3.8312e-22, 3.8312e-22, 3.8312e-22, 3.8312e-22, 3.8312e-22, 3.8312e-22,\n        3.8312e-22, 0.0000e+00])\n24: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.])\n25: tensor([3.2300e-04, 2.0962e-04, 2.4430e-02, 1.2832e-02, 2.9359e-05, 2.7338e-02,\n        3.4116e-01, 6.8942e-24, 2.0223e-08, 2.0634e-02, 6.8942e-24, 2.6500e-03,\n        9.3483e-04, 5.6843e-01, 6.8942e-24, 3.6721e-06, 6.8942e-24, 3.4586e-04,\n        6.5441e-04, 6.8942e-24, 6.8942e-24, 2.1103e-07, 5.8968e-06, 1.7608e-05,\n        6.8942e-24, 0.0000e+00])\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4051/4051 [00:10<00:00, 378.22it/s]\nINFO : Cross-entropy: 8.1748 nats (= perplexity 3550.281)\nINFO : Saved model to /kaggle/working/ensup_hmm.pkl\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Now let's throw in the unsupervised training data as well, and continue\ntraining as before, in order to increase the regularized log-likelihood on\nthis larger, semi-supervised training set.  It's now the *incomplete-data*\nlog-likelihood.\n\nThis time, we'll use a different evaluation loss function: we'll stop when the\n*tagging error rate* on a held-out dev set stops getting better.  Also, the\nimplementation of this loss function (`viterbi_error_rate`) includes a helpful\nside effect: it logs the *cross-entropy* on the held-out dataset as well, just\nfor your information.\n\nWe hope that held-out tagging accuracy will go up for a little bit before it\ngoes down again (see Merialdo 1994). (Log-likelihood on training data will\ncontinue to improve, and that improvement may generalize to held-out\ncross-entropy.  But getting accuracy to increase is harder.)","metadata":{}},{"cell_type":"code","source":"hmm = HiddenMarkovModel.load(\"/kaggle/working/ensup_hmm.pkl\")  # reset to supervised model (in case you're re-executing this bit)\nloss_dev = lambda model: viterbi_error_rate(model, eval_corpus=endev, \n                                            known_vocab=known_vocab)\nhmm.train(corpus=entrain, loss=loss_dev, λ=1.0,\n          save_path=\"/kaggle/working/entrain_hmm.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T03:55:40.452601Z","iopub.execute_input":"2025-11-22T03:55:40.452785Z","iopub.status.idle":"2025-11-22T04:03:33.270846Z","shell.execute_reply.started":"2025-11-22T03:55:40.452769Z","shell.execute_reply":"2025-11-22T04:03:33.269849Z"}},"outputs":[{"name":"stderr","text":"INFO : Loaded model from /kaggle/working/ensup_hmm.pkl\n100%|██████████| 996/996 [00:02<00:00, 340.80it/s]\nINFO : Cross-entropy: 12.8301 nats (= perplexity 373293.208)\n100%|██████████| 996/996 [03:29<00:00,  4.76it/s]\nINFO : Tagging accuracy: all: 87.010%, known: 94.144%, seen: 10.943%, novel: 13.937%\n100%|██████████| 8064/8064 [00:51<00:00, 155.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"M-step updated A values:\n0: tensor([7.1401e-24, 2.7224e-05, 2.7295e-05, 1.0635e-05, 1.4372e-01, 8.6812e-05,\n        6.5150e-01, 1.9480e-03, 1.1894e-01, 7.1687e-02, 6.0119e-06, 1.7833e-04,\n        8.1839e-05, 3.3717e-14, 7.1396e-24, 1.1780e-02, 5.7791e-06, 7.1407e-24,\n        1.2788e-06, 7.1396e-24, 7.1396e-24, 2.5997e-23, 7.1396e-24, 7.1396e-24,\n        7.1396e-24, 0.0000e+00])\n1: tensor([2.9077e-05, 9.5703e-05, 5.4691e-03, 8.4964e-03, 2.5434e-06, 4.3518e-02,\n        4.9274e-05, 6.0417e-01, 7.7672e-08, 2.3388e-06, 1.9878e-01, 8.3890e-25,\n        5.7893e-06, 3.3594e-05, 8.9551e-04, 1.3808e-01, 2.7364e-04, 9.9931e-05,\n        7.6689e-06, 3.0194e-15, 8.3893e-25, 8.7526e-25, 8.3890e-25, 8.3890e-25,\n        8.3890e-25, 0.0000e+00])\n2: tensor([1.8782e-04, 8.4539e-08, 4.8486e-06, 1.5446e-03, 2.5386e-04, 3.0922e-02,\n        2.1227e-05, 6.5559e-01, 3.6527e-05, 6.0966e-04, 3.0227e-01, 5.6531e-10,\n        4.5489e-06, 1.3415e-06, 1.9592e-05, 7.3666e-03, 2.6440e-09, 5.7523e-05,\n        8.1900e-06, 4.3153e-18, 5.2562e-26, 5.2852e-09, 5.2559e-26, 5.2559e-26,\n        1.1072e-03, 0.0000e+00])\n3: tensor([1.1710e-04, 4.4778e-05, 2.7310e-03, 3.1942e-02, 3.8262e-05, 1.3717e-02,\n        5.3132e-02, 6.1070e-01, 9.5191e-06, 2.3816e-04, 2.4844e-01, 1.8727e-06,\n        1.2565e-05, 6.4728e-05, 1.1044e-17, 2.4273e-02, 2.3982e-03, 2.8347e-05,\n        2.1473e-04, 1.0801e-24, 1.0803e-24, 3.2498e-08, 1.0842e-24, 1.0801e-24,\n        1.1895e-02, 0.0000e+00])\n4: tensor([1.2746e-04, 2.2670e-05, 4.7082e-06, 1.4754e-04, 4.0689e-05, 1.9254e-02,\n        5.0557e-01, 1.8936e-02, 2.1327e-08, 1.6215e-03, 5.2767e-02, 8.7912e-07,\n        1.5738e-03, 3.6726e-04, 2.2388e-06, 3.9889e-01, 6.1621e-04, 4.6766e-06,\n        2.9224e-07, 1.4086e-08, 3.8913e-10, 4.0885e-08, 2.6986e-12, 1.9210e-25,\n        5.7565e-05, 0.0000e+00])\n5: tensor([4.4117e-05, 4.8210e-06, 6.2625e-06, 3.6901e-06, 5.2062e-08, 2.5213e-05,\n        9.9340e-01, 9.4143e-06, 8.7485e-13, 2.9503e-04, 9.8222e-06, 2.4090e-07,\n        4.7376e-07, 3.6683e-05, 4.1256e-10, 7.4691e-06, 6.1532e-03, 1.0080e-09,\n        4.0418e-10, 7.6264e-08, 8.7654e-26, 2.0711e-08, 8.7654e-26, 8.7654e-26,\n        8.8609e-26, 0.0000e+00])\n6: tensor([1.9806e-04, 9.0830e-02, 2.9054e-01, 8.2416e-04, 1.2757e-03, 3.3719e-02,\n        1.2640e-04, 4.2790e-03, 6.8545e-05, 8.2369e-06, 1.4681e-03, 1.5818e-23,\n        2.3027e-04, 9.7347e-02, 8.4597e-24, 1.3669e-04, 4.6883e-01, 1.7978e-05,\n        2.7456e-06, 3.6967e-05, 8.4602e-24, 1.4857e-06, 8.4597e-24, 8.4597e-24,\n        1.0059e-02, 0.0000e+00])\n7: tensor([2.0184e-02, 4.7557e-06, 5.3546e-05, 4.6243e-02, 1.3265e-03, 3.0539e-03,\n        5.3287e-01, 3.7512e-08, 9.0420e-05, 1.3365e-03, 7.2163e-25, 1.4774e-05,\n        8.4998e-05, 2.2836e-03, 3.8796e-01, 3.1019e-03, 8.0899e-06, 7.2163e-25,\n        8.5298e-20, 7.2163e-25, 7.2164e-25, 6.0602e-23, 1.1779e-10, 7.2163e-25,\n        1.3908e-03, 0.0000e+00])\n8: tensor([1.2812e-23, 4.3963e-14, 7.7706e-10, 1.3668e-23, 7.7186e-01, 8.1447e-14,\n        1.7960e-06, 7.0008e-04, 6.5084e-14, 5.1177e-06, 1.4346e-04, 1.2812e-23,\n        2.2675e-01, 2.8928e-04, 1.2812e-23, 2.4523e-04, 1.2812e-23, 1.2812e-23,\n        1.8596e-06, 1.2812e-23, 1.2812e-23, 1.4628e-23, 1.2812e-23, 1.2812e-23,\n        1.2812e-23, 0.0000e+00])\n9: tensor([6.9332e-07, 1.1441e-03, 8.4957e-04, 7.6562e-04, 3.8244e-01, 8.3310e-04,\n        1.3447e-02, 8.3984e-02, 1.9979e-01, 1.2314e-03, 2.8138e-01, 6.4077e-23,\n        6.1409e-04, 1.0584e-02, 4.1777e-07, 1.2471e-02, 2.3138e-03, 2.8114e-05,\n        1.2548e-08, 4.3984e-07, 5.4543e-24, 5.8103e-07, 5.4540e-24, 5.4540e-24,\n        8.1213e-03, 0.0000e+00])\n10: tensor([2.8565e-26, 1.6606e-16, 2.9369e-15, 5.6759e-18, 2.8499e-26, 2.8490e-26,\n        2.8727e-26, 2.8495e-26, 3.0310e-26, 2.0250e-16, 1.1512e-14, 2.8791e-26,\n        1.4595e-16, 1.4630e-16, 1.0077e-08, 2.8498e-26, 2.8567e-26, 1.2849e-15,\n        5.6398e-12, 2.9479e-26, 2.8660e-26, 2.9307e-26, 2.8701e-26, 3.0077e-26,\n        1.0000e+00, 0.0000e+00])\n11: tensor([3.8914e-23, 3.8914e-23, 3.8914e-23, 4.5933e-23, 9.7632e-01, 4.2322e-23,\n        3.9520e-23, 7.4487e-03, 1.0027e-02, 6.2025e-03, 3.8914e-23, 3.8914e-23,\n        4.4833e-07, 3.8914e-23, 3.8914e-23, 4.2854e-23, 3.8914e-23, 3.9606e-23,\n        3.8914e-23, 3.8914e-23, 3.8914e-23, 3.8915e-23, 3.8914e-23, 3.8914e-23,\n        3.8914e-23, 0.0000e+00])\n12: tensor([1.8261e-05, 1.8491e-05, 2.8807e-08, 1.6260e-04, 1.0823e-03, 1.4319e-02,\n        1.0840e-02, 7.9578e-01, 2.9430e-05, 1.4410e-05, 1.3869e-01, 8.2459e-08,\n        1.0412e-04, 6.2312e-06, 1.9407e-06, 2.7518e-02, 2.7896e-03, 8.2305e-06,\n        1.8544e-07, 1.7429e-07, 9.5845e-25, 2.1314e-24, 9.5815e-25, 9.5815e-25,\n        8.6260e-03, 0.0000e+00])\n13: tensor([7.3364e-04, 9.6310e-05, 3.0315e-05, 6.1654e-04, 6.6958e-04, 1.7717e-03,\n        8.5556e-01, 1.1610e-23, 5.9968e-04, 1.1772e-01, 1.1610e-23, 2.1531e-02,\n        1.2428e-04, 1.1610e-23, 1.1610e-23, 3.5948e-04, 1.1610e-23, 1.4413e-10,\n        6.3511e-06, 1.1610e-23, 1.1612e-23, 2.5987e-06, 1.8170e-04, 1.1610e-23,\n        1.1610e-23, 0.0000e+00])\n14: tensor([1.4975e-10, 8.5672e-13, 5.1897e-11, 5.9498e-09, 1.2960e-08, 5.2709e-09,\n        1.0816e-08, 4.5725e-25, 2.0568e-12, 7.0866e-09, 3.1676e-11, 4.5725e-25,\n        4.7126e-13, 2.9177e-12, 1.2037e-09, 6.2888e-09, 4.5725e-25, 1.7094e-10,\n        1.2999e-09, 4.5727e-25, 4.5725e-25, 4.7661e-25, 4.5726e-25, 4.5733e-25,\n        1.0000e+00, 0.0000e+00])\n15: tensor([4.8753e-07, 2.9920e-06, 6.1285e-06, 2.4706e-05, 8.0775e-03, 3.3060e-08,\n        4.3903e-01, 5.8197e-07, 1.1977e-24, 5.3723e-05, 1.3822e-05, 1.1977e-24,\n        2.3854e-07, 2.4636e-04, 1.1977e-24, 1.7652e-14, 5.5254e-01, 6.9847e-13,\n        4.0901e-10, 1.1708e-06, 1.1977e-24, 1.4482e-07, 1.0161e-09, 1.1977e-24,\n        1.2579e-24, 0.0000e+00])\n16: tensor([9.1108e-23, 5.8277e-09, 2.9536e-10, 1.0000e+00, 9.1108e-23, 9.1108e-23,\n        9.1108e-23, 9.1108e-23, 9.1108e-23, 9.1108e-23, 9.1108e-23, 9.1108e-23,\n        9.1108e-23, 9.1108e-23, 9.1108e-23, 9.1108e-23, 9.1108e-23, 9.1108e-23,\n        9.1108e-23, 9.1108e-23, 9.1110e-23, 9.1108e-23, 9.1108e-23, 9.1108e-23,\n        9.1108e-23, 0.0000e+00])\n17: tensor([1.8007e-05, 1.3437e-07, 1.1369e-07, 1.4682e-03, 5.1599e-06, 9.4893e-06,\n        4.2504e-03, 1.9071e-23, 9.3407e-07, 2.9883e-05, 1.9071e-23, 2.0293e-07,\n        1.6771e-06, 1.0262e-02, 1.9071e-23, 4.0458e-05, 7.2510e-04, 9.8925e-07,\n        4.0720e-08, 1.9071e-23, 1.9105e-23, 7.8317e-21, 1.4967e-09, 1.9071e-23,\n        9.8319e-01, 0.0000e+00])\n18: tensor([1.1172e-08, 1.9793e-11, 2.4804e-09, 1.1571e-06, 1.1007e-08, 2.7247e-07,\n        1.9685e-07, 1.2749e-04, 2.7322e-10, 9.4400e-11, 1.3640e-04, 1.1762e-23,\n        1.3082e-10, 2.0217e-06, 4.8763e-24, 5.3290e-08, 1.0116e-04, 3.3588e-07,\n        5.1805e-10, 4.8763e-24, 4.8763e-24, 3.7587e-10, 4.8764e-24, 4.8766e-24,\n        9.9963e-01, 0.0000e+00])\n19: tensor([9.1246e-23, 9.1246e-23, 9.1246e-23, 3.5762e-02, 9.1246e-23, 9.1246e-23,\n        9.1246e-23, 9.1246e-23, 9.1246e-23, 9.1246e-23, 9.1246e-23, 9.1246e-23,\n        9.1246e-23, 9.1246e-23, 9.1246e-23, 9.1246e-23, 9.1246e-23, 9.1246e-23,\n        9.1246e-23, 9.6424e-01, 9.1252e-23, 9.1246e-23, 9.1246e-23, 9.1246e-23,\n        9.1246e-23, 0.0000e+00])\n20: tensor([3.8322e-22, 3.8322e-22, 3.8322e-22, 3.8322e-22, 3.8322e-22, 3.8322e-22,\n        3.8322e-22, 3.8322e-22, 3.8322e-22, 3.8322e-22, 3.8322e-22, 3.8322e-22,\n        3.8322e-22, 3.8322e-22, 3.8322e-22, 3.8322e-22, 3.8322e-22, 1.0000e+00,\n        3.8322e-22, 3.8322e-22, 3.8322e-22, 3.8322e-22, 3.8322e-22, 3.8322e-22,\n        3.8322e-22, 0.0000e+00])\n21: tensor([1.0979e-22, 1.0979e-22, 2.9312e-05, 1.0979e-22, 1.0979e-22, 3.0493e-05,\n        1.0979e-22, 3.9218e-01, 1.0979e-22, 1.0979e-22, 1.0979e-22, 1.0979e-22,\n        1.0979e-22, 1.0980e-22, 2.3329e-01, 1.0979e-22, 1.0979e-22, 1.0979e-22,\n        3.0720e-03, 1.0980e-22, 1.0979e-22, 3.7140e-01, 1.0979e-22, 1.0979e-22,\n        1.0979e-22, 0.0000e+00])\n22: tensor([3.1390e-23, 3.1393e-23, 1.2350e-10, 3.1402e-23, 3.1390e-23, 3.1390e-23,\n        3.1390e-23, 9.0210e-01, 3.1390e-23, 5.6102e-08, 9.4427e-02, 3.1390e-23,\n        3.1390e-23, 3.1390e-23, 3.1390e-23, 3.4728e-03, 3.1390e-23, 3.1390e-23,\n        3.1390e-23, 3.1390e-23, 3.1391e-23, 3.1390e-23, 3.1390e-23, 3.1390e-23,\n        3.1390e-23, 0.0000e+00])\n23: tensor([1.9336e-22, 1.9336e-22, 1.0025e-12, 1.9336e-22, 6.4124e-06, 1.9336e-22,\n        1.9336e-22, 9.9999e-01, 1.9336e-22, 1.9336e-22, 1.9336e-22, 1.9336e-22,\n        1.9336e-22, 1.9336e-22, 1.9336e-22, 1.9336e-22, 1.9336e-22, 1.9336e-22,\n        1.9336e-22, 1.9336e-22, 1.9336e-22, 1.9336e-22, 1.9336e-22, 1.9336e-22,\n        1.9336e-22, 0.0000e+00])\n24: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.])\n25: tensor([1.7739e-06, 1.2659e-06, 3.3829e-04, 4.2297e-04, 8.8330e-09, 8.3501e-04,\n        9.8603e-02, 3.1360e-15, 7.7198e-14, 9.1397e-04, 6.1385e-25, 1.7245e-04,\n        6.8652e-06, 8.9867e-01, 5.0570e-17, 1.5652e-09, 3.1822e-15, 8.3164e-06,\n        2.1801e-05, 6.1385e-25, 6.1386e-25, 1.5992e-11, 2.9863e-08, 5.6042e-08,\n        6.1385e-25, 0.0000e+00])\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 996/996 [00:02<00:00, 340.97it/s]\nINFO : Cross-entropy: 14.0351 nats (= perplexity 1245583.460)\n100%|██████████| 996/996 [03:25<00:00,  4.84it/s]\nINFO : Tagging accuracy: all: 84.822%, known: 91.905%, seen: 10.269%, novel: 11.889%\nINFO : Saved model to /kaggle/working/entrain_hmm.pkl\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"You can also retry the above workflow where you start with a worse supervised\nmodel (like Merialdo).  Does EM help more in that case?  It's easiest to rerun\nexactly the code above, but first make the `ensup` file smaller by copying\n`ensup-tiny` over it.  `ensup-tiny` is only 25 sentences (that happen to cover\nall tags in `endev`).  Back up your old `ensup` and your old `*.pkl` models\nbefore you do this.","metadata":{}},{"cell_type":"markdown","source":"More detailed look at the first 10 sentences in the held-out corpus,\nincluding Viterbi tagging.","metadata":{}},{"cell_type":"code","source":"def look_at_your_data(model, dev, N):\n    for m, sentence in enumerate(dev):\n        if m >= N: break\n        viterbi = model.viterbi_tagging(sentence.desupervise(), endev)\n        counts = eval_tagging(predicted=viterbi, gold=sentence, \n                              known_vocab=known_vocab)\n        num = counts['NUM', 'ALL']\n        denom = counts['DENOM', 'ALL']\n        \n        log.info(f\"Gold:    {sentence}\")\n        log.info(f\"Viterbi: {viterbi}\")\n        log.info(f\"Loss:    {denom - num}/{denom}\")\n        xent = -model.logprob(sentence, endev) / len(sentence)  # measured in nats\n        log.info(f\"Cross-entropy: {xent/math.log(2)} nats (= perplexity {math.exp(xent)})\\n---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:33:28.166475Z","iopub.execute_input":"2025-11-22T15:33:28.166843Z","iopub.status.idle":"2025-11-22T15:33:28.171793Z","shell.execute_reply.started":"2025-11-22T15:33:28.166821Z","shell.execute_reply":"2025-11-22T15:33:28.170893Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"look_at_your_data(hmm, endev, 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T04:03:33.276477Z","iopub.execute_input":"2025-11-22T04:03:33.276644Z","iopub.status.idle":"2025-11-22T04:03:35.189113Z","shell.execute_reply.started":"2025-11-22T04:03:33.276630Z","shell.execute_reply":"2025-11-22T04:03:35.188224Z"}},"outputs":[{"name":"stderr","text":"INFO : Gold:    ``/` We/P 're/V strongly/R _OOV_/V that/I anyone/N who/W has/V eaten/V in/I the/D cafeteria/N this/D month/N have/V the/D shot/N ,/, ''/' Mr./N Mattausch/N added/V ,/, ``/` and/C that/D means/V virtually/R everyone/N who/W works/V here/R ./.\nINFO : Viterbi: ``/` We/P 're/V strongly/R _OOV_/, that/D anyone/N who/W has/V eaten/V in/I the/D cafeteria/` this/D month/N have/V the/D shot/V ,/, ''/D Mr./N Mattausch/P added/V ,/, ``/` and/C that/W means/V virtually/R everyone/N who/W works/V here/R ./.\nINFO : Loss:    7/34\nINFO : Cross-entropy: 18.20014945645551 nats (= perplexity 301155.57826512575)\n---\nINFO : Gold:    I/P was/V _OOV_/V to/T read/V the/D _OOV_/N of/I facts/N in/I your/P Oct./N 13/C editorial/N ``/` _OOV_/N 's/P _OOV_/N _OOV_/N ./. ''/'\nINFO : Viterbi: I/P was/V _OOV_/R to/T read/V the/D _OOV_/J of/I facts/N in/I your/P Oct./N 13/C editorial/J ``/` _OOV_/E 's/P _OOV_/M _OOV_/R ./, ''/'\nINFO : Loss:    7/21\nINFO : Cross-entropy: 30.1527424287503 nats (= perplexity 1193658026.1554554)\n---\nINFO : Gold:    It/P is/V the/D _OOV_/J guerrillas/N who/W are/V aligned/V with/I the/D drug/N traffickers/N ,/, not/R the/D left/J _OOV_/N ./.\nINFO : Viterbi: It/P is/V the/D _OOV_/J guerrillas/, who/W are/V aligned/, with/I the/D drug/N traffickers/N ,/, not/R the/D left/V _OOV_/P ./.\nINFO : Loss:    4/18\nINFO : Cross-entropy: 22.17307817196956 nats (= perplexity 4728916.286138446)\n---\nINFO : Gold:    This/D information/N was/V _OOV_/V from/I your/P own/J news/N stories/N on/I the/D region/N ./.\nINFO : Viterbi: This/D information/N was/V _OOV_/D from/I your/P own/J news/N stories/N on/I the/D region/N ./.\nINFO : Loss:    1/13\nINFO : Cross-entropy: 17.57684930715871 nats (= perplexity 195505.4510024038)\n---\nINFO : Gold:    _OOV_/J _OOV_/J government/N _OOV_/N of/I the/D ``/` _OOV_/F ''/' was/V due/J to/T the/D drug/N _OOV_/N '/P history/N of/I _OOV_/V out/R _OOV_/N in/I the/D _OOV_/N ./.\nINFO : Viterbi: _OOV_/` _OOV_/D government/N _OOV_/, of/I the/D ``/` _OOV_/D ''/` was/V due/J to/T the/D drug/N _OOV_/, '/P history/N of/I _OOV_/D out/I _OOV_/D in/I the/D _OOV_/N ./.\nINFO : Loss:    9/25\nINFO : Cross-entropy: 36.352797964669364 nats (= perplexity 87757170817.88123)\n---\nINFO : Gold:    Mary/N _OOV_/N Palo/N Alto/N ,/, Calif/N ./.\nINFO : Viterbi: Mary/N _OOV_/, Palo/N Alto/N ,/, Calif/N ./.\nINFO : Loss:    1/7\nINFO : Cross-entropy: 25.176081390062752 nats (= perplexity 37910164.741189115)\n---\nINFO : Gold:    I/P suggest/V that/I The/D Wall/N Street/N Journal/N -LRB-/- as/R well/R as/I other/J U.S./N news/N publications/N of/I like/J mind/N -RRB-/- should/M put/V its/P money/N where/W its/P mouth/N is/V :/: _OOV_/V computer/N equipment/N to/T replace/V that/I damaged/V at/I El/N _OOV_/N ,/, buy/V ad/N space/N ,/, publish/V stories/N under/I the/D _OOV_/N of/I El/N _OOV_/N journalists/N ./.\nINFO : Viterbi: I/_BOS_TAG_ suggest/_BOS_TAG_ that/_BOS_TAG_ The/_BOS_TAG_ Wall/_BOS_TAG_ Street/_BOS_TAG_ Journal/_BOS_TAG_ -LRB-/_BOS_TAG_ as/_BOS_TAG_ well/_BOS_TAG_ as/_BOS_TAG_ other/_BOS_TAG_ U.S./_BOS_TAG_ news/_BOS_TAG_ publications/_BOS_TAG_ of/_BOS_TAG_ like/_BOS_TAG_ mind/_BOS_TAG_ -RRB-/_BOS_TAG_ should/_BOS_TAG_ put/_BOS_TAG_ its/_BOS_TAG_ money/_BOS_TAG_ where/_BOS_TAG_ its/_BOS_TAG_ mouth/_BOS_TAG_ is/_BOS_TAG_ :/_BOS_TAG_ _OOV_/_BOS_TAG_ computer/_BOS_TAG_ equipment/_BOS_TAG_ to/_BOS_TAG_ replace/_BOS_TAG_ that/_BOS_TAG_ damaged/_BOS_TAG_ at/_BOS_TAG_ El/_BOS_TAG_ _OOV_/_BOS_TAG_ ,/_BOS_TAG_ buy/_BOS_TAG_ ad/_BOS_TAG_ space/_BOS_TAG_ ,/_BOS_TAG_ publish/_BOS_TAG_ stories/_BOS_TAG_ under/_BOS_TAG_ the/_BOS_TAG_ _OOV_/_BOS_TAG_ of/_BOS_TAG_ El/_BOS_TAG_ _OOV_/_BOS_TAG_ journalists/_BOS_TAG_ ./_BOS_TAG_\nINFO : Loss:    53/53\nINFO : Cross-entropy: 25.680776348286535 nats (= perplexity 53787826.1832531)\n---\nINFO : Gold:    Perhaps/R an/D arrangement/N could/M be/V worked/V out/R to/T ``/` sponsor/V ''/' El/N _OOV_/N journalists/N and/C staff/N by/I paying/V for/I added/V security/N in/I exchange/N for/I exclusive/J stories/N ./.\nINFO : Viterbi: Perhaps/R an/D arrangement/N could/M be/V worked/V out/R to/T ``/` sponsor/N ''/D El/N _OOV_/, journalists/N and/C staff/N by/I paying/V for/I added/J security/N in/I exchange/N for/I exclusive/J stories/N ./.\nINFO : Loss:    4/27\nINFO : Cross-entropy: 23.16035888251649 nats (= perplexity 9374815.598863956)\n---\nINFO : Gold:    _OOV_/V El/N _OOV_/N 's/P courage/N with/I real/J support/N ./.\nINFO : Viterbi: _OOV_/D El/N _OOV_/, 's/P courage/N with/I real/J support/N ./.\nINFO : Loss:    2/9\nINFO : Cross-entropy: 31.335270371578808 nats (= perplexity 2709295053.5116973)\n---\nINFO : Gold:    Douglas/N B./N Evans/N\nINFO : Viterbi: Douglas/N B./N Evans/N\nINFO : Loss:    0/3\nINFO : Cross-entropy: 18.955827429206778 nats (= perplexity 508478.5637519965)\n---\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Now let's try supervised training of a CRF (this doesn't use the unsupervised\npart of the data, so it is comparable to the supervised pre-training we did\nfor the HMM).  We will use SGD to approximately maximize the regularized\nlog-likelihood. \n\nAs with the semi-supervised HMM training, we'll periodically evaluate the\ntagging accuracy (and also print the cross-entropy) on a held-out dev set.\nWe use the default `eval_interval` and `tolerance`.  If you want to stop\nsooner, then you could increase the `tolerance` so the training method decides\nsooner that it has converged.\n\nWe arbitrarily choose reg = 1.0 for L2 regularization, learning rate = 0.05,\nand a minibatch size of 10, but it would be better to search for the best\nvalue of these hyperparameters.\n\nNote that the logger reports the CRF's *conditional* cross-entropy, log p(tags\n| words) / n.  This is much lower than the HMM's *joint* cross-entropy log\np(tags, words) / n, but that doesn't mean the CRF is worse at tagging.  The\nCRF is just predicting less information.","metadata":{}},{"cell_type":"code","source":"log.info(\"*** Conditional Random Field (CRF)\\n\")\ncrf = ConditionalRandomField(entrain.tagset, entrain.vocab)  # randomly initialized parameters  \ncrf.train(corpus=ensup, loss=loss_dev, reg=1.0, lr=0.05, minibatch_size=10,\n          save_path=\"/kaggle/working/ensup_crf.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T04:03:35.189801Z","iopub.execute_input":"2025-11-22T04:03:35.189973Z","iopub.status.idle":"2025-11-22T04:35:02.940613Z","shell.execute_reply.started":"2025-11-22T04:03:35.189957Z","shell.execute_reply":"2025-11-22T04:35:02.939359Z"}},"outputs":[{"name":"stderr","text":"INFO : *** Conditional Random Field (CRF)\n\n100%|██████████| 996/996 [00:04<00:00, 216.14it/s]\nINFO : Cross-entropy: 3.0501 nats (= perplexity 21.118)\n100%|██████████| 996/996 [02:57<00:00,  5.62it/s]\nINFO : Tagging accuracy: all: 5.800%, known: 6.245%, seen: 3.704%, novel: 0.198%\n100%|██████████| 500/500 [00:06<00:00, 71.89it/s]\n100%|██████████| 996/996 [00:04<00:00, 214.42it/s]\nINFO : Cross-entropy: 2.9038 nats (= perplexity 18.244)\n100%|██████████| 996/996 [02:55<00:00,  5.66it/s]\nINFO : Tagging accuracy: all: 33.513%, known: 31.336%, seen: 54.209%, novel: 56.803%\n  1%|          | 6/500 [00:00<00:08, 56.59it/s]INFO : Saved model to /kaggle/working/ensup_crf-510.pkl\n100%|██████████| 500/500 [00:07<00:00, 67.30it/s]\n100%|██████████| 996/996 [00:04<00:00, 214.59it/s]\nINFO : Cross-entropy: 2.8704 nats (= perplexity 17.645)\n100%|██████████| 996/996 [02:56<00:00,  5.63it/s]\nINFO : Tagging accuracy: all: 33.722%, known: 31.564%, seen: 54.209%, novel: 56.803%\n100%|██████████| 500/500 [00:07<00:00, 66.69it/s]\n100%|██████████| 996/996 [00:04<00:00, 213.09it/s]\nINFO : Cross-entropy: 2.8491 nats (= perplexity 17.272)\n100%|██████████| 996/996 [02:57<00:00,  5.61it/s]\nINFO : Tagging accuracy: all: 33.722%, known: 31.564%, seen: 54.209%, novel: 56.803%\n  2%|▏         | 9/500 [00:00<00:05, 89.05it/s]INFO : Saved model to /kaggle/working/ensup_crf-1510.pkl\n100%|██████████| 500/500 [00:07<00:00, 70.63it/s]\n100%|██████████| 996/996 [00:04<00:00, 212.37it/s]\nINFO : Cross-entropy: 2.8265 nats (= perplexity 16.887)\n100%|██████████| 996/996 [02:58<00:00,  5.59it/s]\nINFO : Tagging accuracy: all: 33.738%, known: 31.583%, seen: 54.209%, novel: 56.803%\n100%|██████████| 500/500 [00:07<00:00, 70.11it/s]\n100%|██████████| 996/996 [00:04<00:00, 213.94it/s]\nINFO : Cross-entropy: 2.8153 nats (= perplexity 16.698)\n100%|██████████| 996/996 [02:58<00:00,  5.58it/s]\nINFO : Tagging accuracy: all: 33.738%, known: 31.583%, seen: 54.209%, novel: 56.803%\n  1%|          | 5/500 [00:00<00:10, 48.16it/s]INFO : Saved model to /kaggle/working/ensup_crf-2510.pkl\n100%|██████████| 500/500 [00:07<00:00, 68.57it/s]\n100%|██████████| 996/996 [00:04<00:00, 210.54it/s]\nINFO : Cross-entropy: 2.8054 nats (= perplexity 16.534)\n100%|██████████| 996/996 [02:57<00:00,  5.60it/s]\nINFO : Tagging accuracy: all: 33.738%, known: 31.583%, seen: 54.209%, novel: 56.803%\n100%|██████████| 500/500 [00:07<00:00, 67.95it/s]\n100%|██████████| 996/996 [00:04<00:00, 211.97it/s]\nINFO : Cross-entropy: 2.7968 nats (= perplexity 16.391)\n100%|██████████| 996/996 [02:57<00:00,  5.62it/s]\nINFO : Tagging accuracy: all: 33.738%, known: 31.583%, seen: 54.209%, novel: 56.803%\n  1%|          | 6/500 [00:00<00:08, 56.84it/s]INFO : Saved model to /kaggle/working/ensup_crf-3510.pkl\n100%|██████████| 500/500 [00:07<00:00, 71.41it/s]\n100%|██████████| 996/996 [00:04<00:00, 210.62it/s]\nINFO : Cross-entropy: 2.7925 nats (= perplexity 16.321)\n100%|██████████| 996/996 [02:58<00:00,  5.58it/s]\nINFO : Tagging accuracy: all: 33.738%, known: 31.583%, seen: 54.209%, novel: 56.803%\n100%|██████████| 500/500 [00:07<00:00, 70.13it/s]\n100%|██████████| 996/996 [00:04<00:00, 212.09it/s]\nINFO : Cross-entropy: 2.7851 nats (= perplexity 16.202)\n100%|██████████| 996/996 [02:58<00:00,  5.59it/s]\nINFO : Tagging accuracy: all: 33.738%, known: 31.583%, seen: 54.209%, novel: 56.803%\nINFO : Saved model to /kaggle/working/ensup_crf.pkl\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"Let's examine how the CRF does on individual sentences. \n(Do you see any error patterns here that would inspire additional CRF features?)","metadata":{}},{"cell_type":"code","source":"look_at_your_data(crf, endev, 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T04:35:02.941520Z","iopub.execute_input":"2025-11-22T04:35:02.941711Z","iopub.status.idle":"2025-11-22T04:35:04.824080Z","shell.execute_reply.started":"2025-11-22T04:35:02.941694Z","shell.execute_reply":"2025-11-22T04:35:04.822884Z"}},"outputs":[{"name":"stderr","text":"INFO : Gold:    ``/` We/P 're/V strongly/R _OOV_/V that/I anyone/N who/W has/V eaten/V in/I the/D cafeteria/N this/D month/N have/V the/D shot/N ,/, ''/' Mr./N Mattausch/N added/V ,/, ``/` and/C that/D means/V virtually/R everyone/N who/W works/V here/R ./.\nINFO : Viterbi: ``/N We/N 're/N strongly/N _OOV_/N that/N anyone/N who/N has/N eaten/N in/N the/N cafeteria/N this/N month/N have/N the/N shot/N ,/N ''/N Mr./N Mattausch/N added/N ,/N ``/N and/N that/N means/N virtually/N everyone/N who/N works/N here/N ./.\nINFO : Loss:    26/34\nINFO : Cross-entropy: 4.020375211200853 nats (= perplexity 16.227571539277715)\n---\nINFO : Gold:    I/P was/V _OOV_/V to/T read/V the/D _OOV_/N of/I facts/N in/I your/P Oct./N 13/C editorial/N ``/` _OOV_/N 's/P _OOV_/N _OOV_/N ./. ''/'\nINFO : Viterbi: I/N was/N _OOV_/N to/N read/N the/N _OOV_/N of/N facts/N in/N your/N Oct./N 13/N editorial/N ``/N _OOV_/N 's/N _OOV_/N _OOV_/N ./. ''/.\nINFO : Loss:    13/21\nINFO : Cross-entropy: 3.8831678415781927 nats (= perplexity 14.755366410094656)\n---\nINFO : Gold:    It/P is/V the/D _OOV_/J guerrillas/N who/W are/V aligned/V with/I the/D drug/N traffickers/N ,/, not/R the/D left/J _OOV_/N ./.\nINFO : Viterbi: It/N is/N the/N _OOV_/N guerrillas/N who/N are/N aligned/N with/N the/N drug/N traffickers/N ,/N not/N the/N left/N _OOV_/N ./.\nINFO : Loss:    13/18\nINFO : Cross-entropy: 3.693675975502884 nats (= perplexity 12.93919514731451)\n---\nINFO : Gold:    This/D information/N was/V _OOV_/V from/I your/P own/J news/N stories/N on/I the/D region/N ./.\nINFO : Viterbi: This/N information/N was/N _OOV_/N from/N your/N own/N news/N stories/N on/N the/N region/N ./.\nINFO : Loss:    8/13\nINFO : Cross-entropy: 3.509957838949756 nats (= perplexity 11.3920686402271)\n---\nINFO : Gold:    _OOV_/J _OOV_/J government/N _OOV_/N of/I the/D ``/` _OOV_/F ''/' was/V due/J to/T the/D drug/N _OOV_/N '/P history/N of/I _OOV_/V out/R _OOV_/N in/I the/D _OOV_/N ./.\nINFO : Viterbi: _OOV_/N _OOV_/N government/N _OOV_/N of/N the/N ``/N _OOV_/N ''/N was/N due/N to/N the/N drug/N _OOV_/N '/N history/N of/N _OOV_/N out/N _OOV_/N in/N the/N _OOV_/N ./.\nINFO : Loss:    17/25\nINFO : Cross-entropy: 3.909451668303758 nats (= perplexity 15.026651653781819)\n---\nINFO : Gold:    Mary/N _OOV_/N Palo/N Alto/N ,/, Calif/N ./.\nINFO : Viterbi: Mary/N _OOV_/N Palo/N Alto/N ,/N Calif/N ./.\nINFO : Loss:    1/7\nINFO : Cross-entropy: 2.9657307028660127 nats (= perplexity 7.812209848584419)\n---\nINFO : Gold:    I/P suggest/V that/I The/D Wall/N Street/N Journal/N -LRB-/- as/R well/R as/I other/J U.S./N news/N publications/N of/I like/J mind/N -RRB-/- should/M put/V its/P money/N where/W its/P mouth/N is/V :/: _OOV_/V computer/N equipment/N to/T replace/V that/I damaged/V at/I El/N _OOV_/N ,/, buy/V ad/N space/N ,/, publish/V stories/N under/I the/D _OOV_/N of/I El/N _OOV_/N journalists/N ./.\nINFO : Viterbi: I/N suggest/N that/N The/N Wall/N Street/N Journal/N -LRB-/N as/N well/N as/N other/N U.S./N news/N publications/N of/N like/N mind/N -RRB-/N should/N put/N its/N money/N where/N its/N mouth/N is/N :/N _OOV_/N computer/N equipment/N to/N replace/N that/N damaged/N at/N El/N _OOV_/N ,/N buy/N ad/N space/N ,/N publish/N stories/N under/N the/N _OOV_/N of/N El/N _OOV_/N journalists/N ./.\nINFO : Loss:    32/53\nINFO : Cross-entropy: 4.06929710511254 nats (= perplexity 16.787286018154514)\n---\nINFO : Gold:    Perhaps/R an/D arrangement/N could/M be/V worked/V out/R to/T ``/` sponsor/V ''/' El/N _OOV_/N journalists/N and/C staff/N by/I paying/V for/I added/V security/N in/I exchange/N for/I exclusive/J stories/N ./.\nINFO : Viterbi: Perhaps/N an/N arrangement/N could/N be/N worked/N out/N to/N ``/N sponsor/N ''/N El/N _OOV_/N journalists/N and/N staff/N by/N paying/N for/N added/N security/N in/N exchange/N for/N exclusive/N stories/N ./.\nINFO : Loss:    18/27\nINFO : Cross-entropy: 3.9748081521040692 nats (= perplexity 15.723038606450697)\n---\nINFO : Gold:    _OOV_/V El/N _OOV_/N 's/P courage/N with/I real/J support/N ./.\nINFO : Viterbi: _OOV_/N El/N _OOV_/N 's/N courage/N with/N real/N support/N ./.\nINFO : Loss:    4/9\nINFO : Cross-entropy: 3.3166828614307002 nats (= perplexity 9.963708824411796)\n---\nINFO : Gold:    Douglas/N B./N Evans/N\nINFO : Viterbi: Douglas/N B./N Evans/.\nINFO : Loss:    1/3\nINFO : Cross-entropy: 2.4651118023696905 nats (= perplexity 5.521697303685183)\n---\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### CRF with PyTorch backprop\nTrain the autograd-enabled CRF to verify `ConditionalRandomFieldBackprop` behaves like the manual-gradient version.","metadata":{}},{"cell_type":"code","source":"from crf_backprop import ConditionalRandomFieldBackprop\n\nloss_dev = lambda model: viterbi_error_rate(model, eval_corpus=endev, \n                                            known_vocab=known_vocab)\n\nlog.info(\"*** Conditional Random Field (autograd/backprop)\")\ncrf_backprop = ConditionalRandomFieldBackprop(entrain.tagset, entrain.vocab)\ncrf_backprop.train(\n    corpus=ensup,\n    loss=loss_dev,\n    reg=1.0,\n    lr=0.05,\n    minibatch_size=10,\n    eval_interval=200,\n    max_steps=5000,\n    save_path=\"/kaggle/working/ensup_crf_backprop.pkl\",\n)\nlook_at_your_data(crf_backprop, endev, 5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:52:26.366356Z","iopub.execute_input":"2025-11-22T13:52:26.366720Z","iopub.status.idle":"2025-11-22T15:28:27.808312Z","shell.execute_reply.started":"2025-11-22T13:52:26.366692Z","shell.execute_reply":"2025-11-22T15:28:27.807179Z"}},"outputs":[{"name":"stderr","text":"INFO : *** Conditional Random Field (autograd/backprop)\nINFO : Parameters: 480610 = 26*18459 + 26*26\n100%|██████████| 996/996 [00:04<00:00, 200.27it/s]\nINFO : Cross-entropy: 3.0506 nats (= perplexity 21.129)\n100%|██████████| 996/996 [03:04<00:00,  5.41it/s]\nINFO : Tagging accuracy: all: 4.451%, known: 4.707%, seen: 6.061%, novel: 0.132%\n100%|██████████| 200/200 [00:33<00:00,  6.03it/s]\nINFO : Average learning speed: 0.12 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 200.98it/s]\nINFO : Cross-entropy: 2.3296 nats (= perplexity 10.274)\n100%|██████████| 996/996 [03:04<00:00,  5.41it/s]\nINFO : Tagging accuracy: all: 33.513%, known: 31.336%, seen: 54.209%, novel: 56.803%\n  4%|▍         | 9/200 [00:00<00:22,  8.53it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-210.pkl\n100%|██████████| 200/200 [00:32<00:00,  6.20it/s]\nINFO : Average learning speed: 0.075 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 198.91it/s]\nINFO : Cross-entropy: 1.9079 nats (= perplexity 6.739)\n100%|██████████| 996/996 [03:03<00:00,  5.44it/s]\nINFO : Tagging accuracy: all: 38.415%, known: 36.706%, seen: 54.209%, novel: 56.869%\n100%|██████████| 200/200 [00:33<00:00,  5.92it/s]\nINFO : Average learning speed: 0.051 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 197.25it/s]\nINFO : Cross-entropy: 1.6772 nats (= perplexity 5.350)\n100%|██████████| 996/996 [03:04<00:00,  5.41it/s]\nINFO : Tagging accuracy: all: 50.708%, known: 50.414%, seen: 51.852%, novel: 54.491%\n  4%|▍         | 9/200 [00:00<00:20,  9.25it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-610.pkl\n100%|██████████| 200/200 [00:33<00:00,  5.94it/s]\nINFO : Average learning speed: 0.039 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 198.88it/s]\nINFO : Cross-entropy: 1.5411 nats (= perplexity 4.670)\n100%|██████████| 996/996 [03:04<00:00,  5.39it/s]\nINFO : Tagging accuracy: all: 51.560%, known: 51.380%, seen: 51.515%, novel: 54.161%\n100%|██████████| 200/200 [00:33<00:00,  6.03it/s]\nINFO : Average learning speed: 0.032 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 197.57it/s]\nINFO : Cross-entropy: 1.4479 nats (= perplexity 4.254)\n100%|██████████| 996/996 [03:04<00:00,  5.39it/s]\nINFO : Tagging accuracy: all: 54.395%, known: 54.746%, seen: 48.990%, novel: 51.453%\n  4%|▍         | 9/200 [00:01<00:23,  8.19it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-1010.pkl\n100%|██████████| 200/200 [00:34<00:00,  5.86it/s]\nINFO : Average learning speed: 0.027 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 194.50it/s]\nINFO : Cross-entropy: 1.3738 nats (= perplexity 3.950)\n100%|██████████| 996/996 [03:06<00:00,  5.35it/s]\nINFO : Tagging accuracy: all: 58.207%, known: 58.541%, seen: 54.040%, novel: 55.020%\n100%|██████████| 200/200 [00:32<00:00,  6.06it/s]\nINFO : Average learning speed: 0.025 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 201.24it/s]\nINFO : Cross-entropy: 1.3157 nats (= perplexity 3.727)\n100%|██████████| 996/996 [03:04<00:00,  5.39it/s]\nINFO : Tagging accuracy: all: 60.646%, known: 61.151%, seen: 55.051%, novel: 55.548%\n  4%|▍         | 9/200 [00:01<00:21,  9.05it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-1410.pkl\n100%|██████████| 200/200 [00:33<00:00,  5.93it/s]\nINFO : Average learning speed: 0.025 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 193.86it/s]\nINFO : Cross-entropy: 1.2654 nats (= perplexity 3.545)\n100%|██████████| 996/996 [03:06<00:00,  5.34it/s]\nINFO : Tagging accuracy: all: 61.126%, known: 61.554%, seen: 56.566%, novel: 56.737%\n100%|██████████| 200/200 [00:30<00:00,  6.55it/s]\nINFO : Average learning speed: 0.02 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 198.44it/s]\nINFO : Cross-entropy: 1.2265 nats (= perplexity 3.409)\n100%|██████████| 996/996 [03:05<00:00,  5.36it/s]\nINFO : Tagging accuracy: all: 62.320%, known: 62.882%, seen: 56.229%, novel: 56.605%\n  4%|▍         | 9/200 [00:01<00:22,  8.42it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-1810.pkl\n100%|██████████| 200/200 [00:33<00:00,  5.98it/s]\nINFO : Average learning speed: 0.022 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 194.64it/s]\nINFO : Cross-entropy: 1.1892 nats (= perplexity 3.284)\n100%|██████████| 996/996 [03:05<00:00,  5.37it/s]\nINFO : Tagging accuracy: all: 64.065%, known: 64.873%, seen: 55.556%, novel: 55.746%\n100%|██████████| 200/200 [00:30<00:00,  6.51it/s]\nINFO : Average learning speed: 0.022 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 199.79it/s]\nINFO : Cross-entropy: 1.1566 nats (= perplexity 3.179)\n100%|██████████| 996/996 [03:05<00:00,  5.38it/s]\nINFO : Tagging accuracy: all: 64.174%, known: 64.796%, seen: 56.734%, novel: 58.124%\n  4%|▍         | 9/200 [00:01<00:19,  9.80it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-2210.pkl\n100%|██████████| 200/200 [00:34<00:00,  5.87it/s]\nINFO : Average learning speed: 0.021 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 199.31it/s]\nINFO : Cross-entropy: 1.1280 nats (= perplexity 3.090)\n100%|██████████| 996/996 [03:04<00:00,  5.40it/s]\nINFO : Tagging accuracy: all: 64.303%, known: 64.905%, seen: 56.902%, novel: 58.520%\n100%|██████████| 200/200 [00:32<00:00,  6.09it/s]\nINFO : Average learning speed: 0.019 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 199.43it/s]\nINFO : Cross-entropy: 1.1034 nats (= perplexity 3.015)\n100%|██████████| 996/996 [03:05<00:00,  5.38it/s]\nINFO : Tagging accuracy: all: 65.005%, known: 65.551%, seen: 57.407%, novel: 60.106%\n  4%|▍         | 8/200 [00:01<00:24,  7.79it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-2610.pkl\n100%|██████████| 200/200 [00:35<00:00,  5.71it/s]\nINFO : Average learning speed: 0.023 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 199.74it/s]\nINFO : Cross-entropy: 1.0807 nats (= perplexity 2.947)\n100%|██████████| 996/996 [03:04<00:00,  5.39it/s]\nINFO : Tagging accuracy: all: 66.266%, known: 66.897%, seen: 57.744%, novel: 60.502%\n100%|██████████| 200/200 [00:30<00:00,  6.46it/s]\nINFO : Average learning speed: 0.018 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 198.40it/s]\nINFO : Cross-entropy: 1.0610 nats (= perplexity 2.889)\n100%|██████████| 996/996 [03:05<00:00,  5.37it/s]\nINFO : Tagging accuracy: all: 66.909%, known: 67.946%, seen: 53.704%, novel: 57.133%\n  4%|▍         | 8/200 [00:00<00:18, 10.56it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-3010.pkl\n100%|██████████| 200/200 [00:31<00:00,  6.37it/s]\nINFO : Average learning speed: 0.018 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 199.73it/s]\nINFO : Cross-entropy: 1.0431 nats (= perplexity 2.838)\n100%|██████████| 996/996 [03:04<00:00,  5.39it/s]\nINFO : Tagging accuracy: all: 67.042%, known: 67.730%, seen: 56.566%, novel: 61.229%\n100%|██████████| 200/200 [00:33<00:00,  5.88it/s]\nINFO : Average learning speed: 0.019 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 198.11it/s]\nINFO : Cross-entropy: 1.0251 nats (= perplexity 2.787)\n100%|██████████| 996/996 [03:05<00:00,  5.37it/s]\nINFO : Tagging accuracy: all: 67.556%, known: 68.175%, seen: 58.923%, novel: 62.021%\n  4%|▍         | 9/200 [00:01<00:31,  6.12it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-3410.pkl\n100%|██████████| 200/200 [00:31<00:00,  6.30it/s]\nINFO : Average learning speed: 0.018 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 199.33it/s]\nINFO : Cross-entropy: 1.0097 nats (= perplexity 2.745)\n100%|██████████| 996/996 [03:05<00:00,  5.38it/s]\nINFO : Tagging accuracy: all: 67.911%, known: 68.500%, seen: 59.933%, novel: 62.550%\n100%|██████████| 200/200 [00:34<00:00,  5.82it/s]\nINFO : Average learning speed: 0.019 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:04<00:00, 199.68it/s]\nINFO : Cross-entropy: 0.9937 nats (= perplexity 2.701)\n100%|██████████| 996/996 [03:04<00:00,  5.40it/s]\nINFO : Tagging accuracy: all: 69.661%, known: 70.478%, seen: 58.249%, novel: 62.351%\n  4%|▍         | 9/200 [00:01<00:24,  7.90it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-3810.pkl\n100%|██████████| 200/200 [00:33<00:00,  5.96it/s]\nINFO : Average learning speed: 0.018 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 198.34it/s]\nINFO : Cross-entropy: 0.9793 nats (= perplexity 2.663)\n100%|██████████| 996/996 [03:04<00:00,  5.39it/s]\nINFO : Tagging accuracy: all: 69.873%, known: 70.583%, seen: 59.428%, novel: 63.738%\n100%|██████████| 200/200 [00:32<00:00,  6.11it/s]\nINFO : Average learning speed: 0.016 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 195.91it/s]\nINFO : Cross-entropy: 0.9659 nats (= perplexity 2.627)\n100%|██████████| 996/996 [03:05<00:00,  5.37it/s]\nINFO : Tagging accuracy: all: 70.521%, known: 71.238%, seen: 59.596%, novel: 64.465%\n  4%|▍         | 9/200 [00:01<00:25,  7.54it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-4210.pkl\n100%|██████████| 200/200 [00:32<00:00,  6.23it/s]\nINFO : Average learning speed: 0.018 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 198.13it/s]\nINFO : Cross-entropy: 0.9542 nats (= perplexity 2.597)\n100%|██████████| 996/996 [03:03<00:00,  5.44it/s]\nINFO : Tagging accuracy: all: 71.402%, known: 72.346%, seen: 58.923%, novel: 62.682%\n100%|██████████| 200/200 [00:32<00:00,  6.23it/s]\nINFO : Average learning speed: 0.017 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 199.01it/s]\nINFO : Cross-entropy: 0.9440 nats (= perplexity 2.570)\n100%|██████████| 996/996 [03:04<00:00,  5.41it/s]\nINFO : Tagging accuracy: all: 71.531%, known: 72.465%, seen: 59.259%, novel: 62.880%\n  4%|▍         | 8/200 [00:01<00:28,  6.77it/s]INFO : Saved model to /kaggle/working/ensup_crf_backprop-4610.pkl\n100%|██████████| 200/200 [00:32<00:00,  6.18it/s]\nINFO : Average learning speed: 0.015 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 194.75it/s]\nINFO : Cross-entropy: 0.9339 nats (= perplexity 2.544)\n100%|██████████| 996/996 [03:04<00:00,  5.39it/s]\nINFO : Tagging accuracy: all: 72.358%, known: 73.252%, seen: 60.606%, novel: 64.069%\n100%|██████████| 200/200 [00:34<00:00,  5.76it/s]\nINFO : Average learning speed: 0.018 (estimated training loss reduction per example)\n100%|██████████| 996/996 [00:05<00:00, 196.01it/s]\nINFO : Cross-entropy: 0.9233 nats (= perplexity 2.518)\n100%|██████████| 996/996 [03:04<00:00,  5.40it/s]\nINFO : Tagging accuracy: all: 72.350%, known: 73.353%, seen: 59.091%, novel: 63.078%\nINFO : Saved model to /kaggle/working/ensup_crf_backprop.pkl\n","output_type":"stream"},{"traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      7\u001b[39m crf_backprop = ConditionalRandomFieldBackprop(entrain.tagset, entrain.vocab)\n\u001b[32m      8\u001b[39m crf_backprop.train(\n\u001b[32m      9\u001b[39m     corpus=ensup,\n\u001b[32m     10\u001b[39m     loss=loss_dev,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     save_path=\u001b[33m\"\u001b[39m\u001b[33m/kaggle/working/ensup_crf_backprop.pkl\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mlook_at_your_data\u001b[49m(crf_backprop, endev, \u001b[32m5\u001b[39m)\n","\u001b[31mNameError\u001b[39m: name 'look_at_your_data' is not defined"],"ename":"NameError","evalue":"name 'look_at_your_data' is not defined","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"from crf_backprop import ConditionalRandomFieldBackprop\n\nloss_dev = lambda model: viterbi_error_rate(model, eval_corpus=endev, \n                                            known_vocab=known_vocab)\n\nlog.info(\"*** Conditional Random Field (autograd/backprop)\")\ncrf_backprop = ConditionalRandomFieldBackprop(entrain.tagset, entrain.vocab)\ncrf_backprop.train(\n    corpus=ensup,\n    loss=loss_dev,\n    reg=1.0,\n    lr=0.05,\n    minibatch_size=10,\n    eval_interval=200,\n    max_steps=5000,\n    save_path=\"/kaggle/working/ensup_crf_backprop.pkl\",\n)\nlook_at_your_data(crf_backprop, endev, 5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"look_at_your_data(crf_backprop, endev, 5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:34:02.162045Z","iopub.execute_input":"2025-11-22T15:34:02.162350Z","iopub.status.idle":"2025-11-22T15:35:43.894068Z","shell.execute_reply.started":"2025-11-22T15:34:02.162328Z","shell.execute_reply":"2025-11-22T15:35:43.892766Z"}},"outputs":[{"name":"stderr","text":"INFO : Gold:    ``/` We/P 're/V strongly/R _OOV_/V that/I anyone/N who/W has/V eaten/V in/I the/D cafeteria/N this/D month/N have/V the/D shot/N ,/, ''/' Mr./N Mattausch/N added/V ,/, ``/` and/C that/D means/V virtually/R everyone/N who/W works/V here/R ./.\nINFO : Viterbi: ``/` We/J 're/N strongly/N _OOV_/N that/I anyone/N who/N has/V eaten/N in/I the/D cafeteria/J this/N month/N have/V the/D shot/N ,/, ''/' Mr./N Mattausch/N added/N ,/, ``/` and/C that/I means/N virtually/N everyone/N who/N works/N here/N ./.\nINFO : Loss:    15/34\n/tmp/ipykernel_12/3159287395.py:14: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\nConsider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n  log.info(f\"Cross-entropy: {xent/math.log(2)} nats (= perplexity {math.exp(xent)})\\n---\")\nINFO : Cross-entropy: 1.7643154826952563 nats (= perplexity 3.397127774681285)\n---\nINFO : Gold:    I/P was/V _OOV_/V to/T read/V the/D _OOV_/N of/I facts/N in/I your/P Oct./N 13/C editorial/N ``/` _OOV_/N 's/P _OOV_/N _OOV_/N ./. ''/'\nINFO : Viterbi: I/P was/V _OOV_/V to/T read/V the/D _OOV_/N of/I facts/N in/I your/N Oct./N 13/N editorial/N ``/N _OOV_/N 's/P _OOV_/N _OOV_/N ./. ''/'\nINFO : Loss:    3/21\nINFO : Cross-entropy: 1.1027407654060886 nats (= perplexity 2.147623007068822)\n---\nINFO : Gold:    It/P is/V the/D _OOV_/J guerrillas/N who/W are/V aligned/V with/I the/D drug/N traffickers/N ,/, not/R the/D left/J _OOV_/N ./.\nINFO : Viterbi: It/P is/V the/D _OOV_/J guerrillas/N who/N are/V aligned/N with/I the/D drug/N traffickers/N ,/, not/V the/D left/J _OOV_/N ./.\nINFO : Loss:    3/18\nINFO : Cross-entropy: 0.8977674891530679 nats (= perplexity 1.8631805563365833)\n---\nINFO : Gold:    This/D information/N was/V _OOV_/V from/I your/P own/J news/N stories/N on/I the/D region/N ./.\nINFO : Viterbi: This/N information/N was/V _OOV_/N from/I your/N own/N news/N stories/N on/I the/D region/N ./.\nINFO : Loss:    4/13\nINFO : Cross-entropy: 0.9949326369319683 nats (= perplexity 1.9929874658746893)\n---\nINFO : Gold:    _OOV_/J _OOV_/J government/N _OOV_/N of/I the/D ``/` _OOV_/F ''/' was/V due/J to/T the/D drug/N _OOV_/N '/P history/N of/I _OOV_/V out/R _OOV_/N in/I the/D _OOV_/N ./.\nINFO : Viterbi: _OOV_/N _OOV_/N government/N _OOV_/N of/I the/D ``/J _OOV_/N ''/N was/V due/V to/T the/D drug/N _OOV_/N '/N history/N of/I _OOV_/N out/N _OOV_/N in/I the/D _OOV_/N ./.\nINFO : Loss:    9/25\nINFO : Cross-entropy: 1.5526071032406736 nats (= perplexity 2.93346769279389)\n---\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### Neural biRNN-CRF\nRun the neural CRF with a simple one-hot lexicon to sanity-check `ConditionalRandomFieldNeural`.","metadata":{}},{"cell_type":"code","source":"from crf_neural import ConditionalRandomFieldNeural\nfrom lexicon import build_lexicon\nimport torch\n\nlog.info(\"*** Neural biRNN-CRF (autograd/backprop)\")\nlexicon = build_lexicon(entrain, one_hot=True)\nlexicon = lexicon.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), dtype=torch.float64)\ncrf_neural = ConditionalRandomFieldNeural(\n    entrain.tagset,\n    entrain.vocab,\n    lexicon=lexicon,\n    rnn_dim=16,\n)\ncrf_neural.train(\n    corpus=ensup,\n    loss=loss_dev,\n    reg=0.5,\n    lr=0.01,\n    minibatch_size=5,\n    eval_interval=100,\n    max_steps=2000,\n    save_path=\"ensup_crf_neural.pkl\",\n)\nlook_at_your_data(crf_neural, endev, 3)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}